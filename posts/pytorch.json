[{"id":1270,"date":"2020-05-21T07:55:23","date_gmt":"2020-05-21T07:55:23","guid":{"rendered":"http://python3.foobrdigital.com/?p=1270"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"what-is-pytorch","status":"publish","type":"post","link":"https://python3.foobrdigital.com/what-is-pytorch/","title":{"rendered":"What is Pytorch?"},"content":{"rendered":"\n<p><strong>PyTorch</strong>&nbsp;is a small part of a computer software which is based on&nbsp;<strong>Torch</strong>&nbsp;library. It is a Deep Learning framework introduced by&nbsp;<strong>Facebook</strong>. PyTorch is a&nbsp;<strong>Machine Learning Library</strong>&nbsp;for&nbsp;<strong>Python</strong>&nbsp;programming language which is used for applications such as&nbsp;<strong>Natural Language Processing</strong>.</p>\n\n\n\n<p><strong>The high-level features which are provided by PyTorch are as follows:</strong></p>\n\n\n\n<ol><li>With the help of the&nbsp;<strong>Graphics Processing Unit</strong>&nbsp;(GPU), it gives tensor computing with strong acceleration.</li><li>It provides&nbsp;<strong>Deep Neural Network</strong>&nbsp;which is built on a tape-based auto diff system.</li></ol>\n\n\n\n<p>PyTorch was developed to provide high flexibility and speed during implementing and building the&nbsp;<strong>Deep Learning Neural Network</strong>. As you already know, it is a machine learning library for&nbsp;<strong>Python</strong>&nbsp;programming language, so it&#8217;s quite simple to install, run, and understand. Pytorch is&nbsp;<strong>completely pythonic</strong>&nbsp;(using widely adopted python idioms rather than writing Java and C++ code) so that it can quickly build a&nbsp;<strong>Neural Network Model</strong>&nbsp;successfully.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/what-is-pytorch.png\" alt=\"What is PyTorch\"/></figure>\n\n\n\n<h2>History of PyTorch</h2>\n\n\n\n<p><strong>PyTorch</strong>&nbsp;was released in 2016. Many researchers are willing to adopt PyTorch increasingly. It was operated by&nbsp;<strong>Facebook</strong>. Facebook also operates&nbsp;<strong>Caffe2</strong>&nbsp;(Convolutional Architecture for Fast Feature Embedding). It is challenging to transform a PyTorch-defined model into Caffe2. For this purpose, Facebook and Microsoft invented an&nbsp;<strong>Open Neural Network Exchange</strong>&nbsp;(ONNX) in September2017. In simple words, ONNX was developed for converting models between frameworks. Caffe2 was merged in March 2018 into PyTorch.</p>\n\n\n\n<p>PyTorch makes ease in building an extremely complex neural network. This feature has quickly made it a go-to library. In research work, it gives a tough competition to TensorFlow. Inventors of PyTorch wants to make a highly imperative library which can easily run all the numerical computation, and finally, they invented PyTorch. There was a big challenge for Deep learning scientist, Machine learning developer, and Neural Network debuggers to run and test part of the code in real-time. PyTorch completes this challenge and allows them to run and test their code in real-time. So they don&#8217;t have to wait to check whether it works or not.</p>\n\n\n\n<p>Note: To use the PyTorch functionality and services, you can use Python packages such as NumPy, SciPy, and Cython.</p>\n\n\n\n<h2>Why use PyTorch?</h2>\n\n\n\n<p>Why PyTorch? What is special in PyTorch which makes it special to build Deep learning model. PyTorch is a dynamic library. Dynamic library means a flexible library, and you can use that library as per your requirements and changes. At present in Kaggle competition, it is continuously used by finishers.</p>\n\n\n\n<p>There are so many features which makes deep learning scientist to use it in making Deep learning model.</p>\n\n\n\n<p><strong>These features are as follows.</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/what-is-pytorch2.png\" alt=\"What is PyTorch\"/></figure>\n\n\n\n<h3>Simple interface</h3>\n\n\n\n<p>PyTorch has a very simple interface like Python. It provides an easy way to use API. This framework is very easy to run and operate like Python. PyTorch can easily understand or implement on both Windows and Linux.</p>\n\n\n\n<h3>Hybrid Front-End</h3>\n\n\n\n<p>PyTorch provides a new hybrid front-end which provides flexibility and ease of use in eager mode, while originally transition to graph mode for speed, optimization, and functionality in C++ runtime environment.</p>\n\n\n\n<p><strong>For example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>@torch.jit.script  \n def Rnn(h, x, Wh, Uh, Wy, bh, by):  \n  y = &#91;]                                                       \n  for t in range(x.size(0)):  \n    h = torch.tanh(x&#91;t] @ Wh + h @ Uh + bh)  \ny += &#91;torch.tanh(h @ Wy + by)]  \n    if t % 10 == 0:  \n        print(\"stats: \", h.mean(), h.var())  \n    return torch.stack(y), h  </code></pre>\n\n\n\n<h3>Distributed Training</h3>\n\n\n\n<p>PyTorch allows developers to train a neural network model in a distributed manner. It provides optimized performance in both research and production with the help of native support for peer to peer communication and asynchronous execution of collective operation from Python and C++.</p>\n\n\n\n<p><strong>For example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch.distributed as dist1   \nfrom torch.nn.parallel import DistributedDataParallel  \ndist1.init_process_group(backend='gloo')  \nmodel = DistributedDataParallel(model)  </code></pre>\n\n\n\n<h3>Python-First</h3>\n\n\n\n<p>PyTorch is completely based on Python. PyTorch is used with most popular libraries and packages of Python such as Cython and Numba. PyTorch is built deeply into Python. Its code is completely pythonic.&nbsp;<strong>Pythonic</strong>&nbsp;means using widely adopted Python idioms rather than writing java and C++ code in your code.</p>\n\n\n\n<p><strong>For example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np  \nx = np.ones(5)  \ny = torch.from_numpy(x)  \nnp.add(x, 1, out=x)  \nprint(x)  \nprint(y)  </code></pre>\n\n\n\n<h3>Tools and Libraries</h3>\n\n\n\n<p>A rich ecosystem of tools and libraries are available for extending PyTorch and supporting development in areas from computer vision and reinforcement learning. This ecosystem was developed by an active community of developers and researchers. These ecosystems help them to build flexible and fast access Deep learning neural network.</p>\n\n\n\n<p><strong>For example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torchvision.models as models  \nresnet18 = models.resnet18(pretrained=True)  \nalexnet = models.alexnet(pretrained=True)  \nsqueezenet = models.squeezenet1_0(pretrained=True)  \nvgg16 = models.vgg16(pretrained=True)  \ndensenet = models.densenet161(pretrained=True)  \ninception = models.inception_v3(pretrained=True)  </code></pre>\n\n\n\n<h3>Native ONNX Support</h3>\n\n\n\n<p>ONNX was developed for converting models between frameworks. For direct access to ONNX-compatible platforms, runtimes, visualizers, and more, you need to export models in the standard ONNX.</p>\n\n\n\n<p><strong>For example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch.onnx  \nimport torchvision  \ndum_input = torch.randn(1, 3, 224, 224)  \nmodel = torchvision.models.alexnet(pretrained=True)  \ntorch.onnx.export(model, dum_input, \"alexnet.onnx\") </code></pre>\n\n\n\n<h3>C++ Front-End</h3>\n\n\n\n<p>The C++ front-end is a c++ interface for PyTorch which follows the design and architecture of the established Python frontend. It enable research in high performance, low latency and bare metal C++ application.</p>\n\n\n\n<p><strong>For example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>#include &lt;torch/torch.h>  \ntorch::nn::Linear model(num_features, 1);  \ntorch::optim::SGD optimizer(model->parameters());  \nauto data_loader = torch::data::data_loader(dataset);  \nfor (size_t epoch = 0; epoch &lt; 10; ++epoch)  \n {  \n      for (auto batch : data_loader)   \n      {  \n        auto prediction = model->forward(batch.data);  \n        auto loss = loss_function(prediction, batch.target);  \n        loss.backward();  \n        optimizer.step();  \n    }  \n}  </code></pre>\n\n\n\n<h3>Cloud Partners</h3>\n\n\n\n<p>PyTorch is supported by many major cloud platforms such as AWS. With the help of prebuilt images, large scale training on GPU&#8217;s and ability to run models in a production scale environment etc.; it provides frictionless development and easy scaling.</p>\n\n\n\n<p><strong>For example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>export IMAGE_FAMILY=\"pytorch-latest-cpu\"  \n  export ZONE=\"us-west1-b\"  \n  export INSTANCE_NAME=\"my-instance\"  \n  gcloud compute instances create $INSTANCE_NAME \\  \n  --zone=$ZONE \\  \n  --image-family=$IMAGE_FAMILY \\ </code></pre>\n","protected":false},"excerpt":{"rendered":"<p>PyTorch&nbsp;is a small part of a computer software which is based on&nbsp;Torch&nbsp;library. It is a Deep Learning framework introduced by&nbsp;Facebook. PyTorch is a&nbsp;Machine Learning Library&nbsp;for&nbsp;Python&nbsp;programming language which is used for applications such as&nbsp;Natural Language Processing. The high-level features which are provided by PyTorch are as follows: With the help of the&nbsp;Graphics Processing Unit&nbsp;(GPU), it gives [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2292,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1270"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1270"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1270/revisions"}],"predecessor-version":[{"id":1281,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1270/revisions/1281"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2292"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1270"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1270"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1270"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1271,"date":"2020-05-21T07:57:16","date_gmt":"2020-05-21T07:57:16","guid":{"rendered":"http://python3.foobrdigital.com/?p=1271"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"installation-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/installation-2/","title":{"rendered":"Installation"},"content":{"rendered":"\n<p>For installation, first, you have to choose your preference and then run the install command. You can start installation locally or with a cloud partner. In the below diagram, Stable shows the most currently supported and tested version of PyTorch (1.1), which is suitable for many users. If you want the latest 1.1 builds but not fully tested and supported, then you have to choose Preview (Nightly).</p>\n\n\n\n<p>For installation, it&#8217;s necessary that you have met the prerequisites which are suited to your package manager. We recommend you to use&nbsp;<strong>Anaconda</strong>&nbsp;package manager because it installs all the dependencies.</p>\n\n\n\n<table><tbody><tr><th>Platforms, Os, Language and other prerequisites</th></tr><tr><td><strong>PyTorch Build</strong></td><td>Suitable (1.1)</td><td>Preview</td></tr><tr><td><strong>Os</strong></td><td>Linux</td><td>Mac</td><td>Windows</td></tr><tr><td><strong>package</strong></td><td>Conda</td><td>pip</td><td>LibTorch</td><td>Source</td></tr><tr><td><strong>language</strong></td><td>Python 2.7</td><td>Python 3.5</td><td>Python 3.6</td><td>Python 3.7</td><td>C++</td></tr><tr><td><strong>Cuda</strong></td><td>9.0</td><td>10.0</td><td>None</td></tr></tbody></table>\n\n\n\n<p>LibTorch is available only for C++. Now, we first install PyTorch in windows with the pip package, and after that we use Conda.</p>\n\n\n\n<h2>Installation on Windows using Pip</h2>\n\n\n\n<p>To install PyTorch, you have to install python first, and then you have to follow the following steps.</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>At very first you have to enter on the python37 folder and then in its Scripts folder using cd Scripts command.</p>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the second step, you have to install pip as per your required version with the help of&nbsp;<strong>easy_install.exe</strong>&nbsp;pip command on your command prompt. Once processing of dependencies is finished, you will back to the Scripts folder automatically.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation.png\" alt=\"PyTorch Installation\"/></figure>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Now, your next steps is to install numpy package of python for pip. Numpy installation will be done with the help of the&nbsp;<strong>pip install numpy command</strong>. If your python has already this package, then it will show you&nbsp;<strong>&#8220;Requirement already satisfied&#8221;</strong>&nbsp;otherwise, it will install the package.&nbsp;<strong>Pip list</strong>&nbsp;command is used to check packages.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation2.png\" alt=\"PInstallation on Windows using Pip\"/></figure>\n\n\n\n<p>When downloading is finished, it shows a successful message and takes back your cursor in the scripts folder.</p>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>Next step is to install pip another package scipy with the help of&nbsp;<strong>pip install scipy</strong>&nbsp;command.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation3.png\" alt=\"Installation on Windows using Pip\"/></figure>\n\n\n\n<p>Once downloading is finished your cursor comes back in the scripts folder.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation4.png\" alt=\"Installation on Windows using Pip\"/></figure>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, check all the installed packages that are required for PyTorch using the&nbsp;<strong>pip list</strong>&nbsp;command.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation5.png\" alt=\"Installation on Windows using Pip\"/></figure>\n\n\n\n<p><strong>Step 6</strong></p>\n\n\n\n<p>Now, you have to go on&nbsp;<a href=\"https://pytorch.org/\" rel=\"noreferrer noopener\" target=\"_blank\">https://pytorch.org/</a>&nbsp;to get the installation command of PyTorch.</p>\n\n\n\n<p>Here, you have to select your preferred PyTorch build, Operating System, Package, Language, and CUDA. It provides you two commands to install PyTorch in your windows.</p>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>Next step is to run both the command on your command prompt. Remember if you make any changes in this command, it will not install PyTorch and give an error message.</p>\n\n\n\n<ul><li>pip3 install&nbsp;<a href=\"https://download.pytorch.org/whl/cpu/torch-1.1.0-cp35-cp35m-win_amd64.whl\" rel=\"noreferrer noopener\" target=\"_blank\">https://download.pytorch.org/whl/cpu/torch-1.1.0-cp35-cp35m-win_amd64.whl</a></li></ul>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation7.png\" alt=\"Installation on Windows using Pip\"/></figure>\n\n\n\n<ul><li>pip3 install&nbsp;<a href=\"https://download.pytorch.org/whl/cpu/torchvision-0.3.0-cp35-cp35m-win_amd64.whl\" rel=\"noreferrer noopener\" target=\"_blank\">https://download.pytorch.org/whl/cpu/torchvision-0.3.0-cp35-cp35m-win_amd64.whl</a></li></ul>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation8.png\" alt=\"Installation on Windows using Pip\"/></figure>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>Now, rerun pip list command to check PyTorch is run successfully or not.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation9.png\" alt=\"Installation on Windows using Pip\"/></figure>\n\n\n\n<p><strong>Step 9:</strong></p>\n\n\n\n<p>Now, test PyTorch. Run python command to work with python. Import torch to work with PyTorch and perform the operation.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation10.png\" alt=\"Installation on Windows using Pip\"/></figure>\n\n\n\n<h2>Installation on Windows using Conda</h2>\n\n\n\n<p>This tutorial defines step by step installation of PyTorch. To install PyTorch using Conda you have to follow the following steps</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>First, you have to install Anaconda&#8217;s latest version in your system. To install Anaconda, you have to go through&nbsp;<a href=\"https://www.anaconda.com/distribution/\" rel=\"noreferrer noopener\" target=\"_blank\">https://www.anaconda.com/distribution/</a>.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation11.png\" alt=\"Installation on Windows using Conda\"/></figure>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>Now, run your Anaconda setup and install it completely. Once your installation of Anaconda is complete, an Anaconda command prompt appears to you.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation12.png\" alt=\"Installation on Windows using Conda\"/></figure>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Next step is to install PyTorch using Anaconda command prompt. To install PyTorch, you have to run the installation command of PyTorch on your command prompt. This command is available on&nbsp;<a href=\"https://pytorch.org/\" rel=\"noreferrer noopener\" target=\"_blank\">https://pytorch.org/</a>.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation13.png\" alt=\"Installation on Windows using Conda\"/></figure>\n\n\n\n<p>Select language and cuda version as per your requirement.</p>\n\n\n\n<p><strong>Step 4</strong></p>\n\n\n\n<p>Now, run&nbsp;<strong>python -version</strong>, and&nbsp;<strong>Conda -version</strong>&nbsp;command to check&nbsp;<strong>Conda</strong>&nbsp;and&nbsp;<strong>python</strong>&nbsp;packages are installed or not. After that, you run the given command in your command prompt. Remember the command which you run on command prompt is similar to the given command. If it is not similar, then it will generate error message and installation will become unsuccessful.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation14.png\" alt=\"Installation on Windows using Conda\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation15.png\" alt=\"Installation on Windows using Conda\"/></figure>\n\n\n\n<p>It will take some time to download and install all the packages. After completion of your command, your cursor switch to your directory&#8217;s folder.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation16.png\" alt=\"PyTorch Installation\"/></figure>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, perform conda list pytorch command to check all the package are installed successfully or not.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation17.png\" alt=\"PyTorch Installation\"/></figure>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>Now, test PyTorch. Run python command to work with python. Import torch to work with PyTorch and perform the operation.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation18.png\" alt=\"PyTorch Installation\"/></figure>\n\n\n\n<h2>Installation on Linux</h2>\n\n\n\n<p>PyTorch installation in Linux is similar to the installation of Windows using Conda. To install PyTorch in your Linux system, you have to follow the steps which are giving below.</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>Your first step is to download Anaconda in your Linux operating system. To download it, you have to go through the following link&nbsp;<a href=\"https://www.anaconda.com/distribution/\" rel=\"noreferrer noopener\" target=\"_blank\">https://www.anaconda.com/distribution/</a>.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation19.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>Here, you choose the latest version of python, i.e., 3.7 and click right button of the mouse and copy link address to install it.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation20.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Open your terminal and run the copy link on the terminal using wget &lt;link&gt; command. This command download Anaconda in your Linux system.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation21.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p>It takes a few seconds to download. Once downloading is complete your cursor go back to your home directory.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation22.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>Next step is to install Anaconda in your system. To install it, you have to first enter in downloads directory or where you have downloaded your anaconda. Installation is done with bash file because in Linux when you download Anaconda, It downloaded as bash file. So, to install Anaconda, you have to run the&nbsp;<strong>bash ~/Downloads/Anaconda3-2019.03-Linux-x86_64.sh</strong>&nbsp;command for the latest version of python 3.7 or to run the&nbsp;<strong>bash ~/Downloads/Anaconda2-2019.03-Linux-x86_64.sh</strong>&nbsp;command for python 2.7.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation23.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p>Here, you have to press the enter button to continue. When you press enter your installation is started. After a few installations it asks you one more question, i.e., Do you accept the license terms? You give it an answer by typing, yes.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation24.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>When you type yes and press enter, your installation of anaconda starts. After a few installations once again it asks you one last question, i.e., Do you wish the installer to initialize Anaconda3 by running conda init? You again type yes as an answer, and after that, your cursor comes back to downloads directory.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation25.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>Now next step is to run&nbsp;<strong>source ~/.bashrc</strong>&nbsp;and&nbsp;<strong>anaconda-navigator</strong>&nbsp;and then we install the PyTorch.</p>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>Next step is to go to the official site of PyTorch using&nbsp;<a href=\"https://pytorch.org/\" rel=\"noreferrer noopener\" target=\"_blank\">https://pytorch.org/</a>&nbsp;link.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation26.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p>Here, you have to select your operating system, package, language, and CUDA version. I am using Conda package with python 3.7 and CUDA 9.0.</p>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>Now you have to run the command given by the official website on your terminal. Remember the command which you run is similar to the given command; otherwise, it will generate the error message with the unsuccessful installation.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation27.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p>After a few seconds, it asks you to update packages if available. We have to give its answer by writing y.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation28.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p>Once you give its answer, it starts downloading all packages such as PyTorch, Cudatoolkit, Conda, torch, etc.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation29.png\" alt=\"Installation on Linux\"/></figure>\n\n\n\n<p><strong>Step 9:</strong></p>\n\n\n\n<p>Now, PyTorch installs successfully. It&#8217;s time to test PyTorch by executing torch program.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-installation30.png\" alt=\"Installation on Linux\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>For installation, first, you have to choose your preference and then run the install command. You can start installation locally or with a cloud partner. In the below diagram, Stable shows the most currently supported and tested version of PyTorch (1.1), which is suitable for many users. If you want the latest 1.1 builds but [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2293,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1271"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1271"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1271/revisions"}],"predecessor-version":[{"id":2491,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1271/revisions/2491"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2293"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1271"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1271"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1271"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1272,"date":"2020-05-21T07:58:34","date_gmt":"2020-05-21T07:58:34","guid":{"rendered":"http://python3.foobrdigital.com/?p=1272"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"packages","status":"publish","type":"post","link":"https://python3.foobrdigital.com/packages/","title":{"rendered":"Packages"},"content":{"rendered":"\n<p>PyTorch is an optimized tensor library for deep learning using CPUs and GPUs. PyTorch has a rich set of packages which are used to perform deep learning concepts. These packages help us in optimization, conversion, and loss calculation, etc. Let&#8217;s get a brief knowledge of these packages.</p>\n\n\n\n<table><tbody><tr><th>S.No</th><th>Name</th><th>Description</th></tr><tr><td>1.</td><td>Torch</td><td>The torch package includes data structure for multi-dimensional tensors and mathematical operation over these are defined.</td></tr><tr><td>2.</td><td>torch.Tensor</td><td>This package is a multi-dimensional matrix which contains an element of a single data type.</td></tr><tr><td>3.</td><td>Tensor Attributes</td><td></td></tr><tr><td>a) torch.dtype</td><td>It is an object which represents the datatype of thetorch.Tensor.</td></tr><tr><td>b) torch.device</td><td>It is an object that represents the device on which torch.Tensor will be allocated.</td></tr><tr><td>c) torch.layout</td><td>It is an object which represents a memory layout of a toch.Tensor.</td></tr><tr><td>4.</td><td>Type Info</td><td>The numerical properties of a torch.dtype will be accessed through either the torch.iinfo or the torch.finfo.</td></tr><tr><td>1) torch.finfo</td><td>It is an object which represents the numerical properties of a floating-point torch.dtype.</td></tr><tr><td>2) torch.iinfo</td><td>It is an object which represents the numerical properties of an integer torch.dtype.</td></tr><tr><td>5.</td><td>torch.sparse</td><td>Torch supports sparse tensors in COO (rdinate) format, which will efficiently store and process tensors for which the majority of elements are zero.</td></tr><tr><td>6.</td><td>torch.cuda</td><td>Torch supports for CUDA tensor types which implement the same function as CPU tensors, but for computation they utilize GPUs.</td></tr><tr><td>7.</td><td>torch.Storage</td><td>A torch.Storage is a contiguous, one-dimensional array of a single data type.</td></tr><tr><td>8.</td><td>torch.nn</td><td>This package provides us many more classes and modules to implement and train the neural network.</td></tr><tr><td>9.</td><td>torch.nn.functional</td><td>This package has functional classes which are similar to torch.nn.</td></tr><tr><td>10.</td><td>torch.optim</td><td>This package is used to implement various optimization algorithm.</td></tr><tr><td>11.</td><td>torch.autogard</td><td>This package provides classes and functions to implement automatic differentiation of arbitrary scalar value functions.</td></tr><tr><td>12.</td><td>torch.distributed</td><td>This package supports three backends and each one is with different capabilities.</td></tr><tr><td>13.</td><td>torch.distribution</td><td>This package allows us to construct the stochastic computation graphs, and stochastic gradient estimators for optimization</td></tr><tr><td>14.</td><td>torch.hub</td><td>It is a pre-trained model repository which is designed to facilitate research reproducibility.</td></tr><tr><td>15.</td><td>torch.multiprocessing</td><td>It is a wrapper around the native multiprocessing module.</td></tr><tr><td>16.</td><td>torch.utils.bottleneck</td><td>It is a tool which can be used as an initial step for debugging bottlenecks in our program.</td></tr><tr><td>17.</td><td>torch.utils.checkpoint</td><td>It is used to create checkpoint in our source program.</td></tr><tr><td>18.</td><td>torch.tils.cpp_extension</td><td>It is used to create the extension of C++, CUDA, and other languages.</td></tr><tr><td>19.</td><td>torch.utils.data</td><td>This package is mainly used for creating the dataset.</td></tr><tr><td>20.</td><td>torch.utils.dlpack</td><td>It will use to decode the Dlpack into tensor.</td></tr><tr><td>21.</td><td>torch.onnx</td><td>The&nbsp;<strong>ONNX</strong>&nbsp;exporter is a trace-based exporter, which means that it operates by executing your model once and exporting the operators which were actually run during this run</td></tr></tbody></table>\n","protected":false},"excerpt":{"rendered":"<p>PyTorch is an optimized tensor library for deep learning using CPUs and GPUs. PyTorch has a rich set of packages which are used to perform deep learning concepts. These packages help us in optimization, conversion, and loss calculation, etc. Let&#8217;s get a brief knowledge of these packages. S.No Name Description 1. Torch The torch package [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2294,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1272"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1272"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1272/revisions"}],"predecessor-version":[{"id":2490,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1272/revisions/2490"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2294"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1272"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1272"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1272"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1273,"date":"2020-05-21T08:03:57","date_gmt":"2020-05-21T08:03:57","guid":{"rendered":"http://python3.foobrdigital.com/?p=1273"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"torch-nn","status":"publish","type":"post","link":"https://python3.foobrdigital.com/torch-nn/","title":{"rendered":"Torch.nn"},"content":{"rendered":"\n<p>PyTorch provides the torch.nn module to help us in creating and training of the neural network. We will first train the basic neural network on the MNIST dataset without using any features from these models. We will use only the basic PyTorch tensor functionality and then we will incrementally add one feature from torch.nn at a time.</p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p><strong><em>torch.nn provide us many more classes and modules to implement and train the neural network.</em></strong></p></blockquote>\n\n\n\n<p>The nn package contains the following modules and classes:</p>\n\n\n\n<table><tbody><tr><th>S.No</th><th>Class and Module</th><th>Description</th></tr><tr><td>1.</td><td>torch.nn.Parameter</td><td>It is a type of tensor which is to be considered as a module parameter.</td></tr><tr><td>2.</td><td>Containers</td><td></td></tr><tr><td>1) torch.nn.Module</td><td>It is a base class for all neural network module.</td></tr><tr><td>2) torch.nn.Sequential</td><td>It is a sequential container in which Modules will be added in the same order as they are passed in the constructor.</td></tr><tr><td>3) torch.nn.ModuleList</td><td>This will holds sub-modules in a list.</td></tr><tr><td>4) torch.nn.ModuleDict</td><td>This will holds sub-modules in a directory.</td></tr><tr><td>5) torch.nn.ParameterList</td><td>This will holds the parameters in a list.</td></tr><tr><td>6) torch.nn.parameterDict</td><td>This will holds the parameters in a directory.</td></tr><tr><td>3.</td><td>Convolution layers</td><td></td></tr><tr><td>1) torch.nn.Conv1d</td><td>This package will be used to apply a 1D convolution over an input signal composed of several input planes.</td></tr><tr><td>2) torch.nn.Conv2d</td><td>This package will be used to apply a 2D convolution over an input signal composed of several input planes.</td></tr><tr><td>3) torch.nn.Conv3d</td><td>This package will be used to apply a 3D convolution over an input signal composed of several input planes.</td></tr><tr><td>4) torch.nn.ConvTranspose1d</td><td>This package will be used to apply a 1D transposed convolution operator over an input image composed of several input planes.</td></tr><tr><td>5) torch.nn.ConvTranspose2d</td><td>This package will be used to apply a 2D transposed convolution operator over an input image composed of several input planes.</td></tr><tr><td>6) torch.nn.ConvTranspose3d</td><td>This package will be used to apply a 3D transposed convolution operator over an input image composed of several input planes.</td></tr><tr><td>7) torch.nn.Unfold</td><td>It is used to extracts sliding local blocks from a batched input tensor.</td></tr><tr><td>8) torch.nn.Fold</td><td>It is used to combine an array of sliding local blocks into a large containing tensor.</td></tr><tr><td>4.</td><td>Pooling layers</td><td></td></tr><tr><td>1) torch.nn.MaxPool1d</td><td>It is used to apply a 1D max pooling over an input signal composed of several input planes.</td></tr><tr><td>2) torch.nn.MaxPool2d</td><td>It is used to apply a 2D max pooling over an input signal composed of several input planes.</td></tr><tr><td>3) torch.nn.MaxPool3d</td><td>It is used to apply a 3D max pooling over an input signal composed of several input planes.</td></tr><tr><td>4) torch.nn.MaxUnpool1d</td><td>It is used to compute the partial inverse of MaxPool1d.</td></tr><tr><td>5) torch.nn.MaxUnpool2d</td><td>It is used to compute the partial inverse of MaxPool2d.</td></tr><tr><td>6) torch.nn.MaxUnpool3d</td><td>It is used to compute the partial inverse of MaxPool3d.</td></tr><tr><td>7) torch.nn.AvgPool1d</td><td>It is used to apply a 1D average pooling over an input signal composed of several input planes.</td></tr><tr><td>8) torch.nn.AvgPool2d</td><td>It is used to apply a 2D average pooling over an input signal composed of several input planes.</td></tr><tr><td>9) torch.nn.AvgPool3d</td><td>It is used to apply a 3D average pooling over an input signal composed of several input planes.</td></tr><tr><td>10) torch.nn.FractionalMaxPool2d</td><td>It is used to apply a 2D fractional max pooling over an input signal composed of several input planes.</td></tr><tr><td>11) torch.nn.LPPool1d</td><td>It is used to apply a 1D power-average pooling over an input signal composed of several input planes.</td></tr><tr><td>12) torch.nn.LPPool2d</td><td>It is used to apply a 2D power-average pooling over an input signal composed of several input planes.</td></tr><tr><td>13) torch.nn.AdavtiveMaxPool1d</td><td>It is used to apply a 1D adaptive max pooling over an input signal composed of several input planes.</td></tr><tr><td>14) torch.nn.AdavtiveMaxPool2d</td><td>It is used to apply a 2D adaptive max pooling over an input signal composed of several input planes.</td></tr><tr><td>15) torch.nn.AdavtiveMaxPool3d</td><td>It is used to apply a 3D adaptive max pooling over an input signal composed of several input planes.</td></tr><tr><td>16) torch.nn.AdavtiveAvgPool1d</td><td>It is used to apply a 1D adaptive average pooling over an input signal composed of several input planes.</td></tr><tr><td>17) torch.nn.AdavtiveAvgPool2d</td><td>It is used to apply a 2D adaptive average pooling over an input signal composed of several input planes.</td></tr><tr><td>18) torch.nn.AdavtiveAvgPool3d</td><td>It is used to apply a 3D adaptive average pooling over an input signal composed of several input planes.</td></tr><tr><td>5.</td><td>Padding layers</td><td></td></tr><tr><td>1) torch.nn.ReflectionPad1d</td><td>It will pad the input tensor using the reflection of the input boundary.</td></tr><tr><td>2) torch.nn.ReflactionPad2d</td><td>It will pad the input tensor using the reflection of the input boundary.</td></tr><tr><td>3) torch.nn.ReplicationPad1</td><td>It will pad the input tensor using the replication of the input boundary.</td></tr><tr><td>4) torch.nn.ReplicationPad2d</td><td>It will pad the input tensor using the replication of the input boundary.</td></tr><tr><td>5) torch.nn.ReplicationPad3d</td><td>It will pad the input tensor using the replication of the input boundary.</td></tr><tr><td>6) torch.nn.ZeroPad2d</td><td>It will pad the input tensor boundaries with zero.</td></tr><tr><td>7) torch.nn.ConstantPad1d</td><td>It will pad the input tensor boundaries with a constant value.</td></tr><tr><td>8) torch.nn.ConstantPad2d</td><td>It will pad the input tensor boundaries with a constant value.</td></tr><tr><td>9) torch.nn.ConstantPad3d</td><td>It will pad the input tensor boundaries with a constant value.</td></tr><tr><td>6.</td><td>Non-linear activations (weighted sum, non-linearity)</td><td></td></tr><tr><td>1) torch.nn.ELU</td><td>It will use to apply the element-wise function:<br>ELU(x)=max(0,x)+min(0,α*(exp(x)-1))</td></tr><tr><td>2) torch.nn.Hardshrink</td><td>It will use to apply the hard shrinkage function element-wise function:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>3) torch.nn.LeakyReLU</td><td>It will use to apply the element-wise function:<br>LeakyReLu(x)=max(0,x) +negative_slope*min(0,x)</td></tr><tr><td>4) torch.nn.LogSigmoid</td><td>It will use to apply the element-wise function:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch2.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>5) torch.nn.MultiheadAttention</td><td>It is used to allow the model to attend to information from different representation subspaces</td></tr><tr><td>6) torch.nn.PReLU</td><td>It will be used to apply the element-wise function:<br>PReLU(x)=max(0,x)+a*min(0,x)</td></tr><tr><td>7) torch.nn.ReLU</td><td>It will use to apply the rectified linear unit function element-wise:<br>ReLU(x)=max(0,x)</td></tr><tr><td>8) torch.nn.ReLU6</td><td>It will be used to apply the element-wise function:<br>ReLU6(x)=min(max(0,x),6)</td></tr><tr><td>9) torch.nn.RReLU</td><td>It will use to apply the randomized leaky rectified linear unit function, element-wise, as described in the paper:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch3.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>10) torch.nn.SELU</td><td>It will use to apply the element-wise function as:<br>SELU(x)=scale*(max(0,x)+ min(0,a*(exp(x)-1)))<br><br>Here α= 1.6732632423543772848170429916717 and scale = 1.0507009873554804934193349852946.</td></tr><tr><td>11) torch.nn.CELU</td><td>It will use to apply the element-wise function as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch4.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>12) torch.nn.Sigmoid</td><td>It will use to apply the element-wise function as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch5.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>13) torch.nn.Softplus</td><td>It will use to apply the element-wise function as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch6.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>14) torch.nn.Softshrink</td><td>It will use to apply soft shrinkage function elementwise as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch7.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>15) torch.nn.Softsign</td><td>It will use to apply the element-wise function as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch8.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>16) torch.nn.Tanh</td><td>It will use to apply the element-wise function as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch9.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>17) torch.nn.Tanhshrink</td><td>It will use to apply the element-wise function as:<br>Tanhshrink(x)=x-Tanh(x)</td></tr><tr><td>18) torch.nn.Threshold</td><td>It will use to thresholds each element of the input Tensor. Threshold is defined as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch11.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>7.</td><td>Non-linear activations (other)</td><td></td></tr><tr><td>1) torch.nn.Softmin</td><td>It is used to apply the softmin function to an n-dimensional input Tensor to rescaling them. After that, the elements of the n-dimensional output Tensor lies in the range 0, 1, and sum to 1. Softmin is defined as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch12.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>2) torch.nn.Softmax</td><td>It is used to apply the softmax function to an n-dimensional input Tensor to rescaling them. After that, the elements of the n-dimensional output Tensor lies in the range 0, 1, and sum to 1. Softmax is defined as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch13.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>3) torch.nn.Softmax2d</td><td>It is used to apply SoftMax over features to each spatial location.</td></tr><tr><td>4) torch.nn.LogSoftmax</td><td>It is used to apply LogSoftmax function to an n-dimensional input Tensor. The LofSoftmax function can be defined as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch14.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>5) torch.nn.AdaptiveLogSoftmaxWithLoss</td><td>It is a strategy for training models with large output spaces. It is very effective when the label distribution is highly imbalanced</td></tr><tr><td>8.</td><td>Normalization layers</td><td></td></tr><tr><td>1) torch.nn.BatchNorm1d</td><td>It is used to apply batch normalization over a 2D or 3D inputs.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch15.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>2) torch.nn.BatchNorm2d</td><td>It is used to apply batch normalization over a 4D.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch16.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>3) torch.nn.BatchNorm3d</td><td>It is used to apply batch normalization over 5D inputs.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch17.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>4) torch.nn.GroupNorm</td><td>It is used to apply group normalization over a mini-batch of inputs.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch17.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>5) torch.nn.SyncBatchNorm</td><td>It is used to apply batch normalization over n-dimensional inputs.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch17.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>6) torch.nn.InstanceNorm1d</td><td>It is used to apply an instance normalization over a 3D input.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch17.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>7) torch.nn.InstanceNorm2d</td><td>It is used to apply an instance normalization over a 4D input.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch17.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>8) torch.nn.InstanceNorm3d</td><td>It is used to apply an instance normalization over a 5D input.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch17.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>9) torch.nn.LayerNorm</td><td>It is used to apply layer normalization over a mini-batch of inputs.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch17.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>10) torch.nn.LocalResponseNorm</td><td>It is used to apply local response normalization over an input signal which is composed of several input planes, where the channel occupies the second dimension.</td></tr><tr><td>9.</td><td>Recurrent layers</td><td></td></tr><tr><td>1) torch.nn.RNN</td><td>It is used to apply a multi-layer Elman RNN with tanh or ReLU non-linearity to an input sequence. Each layer computes the following function for each element in the input sequence:<br>h<sub>t</sub>=tanh(W<sub>ih</sub>&nbsp;x<sub>t</sub>+b<sub>ih</sub>+W<sub>hh</sub>&nbsp;t<sub>t-1</sub>+b<sub>hh</sub>)</td></tr><tr><td>2) torch.nn.LSTM</td><td>It is used to apply a multi-layer long short-term memory (LSTM) RNN to an input sequence. Each layer computes the following function for each element in the input sequence:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch18.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>3) torch.nn.GRU</td><td>It is used to apply a multi-layer gated recurrent unit (GRU) RNN to an input sequence. Each layer computes the following function for each element in the input sequence:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch19.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>4) torch.nn.RNNCell</td><td>It is used to apply an Elman RNN cell with tanh or ReLU non-linearity to an input sequence. Each layer computes the following function for each element in the input sequence:<br><em>h&#8217;=tanh(W<sub>ih</sub>&nbsp;x+b<sub>ih</sub>+W<sub>hh</sub>&nbsp;h+b<sub>hh</sub>)</em><br>ReLU is used in place of tanh</td></tr><tr><td>5) torch.nn.LSTMCell</td><td>It is used to apply a long short-term memory (LSTM) cell to an input sequence. Each layer computes the following function for each element in the input sequence:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch20.png\" alt=\"torch.nn in PyTorch\"><br>Where σ is the sigmoid function, and * is the Hadamard product.</td></tr><tr><td>6) torch.nn.GRUCell</td><td>It is used to apply a gated recurrent unit (GRU) cell to an input sequence. Each layer computes the following function for each element in the input sequence:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch21.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>10.</td><td>Linear layers</td><td></td></tr><tr><td>1) torch.nn.Identity</td><td>It is a placeholder identity operator which is argument-insensitive.</td></tr><tr><td>2) torch.nn.Linear</td><td>It is used to apply a linear transformation to the incoming data:<br>y=xA<sup>T</sup>+b</td></tr><tr><td>3) torch.nn.Bilinear</td><td>It is used to apply a bilinear transformation to the incoming data:<br>y=x<sub>1</sub>&nbsp;Ax<sub>2</sub>+b</td></tr><tr><td>11.</td><td>Dropout layers</td><td></td></tr><tr><td>1) torch.nn.Dropout</td><td>It is used for regularization and prevention of co-adaptation of neurons. A factor of<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch22.png\" alt=\"torch.nn in PyTorch\">during training scales the output. That means the module computes an identity function during the evaluation.</td></tr><tr><td>2) torch.nn.Dropout2d</td><td>If adjacent pixels within feature maps are correlated, then torch.nn.Dropout will not regularize the activations, and it will decrease the effective learning rate. In this case, torch.nn.Dropout2d() is used to promote independence between feature maps.</td></tr><tr><td>3) torch.nn.Dropout3d</td><td>If adjacent pixels within feature maps are correlated, then torch.nn.Dropout will not regularize the activations, and it will decrease the effective learning rate. In this case, torch.nn.Dropout2d () is used to promote independence between feature maps.</td></tr><tr><td>4) torch.nn.AlphaDropout</td><td>It is used to apply Alpha Dropout over the input. Alpha Dropout is a type of Dropout which maintains the self-normalizing property.</td></tr><tr><td>12.</td><td>Sparse layers</td><td></td></tr><tr><td>1) torch.nn.Embedding</td><td>It is used to store word embedding&#8217;s and retrieve them using indices. The input for the module is a list of indices, and the output is the corresponding word embedding.</td></tr><tr><td>2) torch.nn.EmbeddingBag</td><td>It is used to compute sums or mean of &#8216;bags&#8217; of embedding without instantiating the Intermediate embedding.</td></tr><tr><td>13.</td><td>Distance Function</td><td></td></tr><tr><td>1) torch.nn.CosineSimilarity</td><td>It will return the cosine similarity between x1 and x2, computed along dim.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch23.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>2) torch.nn.PairwiseDistance</td><td>It computes the batch-wise pairwise distance between vectors v1, v2 using the p-norm:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch24.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>14.</td><td>Loss function</td><td></td></tr><tr><td>1) torch.nn.L1Loss</td><td>It is used to a criterion which measures the mean absolute error between each element in the input x and target y. The unreduced loss can be described as:<br>&nbsp; &nbsp; &nbsp; l(x,y)=L={l<sub>1</sub>,&#8230;,l<sub>n</sub>&nbsp;},l<sub>n</sub>=|x<sub>n</sub>-y<sub>n</sub>&nbsp;|,<br>Where N is the batch size.</td></tr><tr><td>2) torch.nn.MSELoss</td><td>It is used to a criterion which measures the mean squared error between each element in the input x and target y. The unreduced loss can be described as:<br>l(x,y)=L={l<sub>1</sub>,&#8230;,l<sub>n</sub>&nbsp;},l<sub>n</sub>=(x<sub>n</sub>-y<sub>n</sub>)<sup>2</sup>,<br>Where N is the batch size.</td></tr><tr><td>3) torch.nn.CrossEntropyLoss</td><td>This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class. It is helpful when we train a classification problem with C classes.</td></tr><tr><td>4) torch.nn.CTCLoss</td><td>The Connectionist Temporal Classification loss calculates loss between a continuous time series and a target sequence.</td></tr><tr><td>5) torch.nn.NLLLoss</td><td>The Negative Log-Likelihood loss is used to train a classification problem with C classes.</td></tr><tr><td>6) torch.nn.PoissonNLLLoss</td><td>The Negative log-likelihood loss with the Poisson distribution of t<br>target~Poisson(input)loss(input,target)=input-target*log(target!)he target.</td></tr><tr><td>7) torch.nn.KLDivLoss</td><td>It is a useful distance measure for continuous distribution, and it is also useful when we perform direct regression over the space of continuous output distribution.</td></tr><tr><td>8) torch.nn.BCELoss</td><td>It is used to create a criterion which measures the Binary Cross Entropy between the target and the output. The unreduced loss can be described as:<br>l(x,y)=L={l<sub>1</sub>,&#8230;,l<sub>n</sub>&nbsp;},l<sub>n</sub>=-w<sub>n</sub>&nbsp;[y<sub>n</sub>*logx<sub>n</sub>+ (1-y<sub>n</sub>&nbsp;)*log(1-x<sub>n</sub>)],<br>Where N is the batch size.</td></tr><tr><td>9) torch.nn.BCEWithLogitsLoss</td><td>It combines a Sigmoid layer and the BCELoss in one single class. We can take advantage of the log-sum-exp trick for numerical stability by combining the operation into one layer.</td></tr><tr><td>10) torch.nn.MarginRankingLoss</td><td>It creates a criterion which measures the loss of given inputs x1, x2, two 1D mini-batch Tensors, and a label 1D mini-batch tensor y which contain 1 or -1. The loss function for each sample in the mini-batch is as follows:<br>&nbsp; &nbsp; &nbsp; loss(x,y)=max(0,-y*(x<sub>1</sub>-x<sub>2</sub>&nbsp;)+margin</td></tr><tr><td>11) torch.nn.HingeEmbeddingLoss</td><td>HingeEmbeddingLoss measures the loss of given an input tensor x and a labels tensor y which contain 1 or -1. It is used for measuring whether two inputs are similar or dissimilar. The loss function is defined as:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch25.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>12) torch.nn.MultiLabelMarginLoss</td><td>It is used to create a criterion which optimizes a multi-class multi-classification hinge loss between input x and output y.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch26.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>13) torch.nn.SmoothL1Loss</td><td>It is used to create a criterion which uses a squared term if the absolute element-wise error falls below 1 and an L1 term otherwise. It is also known as Huber loss:<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch27.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>14) torch.nn.SoftMarginLoss</td><td>It is used to create a criterion which optimizes the two-class classification logistic loss between input tensor x and target tensor y which contain 1 or -1.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch28.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>15) torch.nn.MultiLabelSoftMarginLoss</td><td>It is used to create a criterion which optimizes the multi-label one-versus-all loss based on max-entropy between input x and target y of size (N, C).<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch29.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>16) torch.nn.CosineEmbeddingLoss</td><td>It is used to create a criterion which measures the loss of given input tensors x1, x2 and a tensor label y with values 1 or -1. It is used for measuring whether two inputs are similar or dissimilar, using the cosine distance.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch30.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>17) torch.nn.MultiMarginLoss</td><td>It is used to create a criterion which optimizes a multi-class classification hinge loss between input x and output y.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch31.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>18) torch.nn.TripletMarginLoss</td><td>It is used to create a criterion which measures the triplet loss of given an input tensors x1, x2, x3 and a margin with a value greater than 0. It is used for measuring a relative similarity between samples. A triplet is composed of an anchor, positive example, and a negative example.<br>L(a,p,n)=max{d(a<sub>i</sub>,p<sub>i</sub>&nbsp;)-d(a<sub>i</sub>,n<sub>i</sub>&nbsp;)+margin,0}</td></tr><tr><td>15.</td><td>Vision layers</td><td></td></tr><tr><td>1) torch.nn.PixelShuffle</td><td>It is used to re-arrange the elements in a tensor of shape(*,C×r<sup>2</sup>,H,W) to a tensor of shape (*,C,H×r,W,r)</td></tr><tr><td>2) torch.nn.Upsample</td><td>It is used to upsample a given multi-channel 1D, 2D or 3D data.</td></tr><tr><td>3) torch.nn.upsamplingNearest2d</td><td>It is used to apply 2D nearest neighbor upsampling to an input signal which is composed with multiple input channel.</td></tr><tr><td>4) torch.nn.UpsamplingBilinear2d</td><td>It is used to apply 2D bilinear upsampling to an input signal which is composed with, multiple input channel.</td></tr><tr><td>16.</td><td>DataParallel layers(multi-GPU, distributed)</td><td></td></tr><tr><td>1) torch.nn.DataParallel</td><td>It is used to implement data parallelism at the module level.</td></tr><tr><td>2) torch.nn.DistributedDataParallel</td><td>It is used to implement distributed data parallelism, which is based on the torch.distributed package at the module level.</td></tr><tr><td>3) torch.nn.DistributedDataParallelCPU</td><td>It is used to implement distributed data parallelism for the CPU at the module level.</td></tr><tr><td>17.</td><td>Utilities</td><td></td></tr><tr><td>1) torch.nn.clip_grad_norm_</td><td>It is used to clip the gradient norm of an iterable of parameters.</td></tr><tr><td>2) torch.nn.clip_grad_value_</td><td>It is used to clip the gradient norm of an iterable of parameters at the specified value.</td></tr><tr><td>3) torch.nn.parameters_to_vector</td><td>It is used to convert parameters to one vector.</td></tr><tr><td>4) torch.nn.vector_to_parameters</td><td>It is used to convert one vector to the parameters.</td></tr><tr><td>5) torch.nn.weight_norm</td><td>It is used to apply weight normalization to a parameter in the given module.<br><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/torch_nn-in-pytorch32.png\" alt=\"torch.nn in PyTorch\"></td></tr><tr><td>6) torch.nn.remove_weight_norm</td><td>It is used to remove the weight normalization and re-parameterization from a module.</td></tr><tr><td>7) torch.nn.spectral_norm</td><td>It is used to apply spectral normalization to a parameter in the given module.</td></tr><tr><td>8) torch.nn.PackedSequence</td><td>It will use to hold the data and list of batch_sizes of a packed sequence.</td></tr><tr><td>9) torch.nn.pack_padded_sequence</td><td>It is used to pack a Tensor containing padded sequences of variable length.</td></tr><tr><td>10) torch.nn.pad_packed_sequence</td><td>It is used to pads a packed batch of variable-length sequences.</td></tr><tr><td>11) torch.nn.pad_sequence</td><td>It is used to pad a list of variable length Tensors with padding value.</td></tr><tr><td>12) torch.nn.pack_sequence</td><td>It is used to packs a list of variable length Tensors</td></tr><tr><td>13) torch.nn.remove_spectral_norm</td><td>It is used to removes the spectral normalization and re-parameterization from a module.</td></tr></tbody></table>\n","protected":false},"excerpt":{"rendered":"<p>PyTorch provides the torch.nn module to help us in creating and training of the neural network. We will first train the basic neural network on the MNIST dataset without using any features from these models. We will use only the basic PyTorch tensor functionality and then we will incrementally add one feature from torch.nn at [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2295,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1273"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1273"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1273/revisions"}],"predecessor-version":[{"id":2489,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1273/revisions/2489"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2295"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1273"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1273"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1273"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1274,"date":"2020-05-21T08:08:50","date_gmt":"2020-05-21T08:08:50","guid":{"rendered":"http://python3.foobrdigital.com/?p=1274"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"basics-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/basics-2/","title":{"rendered":"Basics"},"content":{"rendered":"\n<p>It is essential to understand all the basic concepts which are required to work with PyTorch. PyTorch is completely based on Tensors. Tensor has operations to perform. Apart from these, there are lots of other concepts which are required to perform the task.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<p>Now, understand all the concepts one by one to gain deep knowledge of PyTorch.</p>\n\n\n\n<h2>Matrices or Tensors</h2>\n\n\n\n<p>Tensors are the key components of Pytorch. We can say PyTorch is completely based on the Tensors. In mathematical term, a rectangular array of number is called a metrics. In&nbsp;<strong>the Numpy</strong>&nbsp;library, these metrics called&nbsp;<strong>ndaaray</strong>. In PyTorch, it is known as&nbsp;<strong>Tensor</strong>. A Tensor is an n-dimensional data container. For example, In PyTorch, 1d-Tensor is a vector, 2d-Tensor is a metrics, 3d- Tensor is a cube, and 4d-Tensor is a cube vector.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch2.jpg\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<p><strong>Above matrics represent 2D-Tensor with three rows and two columns.</strong></p>\n\n\n\n<p>There are three ways to create Tensor. Each one has a different way to create Tensor. Tensors are created as:</p>\n\n\n\n<ol><li>Create PyTorch Tensor an array</li><li>Create a Tensor with all ones and random number</li><li>Create Tensor from numpy array</li></ol>\n\n\n\n<p>Let see how Tensors are created</p>\n\n\n\n<h3>Create a PyTorch Tensor as an array</h3>\n\n\n\n<p>In this, you have first to define the array and then pass that array in your Tensor method of the torch as an argument.</p>\n\n\n\n<p><strong>For example</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \narr = &#91;&#91;3, 4], &#91;8, 5]]   \npyTensor = torch.Tensor(arr)  \nprint(pyTensor)      </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor (&#91;&#91;3., 4.],&#91;8., 5.]])\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch3.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<h3>Create a Tensor with the random number and all one</h3>\n\n\n\n<p>To create a random number Tensor, you have to use rand() method and to create a Tensor with all ones you have to use ones() of the torch. To generate random number one more method of the torch will be used with the rand, i.e., manual_seed with 0 parameters.</p>\n\n\n\n<p><strong>For example</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nones_t = torch.ones((2, 2))   \ntorch.manual_seed(0)  //to have same values for random generation  \nrand_t = torch.rand((2, 2))  \nprint(ones_t)  \nprint(rand_t)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>Tensor (&#91;&#91;1., 1.],&#91;1., 1.]])\ntensor (&#91;&#91;0.4963, 0.7682],&#91;0.0885, 0.1320]])</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch4.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<h3>Create a Tensor from numpy array</h3>\n\n\n\n<p>To create a Tensor from the numpy array, we have to create a numpy array. Once your numpy array is created, we have to pass it in from_numpy() as an argument. This method converts the numpy array to Tensor.</p>\n\n\n\n<p><strong>For example</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np1  \nnumpy_arr = np1.ones((2, 2))  \npyTensor = torch.from_numpy(numpy_arr)  \nnp1_arr_from_Tensor = pyTensor.numpy()  \nprint(np1_arr_from_Tensor)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91;&#91;1. 1.] &#91;1. 1.]]\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch5.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<h2>Tensors Operations</h2>\n\n\n\n<p>Tensors are similar to an array, so all the operation which we are performing on an array can also apply for Tensor.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch6.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<h3>1) Resizing a Tensor</h3>\n\n\n\n<p>We can resize the Tensor using the size property of Tensor. We use Tensor.view() for resizing a Tensor. Resizing a Tensor means the conversion of 2*2 dimensional Tensor to 4*1 or 4*4 dimensional Tensor to 16*1 and so on. To print the Tensor size, we use Tensor.size() method.</p>\n\n\n\n<p>Let see an example of resizing a Tensor.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \npyt_Tensor = torch.ones((2, 2))  \nprint(pyt_Tensor.size())        # shows the size of this Tensor  \npyt_Tensor = pyt_Tensor.view(4) # resizing 2x2 Tensor to 4x1  \nprint(pyt_Tensor)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>torch.Size (&#91;2, 2])\ntensor (&#91;1., 1., 1., 1.])</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch7.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<h3>2) Mathematical Operations</h3>\n\n\n\n<p>All the mathematical operation such as addition, subtraction, division, and multiplication can be performed on Tensor. The torch can do the mathematical operation. We use a torch.add(), torch.sub(), torch.mul() and torch.div() to perform operations on Tensors.</p>\n\n\n\n<p>Let see an example how mathematical operations are performed:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import numpy as np  \nimport torch  \nTensor_a = torch.ones((2, 2))  \nTensor_b = torch.ones((2, 2))  \nresult=Tensor_a+Tensor_b  \nresult1 = torch.add(Tensor_a, Tensor_b)     //another way of addidtion  \nTensor_a.add_(Tensor_b) // In-place addition  \nprint(result)  \nprint(result1)  \nprint(Tensor_a)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor (&#91;&#91;2., 2.], &#91;2., 2.]])\ntensor (&#91;&#91;2., 2.], &#91;2., 2.]])</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch8.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<h3>3) Mean and Standard deviation</h3>\n\n\n\n<p>We can calculate the standard deviation of Tensor either for one dimensional or multi-dimensional. In our mathematical calculation, we have first to calculate mean, and then we apply the following formula on the given data with mean.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch9.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<p>But in Tensor, we can use Tensor.mean() and Tensor.std() to find the deviation and mean of the given Tensor.</p>\n\n\n\n<p>Let see an example of how it performed.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \npyTensor = torch.Tensor(&#91;1, 2, 3, 4, 5])  \nmean = pyt_Tensor.mean(dim=0)        //if multiple rows then dim = 1  \nstd_dev = pyTensor.std(dim=0)       // if multiple rows then dim = 1  \nprint(mean)  \nprint(std_dev) </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor (3.)\ntensor (1.5811)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch10.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<h2>Variables and Gradient</h2>\n\n\n\n<p>The central class of the package is&nbsp;<strong>autograd.variable</strong>. Its main task is to wrap a&nbsp;<strong>Tensor</strong>. It supports nearly all of the operations defined on it. You can call&nbsp;<strong>.backword()</strong>&nbsp;and have all the gradient computed only when you finish your computation.</p>\n\n\n\n<p>Through&nbsp;<strong>.data</strong>&nbsp;attribute, you can access the row Tensor, while the gradient for this variable is accumulated into&nbsp;<strong>.grad</strong>.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch11.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<p>In Deep learning, gradient calculation is the key point. Variables are used to calculate the gradient in PyTorch. In simple words, variables are just a wrapper around Tensors with gradient calculation functionality.</p>\n\n\n\n<p>Below is the python code which is used to manage variables.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import numpy as np  \nimport torch  \nfrom torch.autograd import Variable  \npyt_var = Variable(torch.ones((2, 2)), requires_grad = True) </code></pre>\n\n\n\n<p>Above code behaves the same as Tensors, so that we can apply all operations in the same way.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch12.png\" alt=\"Basics of PyTorch\"/></figure>\n\n\n\n<p>Let see how we can calculate the gradient in PyTorch.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import numpy as np  \nimport torch  \nfrom torch.autograd import Variable    \n// let's consider the following equation  \n// y = 5(x + 1)^2  \nx = Variable (torch.ones(1), requires_grad = True)  \ny = 5 * (x + 1) ** 2        //implementing the equation.  \ny.backward()                // calculate gradient  \nprint(x.grad)                // get the gradient of variable x  \n# differentiating the above mentioned equation  \n// => 5(x + 1)^2 = 10(x + 1) = 10(2) = 20  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;20.])\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/basic-of-pytorch13.png\" alt=\"Basics of PyTorch\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>It is essential to understand all the basic concepts which are required to work with PyTorch. PyTorch is completely based on Tensors. Tensor has operations to perform. Apart from these, there are lots of other concepts which are required to perform the task. Now, understand all the concepts one by one to gain deep knowledge [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2296,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1274"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1274"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1274/revisions"}],"predecessor-version":[{"id":1302,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1274/revisions/1302"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2296"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1274"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1274"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1274"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1303,"date":"2020-05-21T08:10:16","date_gmt":"2020-05-21T08:10:16","guid":{"rendered":"http://python3.foobrdigital.com/?p=1303"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"tensorflow","status":"publish","type":"post","link":"https://python3.foobrdigital.com/tensorflow/","title":{"rendered":"TensorFlow"},"content":{"rendered":"\n<p>It is required to understand the difference between the&nbsp;<strong>PyTorch</strong>&nbsp;and&nbsp;<strong>TensorFlow</strong>&nbsp;for starting a new project. Libraries play a crucial role when developers decide to work in deep learning or machine learning researches. According to a survey, there are 1,616 ML developers and data scientists who are using PyTorch and 3.4 ML developers who are using TensorFlow.</p>\n\n\n\n<p><strong>We will compare both the frameworks based on the following factors:</strong></p>\n\n\n\n<h2>1) Origin</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/origin.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>PyTorch is a machine learning library which is based on Torch library.&nbsp;<strong>Facebook&#8217;s artificial intelligence research group</strong>&nbsp;developed it for application, such as deep learning and natural language processing. It is free and open-source software which is released under the&nbsp;<strong>Modified BSD license</strong>. Tensor flow is also an open-source machine learning, which was initially developed by&nbsp;<strong>Google</strong>.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>2) Features</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/features.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>PyTorch has several attracting features such as:</p>\n\n\n\n<ol><li>Native support for Python</li><li>Dynamic computation graphs</li><li>Supports for CUDA</li></ol>\n\n\n\n<p>These features ensure less time for running the code and increase in performance. On the other hand, TensorFlow has also distinguished and attracting features such as&nbsp;<strong>TensorBoard</strong>&nbsp;which will be a great option while visualizing a machine learning model. It also provides&nbsp;<strong>TensorFlow Serving</strong>, which is a specific&nbsp;<strong>grpc server</strong>&nbsp;which is used during the deployment during the production.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>3) Community</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/community.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>PyTorch has much lesser community than TensorFlow. TensorFlow is adopted by many researchers of various fields such as business organization, academics, etc. In TensorFlow, it is easier to find for resources or solution. There is a great number of tutorials, codes, as well as support in TensorFlow and PyTorch.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>4) Level of API</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/level-of-api.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>If we will talk about the&nbsp;<strong>API</strong>, then the TensorFlow is the best one because it provides both high and low-level&nbsp;<strong>APIs</strong>. PyTorch provides lower-level API which focuses on the direct work with array expression. PyTorch has gained great interest in the last year and becoming a preferred solution for academic research and application of deep learning, which requires optimizing custom expression.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>5) Speed</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/speed.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p><strong>PyTorch</strong>&nbsp;and&nbsp;<strong>TensorFlow</strong>&nbsp;are two most popular deep learning framework.&nbsp;<strong>PyTorch</strong>&nbsp;is suitable if we are working in our home, and we are implementing our first deep learning project. But&nbsp;<strong>TensorFlow</strong>&nbsp;is used if we are working in our office, and we have an excellent knowledge of deep learning projects. If we compare both&nbsp;<strong>PyTorch</strong>&nbsp;and&nbsp;<strong>TensorFlow</strong>&nbsp;with their speed, then both the framework provides a similar pace, which is fast and suitable for performance.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>6) Popularity</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/popularity.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>Based on popularity, TensorFlow is widely used rather than PyTorch. Every organization needs simple and readable architecture with the high performance of large dataset execution. PyTorch is younger than TensorFlow and has grown rapidly in popularity. PyTorch allows customization, whereas TensorFlow does not. TensorFlow has the most GitHub activity, Google searches, Medium articles, books on Amazon, and ArXiv articles. It is used by most of the developers and is listed in the most online job descriptions.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>7) Ramp-Up Time</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/ramp-up-time.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>PyTorch is a GPU enabled drop-in-replacement for NumPy which equipped higher-level functionality for building and training the deep neural network. If we are familiar with Python, NumPy, and deep learning abstraction, it makes PyTorch easy to learn. When we write TensorFlow code, it will first get &#8220;<strong>compile</strong>&#8221; into a graph by Python and then run by the TensorFlow execution engine. TensorFlow has a few extra concepts to learn, such as the graph, the session, placeholder, and variable scoping. The ramp-up time of TensorFlow is definitely longer than PyTorch.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>8) Coverage</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/coverage.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>TensorFlow natively supports certain operations such as flipping a tensor along a dimension, checking a tensor for Nan and infinity and Fast Fourier transforms. It also has the&nbsp;<strong>contrib package</strong>&nbsp;which is used for the creation of more model. It provides support for the use of the higher-level functionality and gives us a wide spectrum of options to work with.</p>\n\n\n\n<p>PyTorch still has fewer features implemented, but due to all the attention, it will be bridged real soon. PyTorch is not popular as TensorFlow among learners and freelancers.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>9) Deployment</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/deployment.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>Both the frameworks are easy to wrap in for small-scale server-side deployments. TensorFlow works well for&nbsp;<strong>mobile</strong>&nbsp;and&nbsp;<strong>embedded deployments</strong>. A non-trivial amount of work is required in TensorFlow for deploying it to&nbsp;<strong>Android</strong>&nbsp;and&nbsp;<strong>IOS</strong>. We don&#8217;t have to re-write the entire inference portion of our model in C++ or Java. PyTorch cannot be hot-swapped easily without bringing the service down, but TensorFlow can do that easily.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>10) Serialization</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/serialization.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>Loading and saving models are very simple with both the framework. PyTorch has a simple API which can pickle the entire class if we want or save all the weights of a model. In serialization, the main feature of TensorFlow is that the entire graph can be saved as a protocol buffer and includes parameters and operation as well. After that, the graph will be loaded in other supported language such as Java and C++. TensorFlow is critical for deployment stacks where Python is not an option. TensorFlow can be useful when you change the model source code, but it should be able to run old models.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>11) Graph Constructing and Debugging</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/graph-constructing-and-debugging.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>PyTorch has a dynamic nature of the entire process of creating a graph. The graphs can be constructed by interpretation of the line of code which corresponds to that particular aspect of the graph so that it is entirely built on run time.</p>\n\n\n\n<p>With TensorFlow, the graph construction is static and need to go through compilation. After that, it will run on the execution engine which we have mentioned previously.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>12) Visualization</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/visualization.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>Visualization plays an important role while we present any project in an organization. For visualizing machine learning models, TensorFlow has TensorBoard, which helps during training the model and spot the errors quickly. It is a real-time representation of the model&#8217;s graphs that does not only show the graphic representation but also shows the accuracy graphs in real-time. This feature is lacked in PyTorch.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>13) Architecture</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>If we will compare PyTorch and TensorFlow with their architecture, then PyTorch has a very simple architecture rather than TensorFlow. TensorFlow is not very easy to use even though it provides&nbsp;<strong>Keras</strong>&nbsp;as a framework which makes work easier. When we compared PyTorch with TensorFlow, then it has less readability.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>14) Dataset</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/dataset.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>PyTorch is usually used for low-performance models, and a large dataset, on the other hand, TensorFlow is used for high-performance models as well as the large dataset. TensorFlow plays a vital role in the execution of large dataset, which requires fast execution. PyTorch is much simpler but not in used because every organization has a large dataset for execution with high performance. PyTorch is used when we want to execute large dataset with low performance.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>15) Documentation</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/documentation.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>PyTorch and TensorFlow both are based on Python programming language. Python APIs are well documented, so it is typical to find the best one. There is one thing which makes TensorFlow best, which is that the PyTorch C library is mostly undocumented. However, this will only matters when writing a custom C extension and perhaps if contributing to the software overall.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>16) Device Management</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/device-management.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>In TensorFlow, device management is a breeze means we don&#8217;t have to specify anything because there are defaults are set well. In TensorFlow, if GPU is available, then it automatically assumes that we want to run on GPU. The downside of TensorFlow management is that it consumes all the memory on the available GPU even if only one is being used.</p>\n\n\n\n<p>On the other hand in PyTorch, even if&nbsp;<strong>CUDA</strong>&nbsp;is enabled although we must explicitly move everything on the device. The code needs more frequent checks for&nbsp;<strong>CUDA</strong>&nbsp;and more explicit device management.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>17) Custom Extensions</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/custom-extensions.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>Binding or building custom extensions which are written in C, C++, or CUDA is feasible with both frameworks. Of course, the TensorFlow need more boilerplate code, although cleaner that supports multiple types and devices.</p>\n\n\n\n<p>In PyTorch, we can simply write an interface and implementation for particular CPU and GPU versions.</p>\n\n\n\n<p>Compiling the custom extensions is straight-forward with both frameworks(PyTorch and TensorFlow). There is no need to download any headers or source code outside of the pip installation.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Conclusion</h2>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/conclusion.png\" alt=\"PyTorch vs. TensorFlow\"/></figure>\n\n\n\n<p>At the end of this, we found that PyTorch and TensorFlow are similar. PyTorch is very pythonic and very comfortable to work with. It has good Ramp-Up Time and documentation as well as it is much faster than TensorFlow. PyTorch has a smaller community as compared to TensorFlow, and some useful tools such as TensorBoard are missing, which make TensorFlow best as compare to PyTorch.</p>\n\n\n\n<p>We can use both frameworks as per our liking (what we would like to code) and according to our requirement.</p>\n\n\n\n<p>We conclude that PyTorch is best to use at home and TensorFlow is best to use at the office.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Comparison between PyTorch and TensorFlow</h2>\n\n\n\n<table><tbody><tr><th>S. No</th><th>Comparison Factors</th><th>Pass</th><th>Fail</th></tr><tr><td><strong>1.</strong></td><td>Features</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>2.</strong></td><td>Community</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>3.</strong></td><td>Level of API</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>4.</strong></td><td>Speed</td><td>PyTorch</td><td>TensorFlow</td></tr><tr><td><strong>5.</strong></td><td>Popularity</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>6.</strong></td><td>Ramp-Up Time</td><td>PyTorch</td><td>TensorFlow</td></tr><tr><td><strong>7.</strong></td><td>Coverage</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>8.</strong></td><td>Deployment</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>9.</strong></td><td>Serialization</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>10.</strong></td><td>Graph constructing and Debugging</td><td>PyTorch</td><td>TensorFlow</td></tr><tr><td><strong>11.</strong></td><td>Visualization</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>12.</strong></td><td>Architecture</td><td>PyTorch</td><td>TensorFlow</td></tr><tr><td><strong>13.</strong></td><td>Dataset</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>14.</strong></td><td>Documentation</td><td>PyTorch, TensorFlow</td><td></td></tr><tr><td><strong>15.</strong></td><td>Device Management</td><td>TensorFlow</td><td>PyTorch</td></tr><tr><td><strong>16.</strong></td><td>Custom Extension</td><td>PyTorch</td><td>TensorFlow</td></tr></tbody></table>\n\n\n\n<p></p>\n","protected":false},"excerpt":{"rendered":"<p>It is required to understand the difference between the&nbsp;PyTorch&nbsp;and&nbsp;TensorFlow&nbsp;for starting a new project. Libraries play a crucial role when developers decide to work in deep learning or machine learning researches. According to a survey, there are 1,616 ML developers and data scientists who are using PyTorch and 3.4 ML developers who are using TensorFlow. We [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2297,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1303"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1303"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1303/revisions"}],"predecessor-version":[{"id":2488,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1303/revisions/2488"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2297"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1303"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1303"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1303"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1304,"date":"2020-05-21T08:13:43","date_gmt":"2020-05-21T08:13:43","guid":{"rendered":"http://python3.foobrdigital.com/?p=1304"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"tensors","status":"publish","type":"post","link":"https://python3.foobrdigital.com/tensors/","title":{"rendered":"Tensors"},"content":{"rendered":"\n<p>Tensors are the key components of Pytorch. We can say PyTorch is wholly based on the Tensors. In mathematics, a rectangular array of number is called metrics. In NumPy library, these metrics called ndaaray. In PyTorch, it is known as Tensor. A tensor is an n-dimensional data container. For example, In PyTorch, 1d-tensor is a vector, 2d-tensor is a metrics, 3d- tensor is a cube, and 4d-tensor is a cube vector.</p>\n\n\n\n<p>Torch provides tensor computation with strong GPU acceleration. It is essential that we get familiar with the tensor data structure to work with PyTorch. It will serve as a fundamental prerequisite before neural network implementation.</p>\n\n\n\n<p>In Deep learning, Tensor is the key part, and we can see so many discussion around Tensor. Even it appears in the name of Google&#8217;s main machine learning library, i.e., TensorFlow.</p>\n\n\n\n<p>In this tutorial, we will discuss what tensors are and how to perform operations and to manipulate them in python with numpy.</p>\n\n\n\n<p><strong>&#8220;In the general case, an array of numbers arranged on a regular grid with a variable number of axes is known as a tensor.&#8221;</strong>Below is the diagram that describes the Tensor&#8217;s dimensions in a very efficient way.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-tensors.png\" alt=\"Tensors Introduction\"/></figure>\n\n\n\n<p>Now let&#8217;s get a little bit knowledge about the notation of Tensors</p>\n\n\n\n<p>The tensor notation is similar to the metrics notation. A capital letter represents the tensor, and the lower letter with subscript integer represents scalar values within the tensor.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-tensors2.jpg\" alt=\"Tensors Introduction\"/></figure>\n\n\n\n<p>In the field of Physics and Engineering, as a tool, tensor and tensor algebra widely used. We can say it is a set of techniques in machine learning in the operation and training of deep learning models can be described regarding tensors.</p>\n\n\n\n<h2>How to create Tensor?</h2>\n\n\n\n<p>There are three ways by which we can create the Tensor. Each one has a different way to createTensor and use a different method. Tensors are created as</p>\n\n\n\n<ol><li>Create Tensor from an array</li><li>Create Tensor with all ones and random number</li><li>Create Tensor from numpy array</li></ol>\n\n\n\n<p>Let see how Tensors are created</p>\n\n\n\n<h3>Create Tensor from an array</h3>\n\n\n\n<p>In this, you have first to define the array and then pass that array in your Tensor method of the torch as an argument.</p>\n\n\n\n<p><strong>For example</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>Import torch  \narr = &#91;&#91;3, 4], &#91;8, 5]]   \npytensor = torch.Tensor(arr)  \nprint(pytensor)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor (&#91;&#91;3., 4.],&#91;8., 5.]])\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-tensors3.png\" alt=\"Tensors Introduction\"/></figure>\n\n\n\n<h3>Create Tensor with the random number and all one</h3>\n\n\n\n<p>To create a random number tensor, we have to use method rand() and to create a tensor with all ones you have to use method ones () of the torch. To generate random number one more method of the torch will be used with rand, i.e., manual_seed with 0 parameters.</p>\n\n\n\n<p><strong>For example</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nones_t = torch.ones((2, 2))   \ntorch.manual_seed(0)  //to have same values for random generation  \nrand_t = torch.rand((2, 2))  \nprint(ones_t)  \nprint(rand_t)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;&#91;1., 1.],&#91;1., 1.]])\ntensor(&#91;&#91;0.4962, 0.7682],&#91;0.0885, 0.1320]])</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-tensors4.png\" alt=\"Tensors Introduction\"/></figure>\n\n\n\n<h3>Create a Tensor from numpy array</h3>\n\n\n\n<p>To create a tensor from the numpy array, we have to create a numpy array. Once your numpy array is created, we have to pass it in from_numpy() as an argument. This method converts the numpy array to tensor.</p>\n\n\n\n<p><strong>For example</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np1  \nnumpy_arr = np1.ones((2, 2))  \npytensor = torch.from_numpy(numpy_arr)  \nnp1_arr_from_tensor = pytensor.numpy()  \nprint(np1_arr_from_tensor)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91;&#91;1. 1.]&#91;1. 1.]]\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-tensors5.png\" alt=\"Tensors Introduction\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>Tensors are the key components of Pytorch. We can say PyTorch is wholly based on the Tensors. In mathematics, a rectangular array of number is called metrics. In NumPy library, these metrics called ndaaray. In PyTorch, it is known as Tensor. A tensor is an n-dimensional data container. For example, In PyTorch, 1d-tensor is a [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2298,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1304"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1304"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1304/revisions"}],"predecessor-version":[{"id":1319,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1304/revisions/1319"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2298"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1304"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1304"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1304"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1306,"date":"2020-05-21T08:17:31","date_gmt":"2020-05-21T08:17:31","guid":{"rendered":"http://python3.foobrdigital.com/?p=1306"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"one-dimensional","status":"publish","type":"post","link":"https://python3.foobrdigital.com/one-dimensional/","title":{"rendered":"One Dimensional"},"content":{"rendered":"\n<p>As we know,&nbsp;<strong>PyTorch</strong>&nbsp;has been embraced by&nbsp;<strong>Deep learning</strong>&nbsp;world for the ability to conveniently define neural network. Neural network is fundamentally structured to sensors, and PyTorch is also built around sensors. There tends to be a significant boost in performance. Vaguely a tensor is a generalization of matrices.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<p>1D-Tensor is similar to 1D- matrix. In one dimensional Tensor have only one row and one column which is known as vector. There is a zero-dimensional tensor also which is known as a scalar.</p>\n\n\n\n<p>Now we will discuss operations which are performed on tensors.</p>\n\n\n\n<p>We can use Google Colab also to write the code of Tensor. Accessing Google Colab is very simple. For Google Colab, There is no setup required. It runs entirely on the cloud.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors2.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<p>Google Colab is similar to Jupyter Notebook. Many packages come pre-install for us when using Google Colab. Unfortunately, the torch is not one of them, so we have first to install torch using&nbsp;<strong>!pip3 install torch</strong>&nbsp;command.</p>\n\n\n\n<p>Now, we will perform the operation on one-dimensional Tensor.</p>\n\n\n\n<h2>Creating one-dimensional Tensor</h2>\n\n\n\n<p>For creating a one-dimensional Tensor, we use the tensor property of torch library. To create a tensor, we use the torch.tensor() method.</p>\n\n\n\n<p><strong>Syntax of creating one dimensional tensor is as follows:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>n= torch.tensor(&#91;Tensor elements])  </code></pre>\n\n\n\n<p>Here, n is a variable of tensor type and tensor elements can be any integer or floating point number following with (,).</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nn=torch.tensor(&#91;1,2,3,4])  \nprint(n)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;1, 2, 3, 4])\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors3.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<h2>Checking data type of elements in Tensor</h2>\n\n\n\n<p>We can check the data type of the element which contains in Tensor. We use dtype() of Tensor to find the data type.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nn=torch.tensor (&#91;1.0, 2.0, 3.0])  \nprint (n.dtype)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>torch.float32\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors4.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<h2>Accessing of Tensor&#8217;s elements</h2>\n\n\n\n<p>We can access the elements of Tensor with the help of the index of that element. If we want to print all the elements of Tensor, then we can print the tensor variable. Like the one-dimensional metrics index, Tensor index also starts from 0.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nn=torch.tensor(&#91;1.0, 2.0, 3.0])  \nprint(n&#91;2]) </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(3.)\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors5.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<h2>Accessing of Tensor&#8217;s elements with the specified range</h2>\n\n\n\n<p>It is quite simple to access elements of specified range by passing the starting index or ending index of elements separated with a colon (:). It will skip starting index element and print elements till ending index.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nn=torch.tensor(&#91;1.0, 2.0, 3.0])  \nprint(n&#91;0:2])   </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor (2.0,3.0)\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors6.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<p>We have another example which prints all elements by skipping the starting index, which is initialized by us.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nn=torch.tensor (&#91;1.0, 2.0, 3.0])  \nprint(n&#91;0:])  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor (2.0,3.0)\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors7.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<h2>Creating of Floating Point Tensor using Integer elements</h2>\n\n\n\n<p>We can create a floating point Tensor using integer element. In this, we use FloatTensor property of torch is used.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nn=torch.FloatTensor(&#91;1,2,3,4,5,6,7])  \nprint(n)</code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;1., 2., 3., 4., 5., 6., 7.])\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors8.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<h2>Finding size of the Tensor</h2>\n\n\n\n<p>Just like one dimensional metrics, we can find the size of Tensor also. We use size() method of Tensor to get the size.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nn=torch.FloatTensor(&#91;1,2,3,4,5,6,7])  \nprint(n.size())  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>torch.Size(&#91;7])\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors9.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<h2>Change view of Tensor</h2>\n\n\n\n<p>Tensor has the property by which we can change the view of the Tensor. Changing view means if a tensor is one dimensional (one row and one column) and we want to change its view by six rows and one column.Changes can be done with the help of view() of Tensor. It is similar to the reshape () of an array.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nn=torch.FloatTensor(&#91;1,2,3,4,5,6])  \nprint(n)  \nn.view(6,1)    </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor (&#91;1., 2., 3., 4., 5., 6.])\ntensor(&#91;&#91;1.],\n        &#91;2.],\n        &#91;3.],\n        &#91;4.],\n        &#91;5.],\n        &#91;6.]])</code></pre>\n\n\n\n<p>Note: We can use other dimension also such as (3, 2) but it should be compatible with our original tensor elements.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors10.png\" alt=\"One Dimensional Tensors\"/></figure>\n\n\n\n<h2>Tensor using numpy array</h2>\n\n\n\n<p>We can also create Tensor using numpy array. We have to convert the numpy array into Tensor with the help of&nbsp;<strong>from_numpy ()</strong>&nbsp;of the torch. For this, we first have to initialize numpy and then create a numpy array.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np  \na=np.array(&#91;1,2,3,4,5,6])  \ntensorcon=torch.from_numpy(a)  \nprint(tensorcon)  \nprint(tensorcon.type())  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;1, 2, 3, 4, 5, 6])\ntorch.LongTensor\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-one-dimensional-tensors11.png\" alt=\"One Dimensional Tensors\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>As we know,&nbsp;PyTorch&nbsp;has been embraced by&nbsp;Deep learning&nbsp;world for the ability to conveniently define neural network. Neural network is fundamentally structured to sensors, and PyTorch is also built around sensors. There tends to be a significant boost in performance. Vaguely a tensor is a generalization of matrices. 1D-Tensor is similar to 1D- matrix. In one dimensional [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2299,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1306"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1306"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1306/revisions"}],"predecessor-version":[{"id":1326,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1306/revisions/1326"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2299"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1306"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1306"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1306"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1307,"date":"2020-05-21T08:20:28","date_gmt":"2020-05-21T08:20:28","guid":{"rendered":"http://python3.foobrdigital.com/?p=1307"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"vector-operations","status":"publish","type":"post","link":"https://python3.foobrdigital.com/vector-operations/","title":{"rendered":"Vector Operations"},"content":{"rendered":"\n<p>We know Tensor have different types of dimensions such as zero dimension, one dimension, and multi-dimensional. Vectors are a one-dimensional tensor, and to manipulate them several operations available. Vector operations are of different types such as mathematical operation, dot product, and linspace. Vectors play a vital role in deep learning.</p>\n\n\n\n<p>In deep learning neural network, we generate random point with the help of vectors or one-dimensional tensor. There are the following operations which are performed on the vector.</p>\n\n\n\n<h2>Mathematical Operations</h2>\n\n\n\n<p>We can add, subtract, multiply, and divide the tensor from another tensor. Following is the table of all mathematical operations which are performed on vectors with the expected output.</p>\n\n\n\n<table><tbody><tr><th>S. No.</th><th>Operation</th><th>Tensor A</th><th>Tensor B</th><th>Number</th><th>Syntax</th><th>Output</th></tr><tr><td>1</td><td>+</td><td>[1, 2, 3]</td><td>[4, 5, 6]</td><td>2</td><td>A+B</td><td>[5, 7, 9]</td></tr><tr><td>2</td><td>[1, 2, 3]</td><td>[4, 5, 6]</td><td>2</td><td>A+2</td><td>[3, 4, 5]</td></tr><tr><td>3</td><td>&#8211;</td><td>[1, 2, 3]</td><td>[4, 5, 6]</td><td>2</td><td>A-B</td><td>[-3, -3, -3]</td></tr><tr><td>4</td><td>[1, 2, 3]</td><td>[4, 5, 6]</td><td>2</td><td>B-2</td><td>[2, 3, 4]</td></tr><tr><td>5</td><td>*</td><td>[1, 2, 3]</td><td>[4, 5, 6]</td><td>2</td><td>A*B</td><td>[4, 10,18]</td></tr><tr><td>6</td><td>[1, 2, 3]</td><td>[4, 5, 6]</td><td>2</td><td>A*2</td><td>[2, 4, 6]</td></tr><tr><td>7</td><td>/</td><td>[1, 2, 3]</td><td>[4, 5, 6]</td><td>2</td><td>B/A</td><td>[4, 2, 2]</td></tr><tr><td>8</td><td>[1, 2, 3]</td><td>[4, 5, 6]</td><td>2</td><td>B/2</td><td>[2, 2, 3]</td></tr></tbody></table>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nA=torch.tensor(&#91;1,2,3])  \nB=torch.tensor(&#91;4,5,6])  \nA+B  \nA+2  \nA-B  \nB-2  \nA*B  \nA*2  \nB/A  \nB/2</code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;5, 7, 9])\ntensor(&#91;3, 4, 5])\ntensor(&#91;-3, -3, -3])\ntensor(&#91;2, 3, 4])\ntensor(&#91; 4, 10, 18])\ntensor(&#91;2, 4, 6])\ntensor(&#91;4, 2, 2])\ntensor(&#91;2, 2, 3])</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-vector-operation.png\" alt=\"Vector Operation\"/></figure>\n\n\n\n<h2>Dot Product and linspace</h2>\n\n\n\n<p>We can perform the dot product of two tensors also. We use the dot() method of the torch to calculate which provide the accurate or expected result. There is another vector operation, i.e., linspace. For linspace, we use the method linspace (). This method contains two parameters first is the starting number, and the second is the ending number.</p>\n\n\n\n<p>The output of this method is, it prints one hundred of equally spaced number from starting number to ending number.</p>\n\n\n\n<p>Note: We can explicitly specify a step size rather than resorting to the default by passing one more argument, which is step size at the end of the parameter list.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nt1= torch.tensor(&#91;1,2,3])  \nt2= torch.tensor(&#91;4,5,6])  \nDotProduct= torch.dot(t1,t2)  \nprint(DotProduct)  \ntorch.linspace(2,9)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(32)\ntensor(&#91;2.0000, 2.0707, 2.1414, 2.2121, 2.2828, 2.3535, 2.4242, 2.4949, 2.5657,\n        2.6364, 2.7071, 2.7778, 2.8485, 2.9192, 2.9899, 3.0606, 3.1313, 3.2020,\n        3.2727, 3.3434, 3.4141, 3.4848, 3.5556, 3.6263, 3.6970, 3.7677, 3.8384,\n        3.9091, 3.9798, 4.0505, 4.1212, 4.1919, 4.2626, 4.3333, 4.4040, 4.4747,\n        4.5455, 4.6162, 4.6869, 4.7576, 4.8283, 4.8990, 4.9697, 5.0404, 5.1111,\n        5.1818, 5.2525, 5.3232, 5.3939, 5.4646, 5.5354, 5.6061, 5.6768, 5.7475,\n        5.8182, 5.8889, 5.9596, 6.0303, 6.1010, 6.1717, 6.2424, 6.3131, 6.3838,\n        6.4545, 6.5253, 6.5960, 6.6667, 6.7374, 6.8081, 6.8788, 6.9495, 7.0202,\n        7.0909, 7.1616, 7.2323, 7.3030, 7.3737, 7.4444, 7.5152, 7.5859, 7.6566,\n        7.7273, 7.7980, 7.8687, 7.9394, 8.0101, 8.0808, 8.1515, 8.2222, 8.2929,\n        8.3636, 8.4343, 8.5051, 8.5758, 8.6465, 8.7172, 8.7879, 8.8586, 8.9293,\n        9.0000])</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-vector-operation2.png\" alt=\"Vector Operation\"/></figure>\n\n\n\n<h2>Plotting a function on the two-dimensional coordinate system</h2>\n\n\n\n<p>The linspace function can come in use when plotting a function on two-dimensional coordinate systems. For the x-axis, we create a land space from 0 to 10 in an interval of 2.5, and Y will be the function of each x value. For example, we can find the exponential of each x value for y.</p>\n\n\n\n<p>Now, we are plotting x and y data using&nbsp;<strong>Map plot lib</strong>&nbsp;library, which is a visualization library for data analysis.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nx=torch.linspace(0,10,100)  \ny=torch.exp(x)  \nplt.plot(x.numpy(),y.numpy())  \nplt.show()  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-vector-operation3.png\" alt=\"Vector Operation\"/></figure>\n\n\n\n<p>Note: For much smoother exponential we have to increase data in linspace. If it is 100 rather than 5, then the output will be smoother like that.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-vector-operation4.png\" alt=\"Vector Operation\"/></figure>\n\n\n\n<p>Note: We can plot the sin value of x rather than exponential value. So it will create a sine called a curve.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nx=torch.linspace(0,10,100)  \ny=torch.sin(x)  \nplt.plot(x.numpy(),y.numpy())  \nplt.show()</code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-vector-operation5.png\" alt=\"Vector Operation\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>We know Tensor have different types of dimensions such as zero dimension, one dimension, and multi-dimensional. Vectors are a one-dimensional tensor, and to manipulate them several operations available. Vector operations are of different types such as mathematical operation, dot product, and linspace. Vectors play a vital role in deep learning. In deep learning neural network, [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2300,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1307"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1307"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1307/revisions"}],"predecessor-version":[{"id":2487,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1307/revisions/2487"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2300"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1307"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1307"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1307"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1308,"date":"2020-05-21T08:23:24","date_gmt":"2020-05-21T08:23:24","guid":{"rendered":"http://python3.foobrdigital.com/?p=1308"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"two-dimensional","status":"publish","type":"post","link":"https://python3.foobrdigital.com/two-dimensional/","title":{"rendered":"Two Dimensional"},"content":{"rendered":"\n<p><strong>Two-dimensional</strong>&nbsp;tensor is similar to the two-dimensional metrics. A two-dimensional metrics have n number of rows and n number of columns. Similarly, two-dimensional tensor has n rows and n columns also.</p>\n\n\n\n<p>A two-dimensional tensor has the following representation</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor.png\" alt=\"Two Dimensional Tensor\"/></figure>\n\n\n\n<p>A gray scalar image is a two-dimensional matrix of pixels. Each pixel&#8217;s intensity denoted by a numeric value that ranges from 0 to 255 such that intensity value of 0 indicates no intensity something being completely black and 255 representing of maximum intensity something being completely white. We can store this two-dimensional grid of values.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor2.png\" alt=\"Two Dimensional Tensor\"/></figure>\n\n\n\n<h2>Creating two-dimensional tensor</h2>\n\n\n\n<p>For creating a two-dimensional tensor, you have first to create a one-dimensional tensor using arrange () method of the torch. This method contains two parameters of integer type. This method arranges the elements in tensor as per the given parameters. Once your one-dimensional tensor is created, then our next step is to change its view in two-dimensional form and store this view in the two-dimensional type of variable.</p>\n\n\n\n<p>Let see an example of creating a two dimensional tensor</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nx=torch.arange(0,9)  \nx  \ny=x.view(3,3)  \ny  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;0, 1, 2, 3, 4, 5, 6, 7, 8])\ntensor(&#91;&#91;0, 1, 2],\n        &#91;3, 4, 5],\n        &#91;6, 7, 8]])</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor3.png\" alt=\"Two Dimensional Tensor\"/></figure>\n\n\n\n<p><strong>Note:</strong>&nbsp;To check the dimension of tensor we have to use&nbsp;<strong>dim() method</strong>&nbsp;of tensor.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nx=torch.arange(0,9)  \nx  \ny=x.view(3,3)  \ny  \nx.dim()  \ny.dim()  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;0, 1, 2, 3, 4, 5, 6, 7, 8])\ntensor(&#91;&#91;0, 1, 2],\n        &#91;3, 4, 5],\n        &#91;6, 7, 8]])\n1\n2</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor4.png\" alt=\"Two Dimensional Tensor\"/></figure>\n\n\n\n<h2>Accessing two-dimensional tensor elements</h2>\n\n\n\n<p>Let see an example of two-dimensional tensor to understand how to access a particular element from two-dimensional tensor using index.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nx=torch.arange(0,9)  \nx  \ny=x.view(3,3)  \ny  \ny&#91;0,2] </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;0, 1, 2, 3, 4, 5, 6, 7, 8])\ntensor(&#91;&#91;0, 1, 2],\n        &#91;3, 4, 5],\n        &#91;6, 7, 8]])\ntensor(2)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor5.png\" alt=\"Two Dimensional Tensor\"/></figure>\n\n\n\n<h2>Tensors Multiplication</h2>\n\n\n\n<p>The multiplication is done in the same manner as metrics multiplication. Tensor multiplication is done with multiplying corresponding row with the corresponding column. Tensor multiplication plays a vital role in the deep learning model. Tensors can be one dimensional, two dimensional, three dimensional, and so on. Multiplication of tensor is done only with compatible size.</p>\n\n\n\n<p>Let see an example of Tensor Multiplication</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nmat_a=torch.tensor(&#91;1,3,5,7,9,2,4,6,8])  \nmat_a=mat_a.view(3,3)  \nmat_b=torch.tensor(&#91;1,3,5,7,9,2,4,6,8])  \nmat_b=mat_b.view(3,3)  \nmat_a  \nmat_b  \ntorch.matmul(mat_a,mat_b)# We can also usemat_a @ mat_b  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;&#91;1, 3, 5],\n        &#91;7, 9, 2],\n        &#91;4, 6, 8]])\ntensor(&#91;&#91;1, 3, 5],\n        &#91;7, 9, 2],\n        &#91;4, 6, 8]])\ntensor(&#91;&#91; 42,  60,  51],\n        &#91; 78, 114,  69],\n        &#91; 78, 114,  96]])\n﻿</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor6.png\" alt=\"Two Dimensional Tensor\"/></figure>\n\n\n\n<h2>Three Dimensional Tensor</h2>\n\n\n\n<p>Three-dimensional tensor is made with the help of view () method. A three-dimensional tensor has the following structure</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor7.png\" alt=\"Two Dimensional Tensor\"/></figure>\n\n\n\n<h2>Accessing element from 3D- Tensor</h2>\n\n\n\n<p>Accessing elements from the 3D-tensor is quite easy. It will be done using the index.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nx=torch.arange(18)  \ny=x.view(3, 2, 3)  \ny  \ny&#91;1,1,1]</code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;&#91;&#91; 0,  1,  2],\n         &#91; 3,  4,  5]],\n        &#91;&#91; 6,  7,  8],\n         &#91; 9, 10, 11]],\n        &#91;&#91;12, 13, 14],\n         &#91;15, 16, 17]]])\ntensor(10)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor8.png\" alt=\"Two Dimensional Tensor\"/></figure>\n\n\n\n<h2>Slicing of three-dimensional tensor</h2>\n\n\n\n<p>Segment slices are very similar to how we would slice a one-dimensional tensor. Slicing a tensor means to slice the elements of a tensor into a new tensor, or we can say slicing is a process of creating a new tensor by dividing a tensor.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Let we have a three dimensional tensor which contains elements from 0 to 17 and we want to slice the tensor from 6 to 11.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nx=torch.arange(18)  \ny=x.view(3,2,3)  \ny  \ny&#91;1, 0:2, 0:3]      # can also apply y&#91;1, :, :]   </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;&#91;&#91; 0,  1,  2],\n         &#91; 3,  4,  5]],\n        &#91;&#91; 6,  7,  8],\n         &#91; 9, 10, 11]],\n        &#91;&#91;12, 13, 14],\n         &#91;15, 16, 17]]])\ntensor(&#91;&#91; 6,  7,  8],\n&#91; 9, 10, 11]])</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-two-dimensional-tensor9.png\" alt=\"Two Dimensional Tensor\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>Two-dimensional&nbsp;tensor is similar to the two-dimensional metrics. A two-dimensional metrics have n number of rows and n number of columns. Similarly, two-dimensional tensor has n rows and n columns also. A two-dimensional tensor has the following representation A gray scalar image is a two-dimensional matrix of pixels. Each pixel&#8217;s intensity denoted by a numeric value [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2301,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1308"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1308"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1308/revisions"}],"predecessor-version":[{"id":2303,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1308/revisions/2303"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2301"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1308"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1308"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1308"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1310,"date":"2020-05-21T08:24:54","date_gmt":"2020-05-21T08:24:54","guid":{"rendered":"http://python3.foobrdigital.com/?p=1310"},"modified":"2020-12-16T16:59:05","modified_gmt":"2020-12-16T16:59:05","slug":"gradient","status":"publish","type":"post","link":"https://python3.foobrdigital.com/gradient/","title":{"rendered":"Gradient"},"content":{"rendered":"\n<p>In this section, we discuss the derivatives and how they can be applied on PyTorch. So let starts</p>\n\n\n\n<p><strong>The gradient</strong>&nbsp;is used to find the derivatives of the function. In mathematical terms, derivatives mean differentiation of a function partially and finding the value.</p>\n\n\n\n<p>Below is the diagram of how to calculate the derivative of a function.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/gradient-with-pytorch.jpg\" alt=\"Gradient with PyTorch\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/gradient-with-pytorch2.jpg\" alt=\"Gradient with PyTorch\"/></figure>\n\n\n\n<p>The work which we have done above in the diagram will do the same in PyTorch with gradient. There is the following step to find the derivative of the function.</p>\n\n\n\n<p>1. We have first to initialize the function (y=3x<sup>3</sup>&nbsp;+5x<sup>2</sup>+7x+1) for which we will calculate the derivatives.</p>\n\n\n\n<p>2. Next step is to set the value of the variable used in the function. The value of x is set in the following manner.</p>\n\n\n\n<ol><li>X=&nbsp;torch.tensor&nbsp;(2.0,&nbsp;requires_grad=True)&nbsp;&nbsp;</li></ol>\n\n\n\n<p>We typically require a gradient to find the derivative of the function.</p>\n\n\n\n<p>3. Next is to compute the derivative of the function simply by using backward () method.</p>\n\n\n\n<p>4. The last step is to access or print the value of the derivative using grad.</p>\n\n\n\n<p>Let see an example of finding derivative</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nx=torch.tensor(2.0, requires_grad=True)  \ny=8*x**4+3*x**3+7*x**2+6*x+3  \ny.backward()  \nx.grad  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(326.)\n</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/gradient-with-pytorch3.png\" alt=\"Gradient with PyTorch\"/></figure>\n\n\n\n<p><strong>Another example</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nx=torch.tensor(2.0, requires_grad=True)  \nz=torch.tensor(4.0, requires_grad=True)  \ny=x**2+z**3  \ny.backward()  \nx.grad  \nz.grad  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(4.)\ntensor(48.)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/gradient-with-pytorch4.png\" alt=\"Gradient with PyTorch\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>In this section, we discuss the derivatives and how they can be applied on PyTorch. So let starts The gradient&nbsp;is used to find the derivatives of the function. In mathematical terms, derivatives mean differentiation of a function partially and finding the value. Below is the diagram of how to calculate the derivative of a function. [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2302,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1310"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1310"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1310/revisions"}],"predecessor-version":[{"id":1329,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1310/revisions/1329"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2302"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1310"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1310"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1310"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1330,"date":"2020-05-21T08:27:12","date_gmt":"2020-05-21T08:27:12","guid":{"rendered":"http://python3.foobrdigital.com/?p=1330"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"linear-regression-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/linear-regression-2/","title":{"rendered":"Linear Regression"},"content":{"rendered":"\n<p><strong>Linear regression</strong>&nbsp;is a way to find the linear relationship between the dependent and independent variable by minimizing the distance.</p>\n\n\n\n<p>Linear regression is a supervised machine learning approach. This approach is used for classification of&nbsp;<strong>order discrete category</strong>. In this section, we will understand how to build a model by which a user can predict the relationship between the dependent and independent variable.</p>\n\n\n\n<p>In simple terms, we can say the relationship between both the variable, i.e.,&nbsp;<strong>independent</strong>&nbsp;or&nbsp;<strong>dependent</strong>, is known as&nbsp;<strong>linear</strong>. Suppose Y is the dependent and X is an independent variable, then the linear regression relationship of these two variables is</p>\n\n\n\n<p><strong>Y=AX+b</strong></p>\n\n\n\n<ul><li>A is the&nbsp;<strong>slope</strong>.</li><li>b is&nbsp;<strong>y-intercept</strong>.</li></ul>\n\n\n\n<p><strong>Initial State</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-linear-regression.png\" alt=\"Linear Regression\"/></figure>\n\n\n\n<p><strong>Final State</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-linear-regression2.png\" alt=\"Linear Regression\"/></figure>\n\n\n\n<p>There are three basic concepts which are essential to understand to create or learn basic linear model.</p>\n\n\n\n<h2>1. Model class</h2>\n\n\n\n<p>It is very typical to code everything and writes all the function when required, and it&#8217;s not our motive.</p>\n\n\n\n<p>It is always better to writing numeric optimization libraries rather than writing all the code and functions, but business value can also be increased if we built it on top of prewritten libraries to get things done. For this purpose, we use the implementation of the nn package of PyTorch. For this, we have first to create a single layer.</p>\n\n\n\n<h3>Linear layer use</h3>\n\n\n\n<p>Each linear module computes the output from the input, and for weight and bias, it holds its internal Tensor.</p>\n\n\n\n<p>There are several other standard modules. We will use a model class format, which has two main methods, which are as follows:</p>\n\n\n\n<ol><li><strong>Init:</strong>&nbsp;Used for defining a linear module.</li><li><strong>Forward:</strong>&nbsp;With the help of forwarding method predictions are made on the basis of that we will train our linear regression model</li></ol>\n\n\n\n<h2>2. Optimizer</h2>\n\n\n\n<p>The optimizer is one of the important concepts in PyTorch. It is used to optimize our weight to fit our model into the dataset. There are several optimization algorithms such as gradient descent and backpropagation which optimize our weight value and fit our model best.</p>\n\n\n\n<p>Various optimization algorithms are implemented by torch.optim package. To use torch.optim, you have to construct an optimizer object which will update the parameter based on the computer gradient and will hold the current state. The object is created as follows:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Optimizer=optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  \nOptimizer=optim.Adam(&#91;var1, var2], lr=0.0001))  </code></pre>\n\n\n\n<p>A&nbsp;<strong>step()</strong>&nbsp;method is implemented by all optimizer, which updates the parameters. There are two ways to use it</p>\n\n\n\n<h3>1) Optimizer.step()</h3>\n\n\n\n<p>This is very simple method and supported by many optimizers. After computing the gradients using backward () method, we can call the optimizer.step() function.</p>\n\n\n\n<h3>Example:</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>for input, target in dataset:  \n    optimizer.zero_grad()  \n    output=model(input)  \n    loss=loss_fn(output, target)  \n    loss.backward()       \n    optimizer.step()  </code></pre>\n\n\n\n<h3>2) Optimizer.step(closure)</h3>\n\n\n\n<p>There are some optimization algorithms such as&nbsp;<strong>LBFGS</strong>, and&nbsp;<strong>Conjugate Gradient</strong>&nbsp;needs to re-evaluate the function many times, so we have to pass it in a closure which allows them to recompute your model.</p>\n\n\n\n<p><strong>Example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>for input, target in dataset:  \ndef closure():  \n    optimizer.zero_grad()  \n    output = model(input)  \n    loss = loss_fn(output, target)  \n    loss.backward()  \n    return loss  \n    optimizer.step(closure)  </code></pre>\n\n\n\n<h2>Criterion</h2>\n\n\n\n<p>The criterion is our loss function, which is used to find loss. This function is used from the torch nn module.</p>\n\n\n\n<p><strong>Example:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>criterion = torch.nn.MSELoss(size_average = False)</code></pre>\n\n\n\n<h3>Functions and objects which are required</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Import torch\nFrom torch.autagrad import Variable</code></pre>\n\n\n\n<p>And we need to define some data and assign them to variables in the following way</p>\n\n\n\n<pre class=\"wp-block-code\"><code>xdata=Variable(torch.Tensor(&#91;&#91;1.0],&#91;2.0],&#91;3.0]]))  \nydata=Variable(torch.Tensor(&#91;&#91;2.0],&#91;4.0],&#91;6.0]]))  </code></pre>\n\n\n\n<p>Following is the code which gives us prediction for training a complete regression model. It&#8217;s just to understand how we implement the code and what function we used to train a regression model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch   \nfrom torch.autograd import Variable   \nxdata = Variable(torch.Tensor(&#91;&#91;1.0], &#91;2.0], &#91;3.0]]))  \nydata = Variable(torch.Tensor(&#91;&#91;2.0], &#91;4.0], &#91;6.0]]))   \nclass LRM(torch.nn.Module):  \n    def __init__(self):   \n        super(LRM, self).__init__()    \n        self.linear = torch.nn.Linear(1, 1)  \n    def forward(self, x):   \n        ypred = self.linear(x)    \n        return ypred    \nourmodel = LRM()  \ncriterion = torch.nn.MSELoss(size_average = False)   \noptimizer = torch.optim.SGD(ourmodel.parameters(), lr = 0.01)   \nfor epoch in range(500):   \n    predy = our_model(xdata)   \n    loss = criterion(predy, ydata)    \n    optimizer.zero_grad()   \n    loss.backward()       \n    optimizer.step()   \n    print('epoch {}, loss {}'.format(epoch, loss.item()))  \nnewvar = Variable(torch.Tensor(&#91;&#91;4.0]]))  \npredy = ourmodel(newvar)  \nprint(\"predict (after training)\", 4, our_model(newvar).data&#91;0]&#91;0])  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>epoch0,loss1.7771836519241333\nepoch1,loss1.0423388481140137\nepoch2,loss0.7115973830223083\nepoch3,loss0.5608030557632446\n.\n.\n.\n.\nepoch499,loss0.0003389564517419785\npredict (after training) 4 tensor(7.9788)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-linear-regression-output.png\" alt=\"Linear Regression\"/></figure>\n\n\n\n<p>There are the following concepts which are used to train a complete regression model</p>\n\n\n\n<ol><li>Making Predictions</li><li>Linear Class</li><li>Custom Modules</li><li>Creating Dataset</li><li>Loss Function</li><li>Gradient Descent</li><li>Mean squared error</li><li>Training</li></ol>\n\n\n\n<p>All the above points are essential to understand how a regression model will be trained.</p>\n","protected":false},"excerpt":{"rendered":"<p>Linear regression&nbsp;is a way to find the linear relationship between the dependent and independent variable by minimizing the distance. Linear regression is a supervised machine learning approach. This approach is used for classification of&nbsp;order discrete category. In this section, we will understand how to build a model by which a user can predict the relationship [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2249,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1330"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1330"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1330/revisions"}],"predecessor-version":[{"id":1334,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1330/revisions/1334"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2249"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1330"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1330"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1330"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1331,"date":"2020-05-21T08:29:04","date_gmt":"2020-05-21T08:29:04","guid":{"rendered":"http://python3.foobrdigital.com/?p=1331"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"prediction","status":"publish","type":"post","link":"https://python3.foobrdigital.com/prediction/","title":{"rendered":"Prediction"},"content":{"rendered":"\n<p>In this, we took a brief introduction to implement a machine learning based algorithm to train a linear model to fit a set of data points.</p>\n\n\n\n<p>For this purpose, there is no need to have any prior knowledge of deep learning. We will start with the discussion of&nbsp;<strong>supervised learning</strong>. We will discuss the notion of supervised learning and how it relates to it.</p>\n\n\n\n<h2>Machine Learning</h2>\n\n\n\n<p><strong>Machine learning</strong>&nbsp;is an application of AI. ML (Machine Learning) provides systems the ability to learn and improve with the help of experience automatically. ML focuses on the development of computer programs which can access data and use it for themselves to learn.</p>\n\n\n\n<p>The process of learning begins with data or observation, such as examples, instructions or direct experience, in order to look for patterns in data and make better decisions in the future based on the examples which we provide. Its aim is to allow the computers to learn automatically without human intervention and adjust actions accordingly.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-prediction-and-linear-class.png\" alt=\"Prediction and linear class\"/></figure>\n\n\n\n<h3>Supervised Learning</h3>\n\n\n\n<p>As the name indicates about the presence of a supervisor as a teacher. In supervised learning, we train or teach the machine using well-labeled data. Well labeled means few of the data is already tagged with the correct answer. After that, the machine is provided with a new set of data. Supervised learning algorithm analyses the training data and produces a correct outcome from labeled data.</p>\n\n\n\n<p><strong>Supervised learning is classified into two broad categories of algorithm:</strong></p>\n\n\n\n<ol><li><strong>Classification</strong>: A classification problem is a problem when the output variable or simply output is a category such as &#8220;red&#8221; or &#8220;blue&#8221; or &#8220;disease or no disease.&#8221;</li><li><strong>Regression</strong>: A regression problem is a problem when the output variable or simply output is a real or continuous value such as &#8220;salary&#8221; or &#8220;weight.&#8221;</li></ol>\n\n\n\n<h3>Unsupervised Learning</h3>\n\n\n\n<p>In unsupervised learning, the machine is trained using information which is neither classified nor labeled and allow the algorithm to act on that information without guidance. In unsupervised learning, the task is to group unsorted information according to similarities, differences, and patterns without any prior training of data.</p>\n\n\n\n<p>There is no supervisor, which means no training will be given to the machine. So, the machine is restricted to find the hidden structure by itself.</p>\n\n\n\n<p><strong>Unsupervised learning is classified into two broad categories of algorithm:</strong></p>\n\n\n\n<ul><li><strong>Clustering</strong>: A clustering problem is a problem where we have to discover the inherent groupings in the data. Such as grouping students by course or age behavior.</li><li><strong>Association</strong>: An association problem is a problem where we have to discover rules which describe a large portion of our data, such as people who buy apple also want to buy a banana.</li></ul>\n\n\n\n<h2>Making Prediction (Creating Data Model)</h2>\n\n\n\n<p>Making a prediction is the initial step of making a linear regression model. In a linear regression model, we use supervised learning because regression is its second broad category. So the learner is trained and makes use of data sets associated with labeled features which define the meaning of our training data.</p>\n\n\n\n<p>The learner is able to predict a corresponding output before giving the newly input data to the machine.</p>\n\n\n\n<h3>Steps to find the prediction</h3>\n\n\n\n<ul><li>The first step is to install the torch and import it to work with it.</li><li>Next step is to initialize the variable c and c to know the equation of a line.</li><li>Initialize the equation of line such that y=w*x + b, here w is slop and b is the bias term, and y is the prediction.</li><li>Prediction is calculated inside the forward () method.</li></ul>\n\n\n\n<p>Let see an example to understand how prediction is made in linear regression.</p>\n\n\n\n<p><strong>For single data</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nb=torch.tensor(3.0,requires_grad=True)  \nc=torch.tensor(1.0,requires_grad=True)  \ndef forward(x):  \n       y=b*x+c  \n       return y  \nx=torch.tensor(&#91;4.0])  \nforward(x)  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;13.], grad_fn=&lt;AddBackward0>)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-prediction-and-linear-class2.png\" alt=\"Prediction and linear class\"/></figure>\n\n\n\n<p><strong>For multiple data</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nb=torch.tensor(3.0,requires_grad=True)  \nc=torch.tensor(1.0,requires_grad=True)  \ndef forward(x):  \n       y=b*x+c  \n       return y  \nx=torch.tensor(&#91;&#91;4.0],&#91;5.0],&#91;6.0]])  \nforward(x) </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>tensor(&#91;&#91;13.],\n        &#91;16.],\n        &#91;19.]], grad_fn=&lt;AddBackward0>)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-prediction-and-linear-class3.png\" alt=\"Prediction and linear class\"/></figure>\n\n\n\n<h2>Prediction using linear class</h2>\n\n\n\n<p>There is another standard way of binding prediction. For this, we have to import the linear class of torch.nn package. In this, we use manual_seed() method to generate random numbers. When we are creating a model with linear class, it will be given random number values for the linear class, which makes sense since the recall.</p>\n\n\n\n<p>Let see an example of how prediction is made with the model and manual_seed() method.</p>\n\n\n\n<p><strong>For single data</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nfrom torch.nn import Linear  \ntorch.manual_seed(1)  \nmodel=Linear(in_features=1,out_features=1)  \nprint(model.bias,model.weight)  \nx=torch.tensor(&#91;2.0])  \nprint(model(x))  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>&lt;torch._C.Generator object at 0x000001FA018DB2B0>\nParameter containing:\ntensor(&#91;-0.4414], requires_grad=True) Parameter containing:\ntensor(&#91;&#91;0.5153]], requires_grad=True)\ntensor(&#91;0.5891], grad_fn=&lt;AddBackward0>)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-prediction-and-linear-class4.png\" alt=\"Prediction and linear class\"/></figure>\n\n\n\n<p><strong>For multiple data</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nfrom torch.nn import Linear  \ntorch.manual_seed(1)  \nmodel=Linear(in_features=1,out_features=1)  \nprint(model.bias,model.weight)  \nx=torch.tensor(&#91;&#91;2.0],&#91;4.0],&#91;6.0]])  \nprint(model(x))</code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>&lt;torch._C.Generator object at 0x00000210A74ED2B0>\nParameter containing:\ntensor(&#91;-0.4414], requires_grad=True) Parameter containing:\ntensor(&#91;&#91;0.5153]], requires_grad=True)\ntensor(&#91;&#91;0.5891],\n        &#91;1.6197],\n        &#91;2.6502]], grad_fn=&lt;AddmmBackward>)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-prediction-and-linear-class5.png\" alt=\"Prediction and linear class\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>In this, we took a brief introduction to implement a machine learning based algorithm to train a linear model to fit a set of data points. For this purpose, there is no need to have any prior knowledge of deep learning. We will start with the discussion of&nbsp;supervised learning. We will discuss the notion of [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2250,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1331"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1331"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1331/revisions"}],"predecessor-version":[{"id":1335,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1331/revisions/1335"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2250"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1331"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1331"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1331"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1332,"date":"2020-05-21T08:30:26","date_gmt":"2020-05-21T08:30:26","guid":{"rendered":"http://python3.foobrdigital.com/?p=1332"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"custom-module","status":"publish","type":"post","link":"https://python3.foobrdigital.com/custom-module/","title":{"rendered":"Custom Module"},"content":{"rendered":"\n<p>There is another way to find the prediction. In the previous section, we find the prediction using forward () and by implementing a linear model. This method is very efficient and reliable. It is easy to understand and implement.</p>\n\n\n\n<p>In&nbsp;<strong>the Custom Module</strong>, we create a customize module with class, and it&#8217;s init() and forward() method and model. The init() method is used to initialize the new instances of the class. In this init() method the first argument is self, which indicates the instance of the class the object that&#8217;s yet to be initialized and after itself, we can add additional arguments.</p>\n\n\n\n<p>Next parameter is to initialize the instance of the linear model. In our previous section initializing a linear model requires input size, as well as output size, equals to 1 but in the custom module, we pass input size and output size variable without passing its default value.</p>\n\n\n\n<p>In this, it is required to import the nn package of the torch. In this, we use&nbsp;<strong>inheritance</strong>&nbsp;such that this subclass will leverage code from our base class and in the module.</p>\n\n\n\n<p>The module itself will typically act as a base class for all neural network modules. After that, we create a model through which we make a prediction.</p>\n\n\n\n<p>Let see an example how prediction is done by creating custom module:</p>\n\n\n\n<p><strong>For single data</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport torch.nn as nn  \nclass LinearRegression(nn.Module):  \n    def __init__(self,input_size, output_size):  \n        super().__init__()  \n        self.linear=nn.Linear(input_size,output_size)  \n    def forward(self,x):  \n        pred=self.linear(x)  \n        return pred  \ntorch.manual_seed(1)  \nmodel=LinearRegression(1,1)  \nx=torch.tensor(&#91;1.0])  \nprint(model.forward(x))  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>&lt;torch._C.Generator object at 0x000001B9B6C4E2B0>\ntensor(&#91;0.0739], grad_fn=&lt;AddBackward0>)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-custom-module.png\" alt=\"Custom Module (Creating Data Model)\"/></figure>\n\n\n\n<p><strong>For multiple data</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport torch.nn as nn  \nclass LinearRegression(nn.Module):  \n    def __init__(self,input_size, output_size):  \n        super().__init__()  \n        self.linear=nn.Linear(input_size,output_size)  \n    def forward(self,x):  \n        pred=self.linear(x)  \n        return pred  \ntorch.manual_seed(1)  \nmodel=LinearRegression(1,1)  \nx=torch.tensor(&#91;&#91;1.0],&#91;2.0],&#91;3.0]])  \nprint(model.forward(x))</code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>&lt;torch._C.Generator object at 0x000001B9B6C4E2B0>\ntensor(&#91;&#91;0.0739],\n        &#91;0.5891],\n        &#91;1.1044]], grad_fn=&lt;AddmmBackward>)</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-custom-module2.png\" alt=\"Custom Module (Creating Data Model)\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>There is another way to find the prediction. In the previous section, we find the prediction using forward () and by implementing a linear model. This method is very efficient and reliable. It is easy to understand and implement. In&nbsp;the Custom Module, we create a customize module with class, and it&#8217;s init() and forward() method [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2251,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1332"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1332"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1332/revisions"}],"predecessor-version":[{"id":1336,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1332/revisions/1336"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2251"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1332"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1332"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1332"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1333,"date":"2020-05-21T08:31:06","date_gmt":"2020-05-21T08:31:06","guid":{"rendered":"http://python3.foobrdigital.com/?p=1333"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"loss-function","status":"publish","type":"post","link":"https://python3.foobrdigital.com/loss-function/","title":{"rendered":"Loss Function"},"content":{"rendered":"\n<p>In the previous topic, we saw that the line is not correctly fitted to our data. To make it best fit, we will update its parameters using gradient descent, but before this, it requires you to know about the loss function.</p>\n\n\n\n<p>So, our goal is to find the parameters of a line that will fit this data well. In our previous example, the linear function will initially assign random weight and bias parameter to our line with the following parameter.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<p>This line does not represent our data well. We need some optimization algorithm that will adjust these parameters based on the total error until we end up with a line containing suitable parameters.</p>\n\n\n\n<p>Now, how do we determine these parameters?</p>\n\n\n\n<p>For a good understanding, we limit our discussion to a single data point.</p>\n\n\n\n<p>The error is determined by subtracting the prediction at that point from the actual y value.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function2.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<p>The closer the prediction is to the value, the smaller the error. The prediction as you already know can be written as</p>\n\n\n\n<pre class=\"wp-block-preformatted\">Ax<sub>1</sub>+b\n</pre>\n\n\n\n<p>However, we are dealing with a single dot. So that an infinite amount of line can be drawn through it. For this, we remove the bias. Removing this extra degree of freedom for now, and we cancel it out by fixing the bias value zero.</p>\n\n\n\n<pre class=\"wp-block-preformatted\">(y-y^)<sup>2</sup>\n(y-(Ax+b))<sup>2</sup>\n(y-(Ax+0))<sup>2</sup>\n(y-Ax)<sup>2</sup>\n</pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function3.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<p>Now, whatever line that we are dealing with the optimal line will have a weight that will reduce this error as close to zero as possible. Now, we are dealing with the point (-3, 3) and for this loss, the function will translate to</p>\n\n\n\n<pre class=\"wp-block-preformatted\">Loss=(3-A(-3))<sup>2</sup>\nLoss=(3+3A)<sup>2</sup>\n</pre>\n\n\n\n<p>Now, we create a table and try out the different value of A and see which one gives us the smallest error</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function4.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function5.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function6.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function7.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function8.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<p>We have plot different error values for different weight in my plot level for visualization purpose.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-loss-function9.png\" alt=\"Loss Function\"/></figure>\n\n\n\n<p>The absolute minimum, in this case, corresponds to the weight of negative one now, that we know how to evaluate the error corresponding to our linear equation.</p>\n","protected":false},"excerpt":{"rendered":"<p>In the previous topic, we saw that the line is not correctly fitted to our data. To make it best fit, we will update its parameters using gradient descent, but before this, it requires you to know about the loss function. So, our goal is to find the parameters of a line that will fit [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2252,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1333"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1333"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1333/revisions"}],"predecessor-version":[{"id":2486,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1333/revisions/2486"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2252"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1333"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1333"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1333"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1338,"date":"2020-05-21T08:32:49","date_gmt":"2020-05-21T08:32:49","guid":{"rendered":"http://python3.foobrdigital.com/?p=1338"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"gradient-descent","status":"publish","type":"post","link":"https://python3.foobrdigital.com/gradient-descent/","title":{"rendered":"Gradient Descent"},"content":{"rendered":"\n<p>Our biggest question is, how we train a model to determine the weight parameters which will minimize our error function. Let starts how gradient descent help us to train our model.</p>\n\n\n\n<p>First, the linear model will begin with a random initial parameter recall when we initialize the model with the linear function. It indeed gave us a random initial parameter.</p>\n\n\n\n<p>Let&#8217;s ignore the bias value for now and based on the error associated with this initial parameter A. Our motive is to move in the direction that gives us the smaller error.</p>\n\n\n\n<p>If we take the gradient of error function the derivatives of the slope of the tangent at the current value that we met, this derivative will take us in the direction of the highest error.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Loss=(3+3A)2\nf' (A)=18(A+1)\n</code></pre>\n\n\n\n<p>So, we move it the negative direction of the gradient, which will take us in the direction of the lowest error. We take current to weight, and we subtract the derivatives of that function at that same point.<br></p>\n\n\n\n<pre class=\"wp-block-code\"><code>A1=A0-f'(A)  </code></pre>\n\n\n\n<p>It will take us in the direction of the least error.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-gradient-descent.png\" alt=\"Gradient Descent\"/></figure>\n\n\n\n<p>In a summarized way, first, we have to compute the derivatives of the loss function and then submission in the current weight value of the line. Whatever the weight maybe, they will give you the gradient value. This gradient value is then subtracted from the current weight A0, to give the new updated weight A1. The new weight should result in a smaller error than the previous one. We will do that iteratively until we obtain the optimal parameter for our line model to fit the data.</p>\n\n\n\n<p>We are descending with the gradient, however, to ensure optimal results. One should descend in minimal steps. As such, we will multiply the gradient by a minimal number known as the&nbsp;<strong><em>learning rate</em></strong>. The value of the learning rate is empirical. Although a good standard starting value tends to be one over 10 or 1 over 100, the learning rate needs to be sufficiently small since as the line adjusting itself you never wanted to move drastically in one direction as that can cause for unwanted divergent behavior.</p>\n\n\n\n<p>In this, we will learn to adjust the earning rate based on empirical results, and we will code a gradient descent algorithm later but follow through with our gradient descent example let&#8217;s refer to a demonstration on excel to visualize the effect of gradient descent.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-gradient-descent2.png\" alt=\"Gradient Descent\"/></figure>\n\n\n\n<p>We will implement it later in our code.</p>\n","protected":false},"excerpt":{"rendered":"<p>Our biggest question is, how we train a model to determine the weight parameters which will minimize our error function. Let starts how gradient descent help us to train our model. First, the linear model will begin with a random initial parameter recall when we initialize the model with the linear function. It indeed gave [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2253,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1338"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1338"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1338/revisions"}],"predecessor-version":[{"id":1343,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1338/revisions/1343"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2253"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1338"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1338"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1338"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1339,"date":"2020-05-21T08:33:29","date_gmt":"2020-05-21T08:33:29","guid":{"rendered":"http://python3.foobrdigital.com/?p=1339"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"mean-squared-error","status":"publish","type":"post","link":"https://python3.foobrdigital.com/mean-squared-error/","title":{"rendered":"Mean Squared Error"},"content":{"rendered":"\n<p><strong>Mean Squared Error</strong>&nbsp;is calculated in much the same way as the general loss equation from earlier. We will consider the bias value as well since that is also a parameter that needs to be updated during the training process.</p>\n\n\n\n<p><strong>(y-Ax+b)<sup>2</sup></strong></p>\n\n\n\n<p>The mean squared error is best explained with an illustration.</p>\n\n\n\n<p>Suppose we have a set of values and we start by drawing some regression line parameter sized by a random set of weight and bias value as before.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-mean-squared-error.png\" alt=\"Mean Squared Error\"/></figure>\n\n\n\n<p>The error corresponds to how far the actual value is from the predicted value &#8211; the actual distance between them.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-mean-squared-error2.png\" alt=\"Mean Squared Error\"/></figure>\n\n\n\n<p>For each point, the error is calculated by comparing the predicted values which are made by our line model with the actual value using the following formula</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-mean-squared-error3.png\" alt=\"Mean Squared Error\"/></figure>\n\n\n\n<p>Every point is associated with an error, which means we have to do the summation of the error for each point. We know the prediction can be rewritten as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-mean-squared-error4.png\" alt=\"Mean Squared Error\"/></figure>\n\n\n\n<p>As we are calculating the mean squared error, we have to take the average by dividing by the no of data points. Now mentioned before the gradient of the error function should take us in the direction of the greatest increase in error.</p>\n\n\n\n<p>Moving towards the negative of the gradient of our cost function, we move in the direction of the smallest error. We will use this gradient as a compass to always take us in downhill. In gradient descent, we ignore the presence of bias, but for the error, both parameters A and b are required to define.</p>\n\n\n\n<p>Now, what we do next we will calculate the partially derivatives for each and as before we start with any A and b value pair.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-mean-squared-error5.png\" alt=\"Mean Squared Error\"/></figure>\n\n\n\n<p>We use a gradient descent algorithm to update A and b in the direction of least error based on two partial derivatives which are mentioned above. For every single iteration, the new weight is equal to the</p>\n\n\n\n<p><strong>A<sub>1</sub>=A<sub>0</sub>-∝ f'(A)</strong></p>\n\n\n\n<p>And the new bias value is equal to</p>\n\n\n\n<p><strong>b<sub>1</sub>=b<sub>0</sub>-∝ f'(b)</strong></p>\n\n\n\n<p>The main idea for writing the code, i.e., we start with some random model with a random set of weight and bias value parameters. This random model will tend to have a large error function, a large cost function, and we then use gradient descent to update the weight of our model in the direction of the least error. Minimizing that error to return an optimized result.</p>\n","protected":false},"excerpt":{"rendered":"<p>Mean Squared Error&nbsp;is calculated in much the same way as the general loss equation from earlier. We will consider the bias value as well since that is also a parameter that needs to be updated during the training process. (y-Ax+b)2 The mean squared error is best explained with an illustration. Suppose we have a set [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2254,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1339"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1339"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1339/revisions"}],"predecessor-version":[{"id":1344,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1339/revisions/1344"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2254"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1339"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1339"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1339"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1340,"date":"2020-05-21T08:35:02","date_gmt":"2020-05-21T08:35:02","guid":{"rendered":"http://python3.foobrdigital.com/?p=1340"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"training","status":"publish","type":"post","link":"https://python3.foobrdigital.com/training/","title":{"rendered":"Training"},"content":{"rendered":"\n<p>We plotted our linear model given the random parameters that were assigned to it. We found that it does not fit our data well. What we have to do. We need to train this model so that the model has the optimal weight and bias parameters and fit this data.</p>\n\n\n\n<p><strong>There are the following steps to train a model:</strong></p>\n\n\n\n<p><strong>Step 1</strong></p>\n\n\n\n<p>Our first step is to specify the loss function, which we intend to minimize. PyTorch provides a very efficient way to specify the lost function. PyTorch provides MSELoss() function, known as mean squared loss, to calculate loss as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>criterion=nn.MSELoss()  </code></pre>\n\n\n\n<p><strong>Step 2</strong></p>\n\n\n\n<p>Now, our next step is to update our parameters. For this purpose, we specify the optimizer that uses the gradient descent algorithm. We use SGD() function known as stochastic gradient descent for optimization. SGD minimizes the total loss one sample at a time and typically reaches convergence much faster as it will frequently update the weight of our model within the same sample size.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>optimizer=torch.optim.SGD(model.parameters(),lr=0.01)   </code></pre>\n\n\n\n<p>Here, lr stands for learning rate, which is initially set to 0.01.</p>\n\n\n\n<p><strong>Step 3</strong></p>\n\n\n\n<p>We will train our model for a specified number of epochs (We calculated the error function and backpropagated the gradient descent of this error function to update the weight).</p>\n\n\n\n<pre class=\"wp-block-code\"><code>epochs=100  </code></pre>\n\n\n\n<p>And now, for every epoch, we have to minimize the error of our model system. The error is simply a comparison between the prediction made by the model and the actual values.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Losses=&#91;]  \nFor i in range (epochs):  \n    ypred=model.forward(x)  #Prediction of y  \n    loss=criterion(ypred,y) #Find loss  \n    losses.append()     # Add loss in list   \n    optimizer.zero_grad() # Set the gradient to zero  \n    loss.backward() #To compute derivatives   \n    optimizer.step()    # Update the parameters   </code></pre>\n\n\n\n<p><strong>Step 4</strong></p>\n\n\n\n<p>Now, at last, we plot our new linear model by simply calling plotfit () method.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plotfit('Trained Model')  </code></pre>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete Code</h2>\n\n\n\n<p><strong>Program</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport torch.nn as nn  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nX=torch.randn(100,1)*10  \ny=X+3*torch.randn(100,1)  \nplt.plot(X.numpy(),y.numpy(),'o')  \nplt.ylabel('y')  \nplt.xlabel('x')  \nclass LR(nn.Module):  \n    def __init__(self,input_size,output_size):  \n        super().__init__()  \n        self.linear=nn.Linear(input_size,output_size)  \n    def forward(self,x):  \n        pred=self.linear(X)  \n        return pred   \ntorch.manual_seed(1)    #For consistency of random result   \nmodel=LR(1,1)  \ncriterion=nn.MSELoss()  #Using Loss Function  \noptimizer=torch.optim.SGD(model.parameters(),lr=0.01)  #Using optimizer which uses GD algorithm  \nprint(model)  \n&#91;a,b]=model.parameters()    #Unpacking of parameters  \nepochs=100  \nlosses=&#91;]  \nfor i in range(epochs):  \n    ypred=model.forward(X)  \n    loss=criterion(ypred,y)  \n    print(\"epoch:\",i,\"loss:\",loss.item())  \n    losses.append(loss)  \n    optimizer.zero_grad()  \n    loss.backward()  \n    optimizer.step()  \ndefgrtparameters():  \n       return(a&#91;0]&#91;0].item(),b&#91;0].item())  \ndefplotfit(title):  \n    plt.title=title  \n    a1,b1=grtparameters()  \n    x1=np.array(&#91;-30,30])  \n    y1=a1*x1+b1  \n    plt.plot(x1,y1,'r')  \n    plt.scatter(X,y)  \n    plt.show()  \nplotfit('Trained Model')  </code></pre>\n\n\n\n<p><strong>Output:</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-training-of-linear-model.png\" alt=\"Training of Linear Model\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-training-of-linear-model2.png\" alt=\"Training of Linear Model\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>We plotted our linear model given the random parameters that were assigned to it. We found that it does not fit our data well. What we have to do. We need to train this model so that the model has the optimal weight and bias parameters and fit this data. There are the following steps [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2255,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1340"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1340"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1340/revisions"}],"predecessor-version":[{"id":1346,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1340/revisions/1346"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2255"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1340"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1340"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1340"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1341,"date":"2020-05-21T08:36:24","date_gmt":"2020-05-21T08:36:24","guid":{"rendered":"http://python3.foobrdigital.com/?p=1341"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"perceptron","status":"publish","type":"post","link":"https://python3.foobrdigital.com/perceptron/","title":{"rendered":"Perceptron"},"content":{"rendered":"\n<p><strong>Perceptron</strong>&nbsp;is a&nbsp;<strong>single layer neural network</strong>, or we can say a neural network is a multi-layer perceptron. Perceptron is a binary classifier, and it is used in supervised learning. A simple model of a biological neuron in an artificial neural network is known as&nbsp;<strong>Perceptron</strong>.</p>\n\n\n\n<p>A function that can decide whether or not an input which is represented by a vector of number belongs to some specific class is known as binary classifiers. The binary classifier is a type of linear classifier. A linear classifier is a classification algorithm which makes its predictions based on a linear predictor function combining a set of weight with the feature vector.</p>\n\n\n\n<p>The perceptron algorithm was designed to categorizing subjects into one of two types, classify visual input and separating groups with a line. Classification is a key part of&nbsp;<strong>image processing</strong>&nbsp;and&nbsp;<strong>machine learning</strong>. The perceptron algorithm classifies patterns, i.e., find and classify by many different means using machine learning algorithm, and groups by finding the linear separation between different objects and patterns which are received through numeric or visual input.</p>\n\n\n\n<p>A normal neural network looks like the following.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron.png\" alt=\"Perceptron\"/></figure>\n\n\n\n<p>Perceptron consist of four parts and which are required to understand for the implementation of the perceptron model in&nbsp;<strong>PyTorch</strong>.</p>\n\n\n\n<ul><li><strong>Input values or one input layer</strong><br>The input layer of a perceptron is made of artificial input neurons and brings the initial data into the system for further processing.</li><li><strong>Weights and bias</strong><br><strong>Weight</strong>&nbsp;represents the strength or dimension of the connection between units. If the weight from node 1 to node 2 has the greater quantity, then neuron 1 has greater influence over neuron 2. How much influence of the input will have on the output, is determined by weight.<br><strong>Bias</strong>&nbsp;is similar to the intercept added in a linear equation. It is an additional parameter which task is to adjust the output along with the weighted sum of the inputs to the neuron.</li><li><strong>Activation Function</strong><br>A neuron should be activated or not, is determined by an activation function. Activation function calculates a weighted sum and further adding bias with it to give the result.</li></ul>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron2.jpg\" alt=\"Perceptron\"/></figure>\n\n\n\n<p><strong>Neural Network</strong>&nbsp;is based on the Perceptron, so if we want to know the working of the neural network, learn how perceptron work.</p>\n\n\n\n<p><strong>The Perceptron works on three simple steps which are as follows:</strong></p>\n\n\n\n<p>a) In the first step, all the input x are multiplied with their weights denoted as K. This step is essential because the output of this step will be input for the next step.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron3.jpg\" alt=\"Perceptron\"/></figure>\n\n\n\n<p>b) Next step is to add all the multiplied value from K<sub>1</sub>&nbsp;to K<sub>n</sub>. It is known as the weighted sum. This weighted sum will be treated as an input for the next step.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron4.jpg\" alt=\"Perceptron\"/></figure>\n\n\n\n<p>c) In the next step, the weighted sum, which is calculated from the previous step, is applied to the correct activation function.</p>\n\n\n\n<p><strong>For example</strong></p>\n\n\n\n<p>A unit step activation function</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron5.png\" alt=\"Perceptron\"/></figure>\n\n\n\n<p><strong>Note 1:</strong>&nbsp;Weight shows the strength of the particular node.</p>\n\n\n\n<p><strong>Note 2:</strong>&nbsp;A bias value allows you to shift the activation function curve up or down.</p>\n\n\n\n<p><strong>Note 3:</strong>&nbsp;The activation functions are used to map the input between the required value like (0, 1) or (-1, 1)</p>\n\n\n\n<p><strong>Note 4:</strong>&nbsp;Perceptron is usually used to classify the data into two parts. Therefore, it is also known as a&nbsp;<strong>Linear Binary Classifier</strong>.</p>\n","protected":false},"excerpt":{"rendered":"<p>Perceptron&nbsp;is a&nbsp;single layer neural network, or we can say a neural network is a multi-layer perceptron. Perceptron is a binary classifier, and it is used in supervised learning. A simple model of a biological neuron in an artificial neural network is known as&nbsp;Perceptron. A function that can decide whether or not an input which is [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2256,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1341"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1341"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1341/revisions"}],"predecessor-version":[{"id":1347,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1341/revisions/1347"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2256"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1341"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1341"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1341"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1342,"date":"2020-05-21T08:37:58","date_gmt":"2020-05-21T08:37:58","guid":{"rendered":"http://python3.foobrdigital.com/?p=1342"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"deep-learning","status":"publish","type":"post","link":"https://python3.foobrdigital.com/deep-learning/","title":{"rendered":"Deep Learning"},"content":{"rendered":"\n<p>Deep learning is a set of algorithms used in&nbsp;<strong>Machine Learning</strong>. It is a part of machine learning methods based on artificial neural network. Learning can be supervised, unsupervised, or semi-supervised.</p>\n\n\n\n<p>Deep learning architectures i.e. deep neural networks, recurrent neural networks and convolution neural networks have been applied to fields such asnatural language processing, computer vision, speech recognition, audio recognition, social network filtering, machine translation, drug design, bioinformatics, medical image analysis, material inspection and board game programs, where they have produced results in some cases superior to and comparable to human experts.</p>\n\n\n\n<p>Deep learning used in</p>\n\n\n\n<ul><li>Self-driving cars</li><li>Deep learning in health care</li><li>Voice search and voice-activated assistants</li><li>Automatically adding sounds to silent movies</li><li>Automatic machine translation</li><li>Automatic text generation</li><li>Automatic handwriting generation</li><li>Image recognition</li><li>Automatic image caption generation</li><li>Automatic colorization</li></ul>\n\n\n\n<h2>Neural Network and Deep Learning Neural Network</h2>\n\n\n\n<p><strong>Artificial Neural Network</strong>&nbsp;or&nbsp;<strong>Neural Network</strong>&nbsp;was modeled after the human brain. Human has a mind to think and to perform the task in a particular situation, but how can a machine do that? For this purpose, an artificial brain was designed, which is known as a Neural Network. As the human brain has neurons for passing information, similarly neural network has nodes to perform that task. Nodes are the mathematical functions.</p>\n\n\n\n<p>A Neural Network is based on the structure and functions of biological Neural Networks. A Neural Network itself changes or learn based on input and output. The information that flows through the network affect the structure of the artificial Neural Network because of its learning and changing property.</p>\n\n\n\n<p><strong>Deep Learning Neural Network</strong>&nbsp;is an advanced form of neural network. Unlike simple Neural Network, Deep Learning Neural Network have more than one hidden layer. Deep Learning Neural Network gets the more complex dataset as that your model is able to learn from. Deep Learning Neural Network is</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-deep-learning.png\" alt=\"Deep Learning\"/></figure>\n\n\n\n<h2>Advantages of Neural Network</h2>\n\n\n\n<table><tbody><tr><th>S.No</th><th>Advantages</th><th>Description</th></tr><tr><td>1.</td><td>Storing information in the entire network.</td><td>In traditional programming, information is stored on the entire network, not on a database. If some piece of information is missed in one place, it does not prevent the network from functioning.</td></tr><tr><td>2.</td><td>Work with incomplete knowledge</td><td>When our ANN is trained. The data may produce output either there is complete information or incomplete information. Here, the loss performance depends on the importance of the missing information.</td></tr><tr><td>3.</td><td>Distributed memory</td><td>To train an ANN, it is necessary to determine the examples, and by showing these examples train it according to the desired output. The network can produce false output is the event cannot be shown to the network.</td></tr><tr><td>4.</td><td>Ability to make ML (Machine Learning)</td><td>ANN has the capability to make a machine learn. ANN learn events and make decisions by commenting on similar events.</td></tr><tr><td>5.</td><td>Fault tolerance features</td><td>If there is a corruption in one or more cell does not prevent it from generating output, and this feature makes it fault tolerance.</td></tr><tr><td>6.</td><td>Parallel Processing</td><td>ANN can perform more than one job at the same time because of its numeric strength quality.</td></tr></tbody></table>\n\n\n\n<h2>Disadvantages of Neural Network</h2>\n\n\n\n<table><tbody><tr><th>S.No</th><th>Disadvantages</th><th>Description</th></tr><tr><td>1.</td><td>Hardware Dependence</td><td>Ann requires processors with parallel processing power according to their structure. The realization of equipment is dependent because of this reason.</td></tr><tr><td>2.</td><td>Network&#8217;s unexplained behavior</td><td>It is one of the most important problems of the ANN. It does not give any clue as to why and how, when it produces a probing solution.</td></tr><tr><td>3.</td><td>Determination of the proper network structure</td><td>For determining the structure of the neural network, there are no specific rules available. With the help of experience, trial, and error, anappropriate network structure is achieved.</td></tr><tr><td>4.</td><td>Difficulty in showing the problem to the network</td><td>ANN works with numerical information so that the problems are translated into numeric values before being introduced to ANN. For this reason, it is difficult to show the problem to the network.</td></tr></tbody></table>\n","protected":false},"excerpt":{"rendered":"<p>Deep learning is a set of algorithms used in&nbsp;Machine Learning. It is a part of machine learning methods based on artificial neural network. Learning can be supervised, unsupervised, or semi-supervised. Deep learning architectures i.e. deep neural networks, recurrent neural networks and convolution neural networks have been applied to fields such asnatural language processing, computer vision, [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2257,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1342"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1342"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1342/revisions"}],"predecessor-version":[{"id":2485,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1342/revisions/2485"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2257"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1342"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1342"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1342"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1349,"date":"2020-05-21T08:40:59","date_gmt":"2020-05-21T08:40:59","guid":{"rendered":"http://python3.foobrdigital.com/?p=1349"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"creating-dataset","status":"publish","type":"post","link":"https://python3.foobrdigital.com/creating-dataset/","title":{"rendered":"Creating Dataset"},"content":{"rendered":"\n<p>Now, we will get the knowledge of how to create, learn, and test a Perceptron model. The implementation of the Perceptron model in PyTorch is done through several steps such as creating the dataset for a model, set up the model, training of the model, and testing of the model.</p>\n\n\n\n<p>Let start with our first step, i.e., creating the dataset.</p>\n\n\n\n<p>For creating a dataset, we will import a dataset directly from SDK learn. SDK-learn provides us access to many pre-prepared datasets. We will get access to all these datasets by simply importing a dataset. In this, we also use numpy library for further manipulating and analyzing of this data, and at last most common library which is used for plotting out dataset, i.e., matplotlib.pyplot will be imported.</p>\n\n\n\n<p>In this we first use SDK learn to create a linearly separable dataset then using torch we create a perception based Neural Network. After that, Neural Network will train to learn how to fit our dataset such that it is able to separate our data into two discrete classes. This will be done using the optimization algorithm (Gradient Descent) from which you might be familiar.</p>\n\n\n\n<p>In this, we will be used make_blobs() method. This function will create a cluster of data points which are all randomly centered on a chosen central point for the cluster.</p>\n\n\n\n<p>Let see the steps of creating the dataset</p>\n\n\n\n<p>1. The first step is to import all the required libraries, such as a torch, sklearn, numpy, and matplotlib.pyplot.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nfromsk learn import datasets  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset.png\" alt=\"Dataset\"/></figure>\n\n\n\n<p>2. In the second step, we define no of data points, and then we create a dataset by using make_blobs() function. As I told you, This function will create a cluster of data points.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>no_of_points=100  \ndatasets.make_blobs()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset2.png\" alt=\"Dataset\"/></figure>\n\n\n\n<p>3. Before calling the make_blobs() function, we need to create a nested list which specifies the coordinates of the center of our cluster. So we have to call the list centers and define central coordinates for our cluster in the following way.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>centers=&#91;&#91;-0.5,0.5],&#91;0.5,-0.5]]  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset3.png\" alt=\"Dataset\"/></figure>\n\n\n\n<p>4. Now, we will create our dataset, and we will store our data points into the variable x while storing values into the variable y and we will make use of our label just a bit.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x,y=dataset.make_blobs()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset4.png\" alt=\"Dataset\"/></figure>\n\n\n\n<p>5. Our dataset is not created yet because we did not pass any appropriate arguments of this function. So we pass all arguments here. The first argument represents the no of sample points; the second argument is random state, the third argument is centers and last argument that will allow us to generate our very first linearly separable dataset, i.e., cluster std.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x,y=datasets.make_blobs(n_samples=no_of_points,random_state=123,centers=centers,cluster_std=0.4)  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset5.png\" alt=\"Dataset\"/></figure>\n\n\n\n<p>6. In the next step, we visualize our data by print x and y coordinates like as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print(x)  \nprint(y)  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset6.png\" alt=\"Dataset\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset6_2.png\" alt=\"Dataset\"/></figure>\n\n\n\n<p>7. Now, after customizing our dataset as desired, we can plot and visualize it using plt.scatter() function. We define x and y coordinates of each label dataset. Let&#8217;s begin with the dataset which label is 0. It plots the top region of our data. Scatter function for 0 labeled dataset is defined as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.scatter(x&#91;y==0,0],x&#91;y==0,1])  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset7.png\" alt=\"Dataset\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset7_2.png\" alt=\"Dataset\"/></figure>\n\n\n\n<p>8. Now, we plot the points in the lower region of our data. The scatter function() for one labeled dataset is defined as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.scatter(x&#91;y==1,0],x&#91;y==1,1])  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset8.png\" alt=\"Dataset\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset8_2.png\" alt=\"Dataset\"/></figure>\n\n\n\n<p>9. Keep in mind to train a model x, and y coordinates both should be numpy array. So what we do we will change our x and y values into tensor like as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>xdata=torch.Tensor(x)  \nydata=torch.Tensor(y)  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset9.png\" alt=\"Dataset\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-dataset9_2.png\" alt=\"Dataset\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>Now, we will get the knowledge of how to create, learn, and test a Perceptron model. The implementation of the Perceptron model in PyTorch is done through several steps such as creating the dataset for a model, set up the model, training of the model, and testing of the model. Let start with our first [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2258,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1349"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1349"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1349/revisions"}],"predecessor-version":[{"id":1354,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1349/revisions/1354"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2258"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1349"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1349"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1349"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1350,"date":"2020-05-21T08:43:14","date_gmt":"2020-05-21T08:43:14","guid":{"rendered":"http://python3.foobrdigital.com/?p=1350"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"perceptron-model","status":"publish","type":"post","link":"https://python3.foobrdigital.com/perceptron-model/","title":{"rendered":"Perceptron Model"},"content":{"rendered":"\n<p>It is essential to know about the perceptron model and some key terms like cross-entropy, sigmoid gradient descent, and so on. So what is the perceptron model, and what does it do?</p>\n\n\n\n<p>Let see an example to understand the perceptron model. Imagine there is a hospital which annually does the operation of thousands of patients and tells you to create a predictive model which is able to accurately determine whether or not someone is likely to be cancer or not.</p>\n\n\n\n<p>With the help of previously determine data, we predict whether or not someone is likely to be cancer-based on their age, which traverses the x-axis and their quantity of tobacco inhaled which traverse the y-axis.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron-model.jpg\" alt=\"Perceptron Model\"/></figure>\n\n\n\n<p>So that the person who has higher in the age and quantity of tobaccos which he takes have higher chances of cancer and if a person has minimum age and quantity of tobaccos which he takes, have a minimum chance of cancer.</p>\n\n\n\n<p>Every green point, which indicates a higher chance of cancer, was initially assigned a label of zero and every blue point, which indicates a lower chance of cancer, was initially assigned a label of one.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron-model2.jpg\" alt=\"Perceptron Model\"/></figure>\n\n\n\n<p>So, we will start with a random model that will not correctly classify our data, but then the model will be trained through some optimization algorithm. The model will be trained through many iterations until it reaches the parameter value, which can classify our data correctly. We use previously labeled data everything here is labeled one, and everything here is label zero.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron-model3.jpg\" alt=\"Perceptron Model\"/></figure>\n\n\n\n<p>We use this labeled data to come up with a predictive model which classifies our data into two discrete categories. Using that model, we can now make a prediction on newly input data which don&#8217;t have a label based on whether or not that point lies below the line or above it. We will train our model, which can determine that this person belongs in class one such that they are most likely healthy.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron-model4.jpg\" alt=\"Perceptron Model\"/></figure>\n\n\n\n<p>Now, the biggest question is how the computer know-how to come up with this linear model does. For this purpose, we will calculate the error associated with this model and then readjust the parameters of the model to minimize the error and properly classify the data points. We will use&nbsp;<strong>cross-entropy ()</strong>&nbsp;function to find an error and&nbsp;<strong>sigmoid gradient descent</strong>&nbsp;to optimize the parameters. Let starts to implement the code in which we will see how cross-entropy function and sigmoid gradient descent is used.</p>\n\n\n\n<p>So, we work on the data set which we have created in the last section. Now, with the help of this data set, we will start implementing our code and create a basic perceptron model.</p>\n\n\n\n<p>At first we put plt.scatter(x[y==0,0],x[y==0,1]) and plt.scatter(x[y==1,0],x[y==1,1]) into a function for further use as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def Scatter():  \nplt.scatter(x&#91;y==0,0],x&#91;y==0,1])  \nplt.scatter(x&#91;y==1,0],x&#91;y==1,1])  </code></pre>\n\n\n\n<p><strong>To create a basic perceptron model we have to follow the following step:</strong></p>\n\n\n\n<p><strong>Step 1.</strong></p>\n\n\n\n<p>Our first step is to create a linear model. For this, we have to create our model class as we have implemented in the linear regression model with the init() method and forward() method. The init() method is similar but forward() method quite differs from the linear regression model. We define forward () as before replacing self for the first argument, and after that, we need to pass the inputs x.</p>\n\n\n\n<p>After that we make prediction by passing our data x into our linear model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Class Perceptron_model(nn.Module):  \ndef __init__(self,input_size,output_size):  \n        super().__init__()  \n        self.linear=nn.Linear(input_size,output_size)  \n    def forward(self,x):  \n        pred=self.linear(X)  \n        return pred  </code></pre>\n\n\n\n<p>It&#8217;s not sufficient, we have to convert the values into probabilities by applying sigmoid () method as follows:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def forward(self,x):  \n    pred=torch.sigmoid(self.linear(x))  \n    return pred  </code></pre>\n\n\n\n<p>Our initialization is finished and now, we are ready to use it.</p>\n\n\n\n<p><strong>Step 2</strong></p>\n\n\n\n<p>We will initialize a new linear model using Perceptron_model() constructor and pass input_size and output_size as an argument. Now, print the random weight and biased values which were assigned to it as follows:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model= Perceptron_model(2,1)  \nprint(list(model.parameters())) </code></pre>\n\n\n\n<p>Before this, to ensure consistency in our random result, we can seed our random number generator with torch manual seed, and we can put a seed of two as follow</p>\n\n\n\n<pre class=\"wp-block-code\"><code>torch.manual_seed(2)  </code></pre>\n\n\n\n<p><strong>Step 3</strong></p>\n\n\n\n<p>Our next step is to extract the model parameters by unpacking model. These parameters are extracted in the form of a list with two-element, i.e., A, B, and printing both values as follows:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91;A,b]=model.parameters()  \nA1,A2=A.view(2)  \nB1=B&#91;0]  \nprint(A1.item(), A2.item(),B1.item()) </code></pre>\n\n\n\n<p>Here, A is weight, and B is biased.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron-model5.png\" alt=\"Perceptron Model\"/></figure>\n\n\n\n<p>For cleanness we use function which returns the value A1.item(), A2.item() and B1[0].item() in the following way</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def get_perameters():  \n    return(A1.item(),A2.item(),B&#91;0].item()) </code></pre>\n\n\n\n<p><strong>Step 4</strong></p>\n\n\n\n<p>Now, we plot our linear model with the parameter which we extract in the form of list. We use title, line equation and so on. We create a user define function to plot our data. Let see the code of plotting the linear model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def plotfit(title):  \n    plt.title=title  \n    A1, A2, B1 = get_perameters()  \n    x1=np.array(&#91;-2.0,2.0])  \n    y1=((A1*x1)+B1)/-A2  \nplt.plot(x1,y1,'r')   \nScatter()  \nplotfit('Initial Model')</code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron-model6.png\" alt=\"Perceptron Model\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-perceptron-model7.png\" alt=\"Perceptron Model\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>It is essential to know about the perceptron model and some key terms like cross-entropy, sigmoid gradient descent, and so on. So what is the perceptron model, and what does it do? Let see an example to understand the perceptron model. Imagine there is a hospital which annually does the operation of thousands of patients [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2259,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1350"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1350"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1350/revisions"}],"predecessor-version":[{"id":1355,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1350/revisions/1355"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2259"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1350"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1350"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1350"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1351,"date":"2020-05-21T08:44:38","date_gmt":"2020-05-21T08:44:38","guid":{"rendered":"http://python3.foobrdigital.com/?p=1351"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"training-of-perceptron-model","status":"publish","type":"post","link":"https://python3.foobrdigital.com/training-of-perceptron-model/","title":{"rendered":"Training of Perceptron Model"},"content":{"rendered":"\n<p>Training of the perceptron model is similar to the linear regression model. We initialize our neural model, which have two input node in the input layer and a single output node with a sigmoid activation function. When we plot our model to the data, we found that it does not fit our data well. We need to train this model so that the model has the optimal weight and bias parameters and fit this data.</p>\n\n\n\n<p><strong>There are the following steps to train a model:</strong></p>\n\n\n\n<p><strong>Step 1</strong></p>\n\n\n\n<p>In the first step, the criterion by which we will compute the error of our model is recall Cross entropy. Our loss function will be measured on the basis of binary cross entropy loss (BCELoss) because we are dealing with only two classes. It is import from nn module.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>criterion=nn.BCELoss()  </code></pre>\n\n\n\n<p><strong>Step 2</strong></p>\n\n\n\n<p>Now, our next step is to update parameters using optimizer. So we define the optimizer which is used gradient descent algorithm (stochastic gradient descent).</p>\n\n\n\n<pre class=\"wp-block-code\"><code>optimizer=torch.optim.SGD(model.parameters(),lr=0.01)   </code></pre>\n\n\n\n<p><strong>Step 3</strong></p>\n\n\n\n<p>Now, we will train our model for a specified no of epochs as we have done in linear model. So the code will be similar to linear model as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>epochs=1000  \nlosses=&#91;]  \nfori in range(epochs):  \n    ypred=model.forward(xdata)  \n    loss=criterion(ypred,ydata)  \n    print(\"epoch:\",i,\"loss:\",loss.item())  \n    losses.append(loss)  \n    optimizer.zero_grad()  # Set the gradient to zero  \n    loss.backward() #To compute derivatives   \n    optimizer.step()    # Update the parameters   </code></pre>\n\n\n\n<p>Now, at last we plot our new linear model by simply calling plotfit() method.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plotfit('Trained Model')  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-training.png\" alt=\"Training\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-training2.png\" alt=\"Training\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>Training of the perceptron model is similar to the linear regression model. We initialize our neural model, which have two input node in the input layer and a single output node with a sigmoid activation function. When we plot our model to the data, we found that it does not fit our data well. We [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2260,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1351"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1351"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1351/revisions"}],"predecessor-version":[{"id":1356,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1351/revisions/1356"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2260"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1351"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1351"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1351"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1352,"date":"2020-05-21T08:47:19","date_gmt":"2020-05-21T08:47:19","guid":{"rendered":"http://python3.foobrdigital.com/?p=1352"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"testing-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/testing-2/","title":{"rendered":"Testing"},"content":{"rendered":"\n<p>The purpose of the perceptron model is to classify our data and tell us about the chances of cancer, i.e., maximum or minimum on the basis of previously labeled data.</p>\n\n\n\n<p>Our model is trained, and now, we test our model to know about its work smoothly and give an accurate result or not. For this purpose, we have to add some more functionality in our code.</p>\n\n\n\n<p><strong>There are the following steps to test our model:</strong></p>\n\n\n\n<p><strong>Step 1</strong></p>\n\n\n\n<p>We will re-plot our fitted model, and for this, we have to make a prediction on a random point which we will initialize. In our case, We will take two points for better understanding.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>p1=torch.Tensor(&#91;1.0,-1.0])  \np2=torch.Tensor(&#91;-1.0,-1.5]) </code></pre>\n\n\n\n<p><strong>Step 2</strong></p>\n\n\n\n<p>Now, our next step is to plot these points for visualization purpose so that we can determine both the points are in which class either 1 or 0.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(p1&#91;0],p1&#91;1],'ro')  \nplt.plot(p2&#91;0],p2&#91;1],'ko')  </code></pre>\n\n\n\n<p>The point p1 and p2 are initially in the form of tensor, so we changed these points into numpy by typecasting.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(p1.numpy()&#91;0],p1.numpy()&#91;1],'ro')  \nplt.plot(p2.numpy()&#91;0],p2.numpy()&#91;1],'ko')  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing.png\" alt=\"Testing\"/></figure>\n\n\n\n<p><strong>Step 3</strong></p>\n\n\n\n<p>We can now make a prediction on each point. We will predict the probabilities of each point belong to the positive region 2 class 1. We know all the orange points are labeled as 1, and all the blue points are labeled as 0. So the probability is determined as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print(\"Red point positive probability={}\".format(model.forward(p1).item()))  \nprint(\"Black point positive probability={}\".format(model.forward(p2).item())) </code></pre>\n\n\n\n<p>The probability of red and black points is equal to its prediction.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing2.png\" alt=\"Testing\"/></figure>\n\n\n\n<p><strong>Step 4</strong></p>\n\n\n\n<p>Now, we will going back to our class initialization and create a method called predict which have a parameter. We use self.forward(x) to find the probability. If probability is greater then 0.5 then we will return class 1 otherwise return 0.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def predict(self,x):  \n    pred=torch.sigmoid(self.linear(x))  \n    if pred>=0.5:  \n        return 1  \n    else:  \n        return 0   </code></pre>\n\n\n\n<p><strong>Step 5</strong></p>\n\n\n\n<p>At last we will add two more print statement which tell us about the class using predict method as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print(\"Red point in calss={}\".format(model.predict(p1)))  \nprint(\"Black point in calss={}\".format(model.predict(p2)))  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing3.png\" alt=\"Testing\"/></figure>\n\n\n\n<p>It&#8217;s clear that our model works smoothly and give us an accurate result with random data.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete Code</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nimport torch.nn as nn  \nfrom sklearn import datasets  \nno_of_points=100  \ncenters=&#91;&#91;-0.5,0.5],&#91;0.5,-0.5]]  \nx,y=datasets.make_blobs(n_samples=no_of_points,random_state=123,centers=centers,cluster_std=0.4)  \nxdata=torch.Tensor(x)  \nydata=torch.Tensor(y.reshape(100,1))  \ndef Scatter():  \n    plt.scatter(x&#91;y==0,0],x&#91;y==0,1])  \n    plt.scatter(x&#91;y==1,0],x&#91;y==1,1])  \nclass Perceptron_model(nn.Module):  \n    def __init__(self,input_size,output_size):  \n        super().__init__()  \n        self.linear=nn.Linear(input_size,output_size)  \n    def forward(self,x):  \n        pred=torch.sigmoid(self.linear(x))  \n        return pred  \n    def predict(self,x):  \n        pred=torch.sigmoid(self.linear(x))  \n        If pred>=0.5:  \n            return 1  \n        else:  \n            return 0  \ntorch.manual_seed(2)  \nmodel= Perceptron_model(2,1)  \ncriterion=nn.BCELoss()  \noptimizer=torch.optim.SGD(model.parameters(),lr=0.01)  \nprint(list(model.parameters()))  \n&#91;A,B]=model.parameters()  \nA1,A2=A.view(2)  \nB1=B&#91;0]  \nepochs=1000  \nlosses=&#91;]  \nfori in range(epochs):  \n    ypred=model.forward(xdata)  \n    loss=criterion(ypred,ydata)  \n    print(\"epoch:\",i,\"loss:\",loss.item())  \n    losses.append(loss)  \n    optimizer.zero_grad()  \n    loss.backward()  \n    optimizer.step()  \ndef get_perameters():  \n    return(A1.item(),A2.item(),B&#91;0].item())  \ndef plotfit(title):  \n    plt.title=title  \n    A1,A2,B1=get_perameters()  \n    x1=np.array(&#91;-2.0,2.0])  \n    y1=((A1*x1)+B1)/-A2  \n    plt.plot(x1,y1,'r')  \n    Scatter()  \n    plt.show()  \np1=torch.Tensor(&#91;1.0,-1.0])  \np2=torch.Tensor(&#91;-1.0,-1.5])  \nplt.plot(p1.numpy()&#91;0],p1.numpy()&#91;1],'ro')  \nplt.plot(p2.numpy()&#91;0],p2.numpy()&#91;1],'ko')  \nprint(\"Red point positive probability={}\".format(model.forward(p1).item()))  \nprint(\"Black point positive probability={}\".format(model.forward(p2).item()))  \nprint(\"Red point in calss={}\".format(model.predict(p1)))  \nprint(\"Black point in calss={}\".format(model.predict(p2)))  \nplotfit('Initial Model')  </code></pre>\n\n\n\n<p><strong>Output</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing4.png\" alt=\"Testing\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing5.png\" alt=\"Testing\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>The purpose of the perceptron model is to classify our data and tell us about the chances of cancer, i.e., maximum or minimum on the basis of previously labeled data. Our model is trained, and now, we test our model to know about its work smoothly and give an accurate result or not. For this [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2261,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1352"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1352"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1352/revisions"}],"predecessor-version":[{"id":1357,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1352/revisions/1357"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2261"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1352"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1352"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1352"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1353,"date":"2020-05-21T08:48:25","date_gmt":"2020-05-21T08:48:25","guid":{"rendered":"http://python3.foobrdigital.com/?p=1353"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"deep-neural-network","status":"publish","type":"post","link":"https://python3.foobrdigital.com/deep-neural-network/","title":{"rendered":"Deep Neural Network"},"content":{"rendered":"\n<p>In the perceptron model, we used a linear model to classify two regions of data. Realistic data is much more complex and not always classify by a straight line. For this purpose, we need a non-linear boundary to separate our data. Perceptron model is work on the most basic form of a neural network, but for realistic data classification, we used&nbsp;<strong>Deep Neural Network</strong>.</p>\n\n\n\n<p>When our model is unable to represent a set of data, we use a non-linear model instead of it. The non-linear model is used in the following situation</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/non-linear-boundary-in-deep-neural-network.png\" alt=\"Non-linear Boundary in Deep Neural Network\"/></figure>\n\n\n\n<p>In the above image, there is a curve which perfectly classifies our data but how we can obtain this curve. For this, we combine two perceptrons into a third one. It&#8217;s quite typical to understand so that for better understanding, we take two linear models and combine them to form a single&nbsp;<strong>non-linear model</strong>.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/non-linear-boundary-in-deep-neural-network2.png\" alt=\"Non-linear Boundary in Deep Neural Network\"/></figure>\n\n\n\n<p>It is clear from the above pictures that both models are unable to classify our data. Following are some steps which are used to form a non-linear model from two linear models:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>Let start by combining each linear model to form a non-linear model. If we have two linear models, then by combining them the resulted model will look like</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/non-linear-boundary-in-deep-neural-network-step1.png\" alt=\"Non-linear Boundary in Deep Neural Network\"/></figure>\n\n\n\n<p>The output model is a&nbsp;<strong>linear combination</strong>&nbsp;of the two other models.</p>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>Now, what we have to do, we will treat both the linear model as an input node which contains some linear equation. We denote our first model as x1 and second as x2.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/non-linear-boundary-in-deep-neural-network-step2.png\" alt=\"Non-linear Boundary in Deep Neural Network\"/></figure>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>In our next step, we will multiply our model with some&nbsp;<strong>weight</strong>&nbsp;such as w1 and w2, and we also consider bias so that we will also treat&nbsp;<strong>bias</strong>&nbsp;value as a node.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/non-linear-boundary-in-deep-neural-network-step3.png\" alt=\"Non-linear Boundary in Deep Neural Network\"/></figure>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>Now, everything is added to obtain a linear combination. For this purpose, we will apply the sigmoid activation function, which gives us the expected curve.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/non-linear-boundary-in-deep-neural-network-step4.png\" alt=\"Non-linear Boundary in Deep Neural Network\"/></figure>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>We will mathematically multiply all the nodes with its weight value such as w1=0.4, w2=1, and b=0.5 and apply the sigmoid then the resulting curve will be as follows:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/non-linear-boundary-in-deep-neural-network-step5.png\" alt=\"Non-linear Boundary in Deep Neural Network\"/></figure>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>In the second linear model x2, if we will take the weight value 3, the resulting model will give us an unexpected curve, and it looks like a</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/non-linear-boundary-in-deep-neural-network-step6.png\" alt=\"Non-linear Boundary in Deep Neural Network\"/></figure>\n\n\n\n<p>From step 5 and step 6 it is clear that the model which is created with weight value 1.5 and 1, classify our data best rather than the model which is created with weight value 1.5 and 3. Weight defined the non-linear boundary of the non-linear model.</p>\n\n\n\n<p>The process of combining two linear models to form a non-linear model is not so simple. It is quite essential to understand the&nbsp;<strong>structure of the Neural Network</strong>&nbsp;to implement the non-linear boundary of deep neural network.</p>\n","protected":false},"excerpt":{"rendered":"<p>In the perceptron model, we used a linear model to classify two regions of data. Realistic data is much more complex and not always classify by a straight line. For this purpose, we need a non-linear boundary to separate our data. Perceptron model is work on the most basic form of a neural network, but [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2262,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1353"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1353"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1353/revisions"}],"predecessor-version":[{"id":1358,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1353/revisions/1358"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2262"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1353"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1353"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1353"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1359,"date":"2020-05-21T08:49:31","date_gmt":"2020-05-21T08:49:31","guid":{"rendered":"http://python3.foobrdigital.com/?p=1359"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"architecture-of-neural-networks","status":"publish","type":"post","link":"https://python3.foobrdigital.com/architecture-of-neural-networks/","title":{"rendered":"Architecture of Neural Networks"},"content":{"rendered":"\n<p>We found a non-linear model by combining two linear models with some equation, weight, bias, and sigmoid function. Let start its better illustration and understand the architecture of&nbsp;<strong>Neural Network</strong>&nbsp;and&nbsp;<strong>Deep Neural Network</strong>.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>Let see an example for better understanding and illustration.</p>\n\n\n\n<p>Suppose, there is a linear model whose line is represented as-4x<sub>1</sub>-x<sub>2</sub>+12. We can represent it with the following perceptron.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch2.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>The weight in the input layer is -4, -1 and 12 represent the equation in the linear model to which input is passed in to obtain their probability of being in the positive region. Take one more model whose line is represented as-<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch3.png\" alt=\"Architecture of Neural Networks\">x<sub>1</sub>-x<sub>2</sub>+3. So the expected perceptron through which we can represent it as follows:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch4.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>Now, what we have to do, we will combine these two perceptrons to obtain a non-linear perceptron or model by multiplying the two models with some set of weight and adding biased. After that, we applied sigmoid to obtain the curve as follows:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch5.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>In our previous example, suppose we had two inputs x1 and x2. These inputs represent a single point at coordinates (2, 2), and we want to obtain the probability of the point being in the positive region and the non-linear model. These coordinates (2, 2) passed into the first input layer, which consists of two linear models.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch6.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>The two inputs are processed in the first linear model to obtain the probability of the point being in the positive region by taking the inputs as a linear combination based on weights and bias of the model and then taking the sigmoid and obtain the probability of point 0.88.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch7.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>In the same way, we will find the probability of the point is in the positive region in the second model, and we found the probability of point 0.64.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch8.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>When we combine both models, we will add the probabilities together. We will take the linear combination with respect to weights 1.5, 1, and bias value 0.5. We will multiply the first model with the first weight and the second model with a second weight and adding everything along with the bias to obtain the score since we will take sigmoid of the linear combination of both our models which obtain a new model. We will do the same thing for our points, which converts it to a 0.92 probability of it being in the positive region and the non-linear model.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch9.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>It is a feed forward process of deep neural network. For more efficiency, we can rearrange the notation of this neural network. Instead of representing our point as two distinct x1 and x2 input node we represent it as a single pair of the x1 and x2 node as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch10.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>This illustrates the unique architecture of a neural network. So there is an input layer which contains the input, the second layer which is set of the linear model and the last layer is the output layer which resulted from the combination of our two linear models to obtain a non-linear model.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-neural-network-in-pytorch11.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<h2>Deep Neural Network</h2>\n\n\n\n<p>We will use the models and the hidden layers to combine them and create non-linear models which best classify our data. Sometimes our data is too complex and to classify that we will have to combine non-linear models to create even more non-linear model.</p>\n\n\n\n<p>We can do this many times with even more hidden layers and obtain highly complex models as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/architecture-of-deep-neural-network-in-pytorch.png\" alt=\"Architecture of Neural Networks\"/></figure>\n\n\n\n<p>To classify this type of data is more complex. It requires many hidden layers of models combining into one another with some set of weight to obtain a model that perfectly classify this data.</p>\n\n\n\n<p>After that, we can produce some output through a feed-forward operation. The input would have to go through the entire depth of the neural network before producing an output. It is just a multilayered perceptron. In a deep neural network, our data&#8217;s trend is not straight forward, so this non-linear boundary is only an accurate model that correctly classifies a very complex set of data.</p>\n\n\n\n<p>Many hidden layers are required to obtain this non-linear boundary and each layer containing models which are combined into one another to produce this very complex boundary which classifies our data.</p>\n\n\n\n<p>The deep neural networks can be trained with more complex function to classify even more complex data.</p>\n","protected":false},"excerpt":{"rendered":"<p>We found a non-linear model by combining two linear models with some equation, weight, bias, and sigmoid function. Let start its better illustration and understand the architecture of&nbsp;Neural Network&nbsp;and&nbsp;Deep Neural Network. Let see an example for better understanding and illustration. Suppose, there is a linear model whose line is represented as-4&#215;1-x2+12. We can represent it [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2263,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1359"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1359"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1359/revisions"}],"predecessor-version":[{"id":1367,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1359/revisions/1367"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2263"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1359"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1359"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1359"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1360,"date":"2020-05-21T08:50:17","date_gmt":"2020-05-21T08:50:17","guid":{"rendered":"http://python3.foobrdigital.com/?p=1360"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"feed-forward-process","status":"publish","type":"post","link":"https://python3.foobrdigital.com/feed-forward-process/","title":{"rendered":"Feed Forward Process"},"content":{"rendered":"\n<p>Now, we know how with the combination of lines with different weight and biases can result in non-linear models. How does a neural network know what weight and biased values to have in each layer? It is no different from how we did it for the single based perceptron model.</p>\n\n\n\n<p>We are still making use of a gradient descent optimization algorithm which acts to minimize the error of our model by iteratively moving in the direction with the steepest descent, the direction which updates the parameters of our model while ensuring the minimal error. It updates the weight of every model in every single layer. We will talk more about optimization algorithms and backpropagation later.</p>\n\n\n\n<p>It is important to recognize the subsequent training of our neural network. Recognition is done by dividing our data samples through some decision boundary.</p>\n\n\n\n<p>&#8220;The process of receiving an input to produce some kind of output to make some kind of prediction is known as Feed Forward.&#8221; Feed Forward neural network is the core of many other important neural networks such as convolution neural network.</p>\n\n\n\n<p>In the feed-forward neural network, there are not any feedback loops or connections in the network. Here is simply an input layer, a hidden layer, and an output layer.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>There can be multiple hidden layers which depend on what kind of data you are dealing with. The number of hidden layers is known as the depth of the neural network. The deep neural network can learn from more functions. Input layer first provides the neural network with data and the output layer then make predictions on that data which is based on a series of functions. ReLU Function is the most commonly used activation function in the deep neural network.</p>\n\n\n\n<p>To gain a solid understanding of the feed-forward process, let&#8217;s see this mathematically.</p>\n\n\n\n<p>1) The first input is fed to the network, which is represented as matrix x1, x2, and one where one is the bias value.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network2.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>2) Each input is multiplied by weight with respect to the first and second model to obtain their probability of being in the positive region in each model.</p>\n\n\n\n<p>So, we will multiply our inputs by a matrix of weight using matrix multiplication.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network3.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>3) After that, we will take the sigmoid of our scores and gives us the probability of the point being in the positive region in both models.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network4.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>4) We multiply the probability which we have obtained from the previous step with the second set of weights. We always include a bias of one whenever taking a combination of inputs.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network5.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>And as we know to obtain the probability of the point being in the positive region of this model, we take the sigmoid and thus producing our final output in a feed-forward process.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network6.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Let takes the neural network which we had previously with the following linear models and the hidden layer which combined to form the non-linear model in the output layer.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network7.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>So, what we will do we use our non-linear model to produce an output that describes the probability of the point being in the positive region. The point was represented by 2 and 2. Along with bias, we will represent the input as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network8.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>The first linear model in the hidden layer recall and the equation defined it</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network9.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Which means in the first layer to obtain the linear combination the inputs are multiplied by -4, -1 and the bias value is multiplied by twelve.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network10.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>The weight of the inputs are multiplied by -1/5, 1, and the bias is multiplied by three to obtain the linear combination of that same point in our second model.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network11.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, to obtain the probability of the point is in the positive region relative to both models we apply sigmoid to both points as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network12.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>The second layer contains the weights which dictated the combination of the linear models in the first layer to obtain the non-linear model in the second layer. The weights are 1.5, 1, and a bias value of 0.5.</p>\n\n\n\n<p>Now, we have to multiply our probabilities from the first layer with the second set of weights as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network13.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, we will take the sigmoid of our final score</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feed-forward-process-in-deep-neural-network14.png\" alt=\"Feed Forward Process in Deep Neural Network\"/></figure>\n\n\n\n<p>It is complete math behind the feed forward process where the inputs from the input traverse the entire depth of the neural network. In this example, there is only one hidden layer. Whether there is one hidden layer or twenty, the computational processes are the same for all hidden layers.</p>\n","protected":false},"excerpt":{"rendered":"<p>Now, we know how with the combination of lines with different weight and biases can result in non-linear models. How does a neural network know what weight and biased values to have in each layer? It is no different from how we did it for the single based perceptron model. We are still making use [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2264,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1360"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1360"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1360/revisions"}],"predecessor-version":[{"id":1368,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1360/revisions/1368"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2264"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1360"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1360"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1360"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1361,"date":"2020-05-21T08:51:03","date_gmt":"2020-05-21T08:51:03","guid":{"rendered":"http://python3.foobrdigital.com/?p=1361"},"modified":"2020-12-16T16:59:04","modified_gmt":"2020-12-16T16:59:04","slug":"backpropagation-process","status":"publish","type":"post","link":"https://python3.foobrdigital.com/backpropagation-process/","title":{"rendered":"Backpropagation Process"},"content":{"rendered":"\n<p><strong>Backpropagation</strong>&nbsp;is one of the important concepts of a neural network. Our task is to classify our data best. For this, we have to update the weights of parameter and bias, but how can we do that in a deep neural network? In the linear regression model, we use gradient descent to optimize the parameter. Similarly here we also use gradient descent algorithm using Backpropagation.</p>\n\n\n\n<p>For a single training example,&nbsp;<strong>Backpropagation</strong>&nbsp;algorithm calculates the gradient of the&nbsp;<strong>error function</strong>. Backpropagation can be written as a function of the neural network. Backpropagation algorithms are a set of methods used to efficiently train artificial neural networks following a gradient descent approach which exploits the chain rule.</p>\n\n\n\n<p>The main features of Backpropagation are the iterative, recursive and efficient method through which it calculates the updated weight to improve the network until it is not able to perform the task for which it is being trained. Derivatives of the activation function to be known at network design time is required to Backpropagation.</p>\n\n\n\n<p>Now, how error function is used in Backpropagation and how Backpropagation works? Let start with an example and do it mathematically to understand how exactly updates the weight using Backpropagation.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<h3>Input values</h3>\n\n\n\n<p>X1=0.05<br>X2=0.10</p>\n\n\n\n<h3>Initial weight</h3>\n\n\n\n<p>W1=0.15 &nbsp; &nbsp; w5=0.40<br>W2=0.20 &nbsp; &nbsp; w6=0.45<br>W3=0.25 &nbsp; &nbsp; w7=0.50<br>W4=0.30 &nbsp; &nbsp; w8=0.55</p>\n\n\n\n<h3>Bias Values</h3>\n\n\n\n<p>b1=0.35 &nbsp; &nbsp; b2=0.60</p>\n\n\n\n<h3>Target Values</h3>\n\n\n\n<p>T1=0.01<br>T2=0.99</p>\n\n\n\n<p>Now, we first calculate the values of H1 and H2 by a forward pass.</p>\n\n\n\n<h3>Forward Pass</h3>\n\n\n\n<p>To find the value of H1 we first multiply the input value from the weights as</p>\n\n\n\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; H1=x1×w<sub>1</sub>+x2×w<sub>2</sub>+b1<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; H1=0.05×0.15+0.10×0.20+0.35<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>H1=0.3775</strong></p>\n\n\n\n<p>To calculate the final result of H1, we performed the sigmoid function as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network2.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>We will calculate the value of H2 in the same way as H1</p>\n\n\n\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; H2=x1×w<sub>3</sub>+x2×w<sub>4</sub>+b1<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; H2=0.05×0.25+0.10×0.30+0.35<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>H2=0.3925</strong></p>\n\n\n\n<p>To calculate the final result of H1, we performed the sigmoid function as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network3.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, we calculate the values of y1 and y2 in the same way as we calculate the H1 and H2.</p>\n\n\n\n<p>To find the value of y1, we first multiply the input value i.e., the outcome of H1 and H2 from the weights as</p>\n\n\n\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; y1=H1×w<sub>5</sub>+H2×w<sub>6</sub>+b2<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; y1=0.593269992×0.40+0.596884378×0.45+0.60<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>y1=1.10590597</strong></p>\n\n\n\n<p>To calculate the final result of y1 we performed the sigmoid function as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network4.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>We will calculate the value of y2 in the same way as y1</p>\n\n\n\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; y2=H1×w<sub>7</sub>+H2×w<sub>8</sub>+b2<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; y2=0.593269992×0.50+0.596884378×0.55+0.60<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>y2=1.2249214</strong></p>\n\n\n\n<p>To calculate the final result of H1, we performed the sigmoid function as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network5.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Our target values are 0.01 and 0.99. Our y1 and y2 value is not matched with our target values T1 and T2.</p>\n\n\n\n<p>Now, we will find the&nbsp;<strong>total error</strong>, which is simply the difference between the outputs from the target outputs. The total error is calculated as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network6.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>So, the total error is</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network7.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, we will backpropagate this error to update the weights using a backward pass.</p>\n\n\n\n<h3>Backward pass at the output layer</h3>\n\n\n\n<p>To update the weight, we calculate the error correspond to each weight with the help of a total error. The error on weight w is calculated by differentiating total error with respect to w.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network8.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>We perform backward process so first consider the last weight w5 as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network9.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>From equation two, it is clear that we cannot partially differentiate it with respect to w5 because there is no any w5. We split equation one into multiple terms so that we can easily differentiate it with respect to w5 as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network10.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, we calculate each term one by one to differentiate E<sub>total</sub>&nbsp;with respect to w5 as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network11.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Putting the value of e<sup>-y</sup>&nbsp;in equation (5)</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network12.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>So, we put the values of&nbsp;<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network13.png\" alt=\"Backpropagation Process in Deep Neural Network\">&nbsp;in equation no (3) to find the final result.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network14.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, we will calculate the updated weight w5<sub>new</sub>&nbsp;with the help of the following formula</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network15.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>In the same way, we calculate w6<sub>new</sub>,w7<sub>new</sub>, and w8<sub>new</sub>&nbsp;and this will give us the following values</p>\n\n\n\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>w5<sub>new</sub>=0.35891648</strong><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>w6<sub>new</sub>=408666186</strong><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>w7<sub>new</sub>=0.511301270</strong><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>w8<sub>new</sub>=0.561370121</strong></p>\n\n\n\n<h3>Backward pass at Hidden layer</h3>\n\n\n\n<p>Now, we will backpropagate to our hidden layer and update the weight w1, w2, w3, and w4 as we have done with w5, w6, w7, and w8 weights.</p>\n\n\n\n<p>We will calculate the error at w1 as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network16.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>From equation (2), it is clear that we cannot partially differentiate it with respect to w1 because there is no any w1. We split equation (1) into multiple terms so that we can easily differentiate it with respect to w1 as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network17.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, we calculate each term one by one to differentiate E<sub>total</sub>&nbsp;with respect to w1 as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network18.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>We again split this because there is no any H1<sup>final</sup>&nbsp;term in E<sup>toatal</sup>&nbsp;as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network19.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network20.png\" alt=\"Backpropagation Process in Deep Neural Network\">&nbsp;will again split because in E1 and E2 there is no H1 term. Splitting is done as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network21.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>We again Split both<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network22.png\" alt=\"Backpropagation Process in Deep Neural Network\">&nbsp;because there is no any y1 and y2 term in E1 and E2. We split it as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network23.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, we find the value of&nbsp;<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network24.png\" alt=\"Backpropagation Process in Deep Neural Network\">&nbsp;by putting values in equation (18) and (19) as</p>\n\n\n\n<p>From equation (18)</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network25.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>From equation (8)</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network26.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>From equation (19)</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network27.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Putting the value of e<sup>-y2</sup>&nbsp;in equation (23)</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network28.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>From equation (21)</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network29.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now from equation (16) and (17)</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network30.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Put the value of&nbsp;<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network31.png\" alt=\"Backpropagation Process in Deep Neural Network\">&nbsp;in equation (15) as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network32.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>We have<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network33.png\" alt=\"Backpropagation Process in Deep Neural Network\">we need to figure out<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network34.png\" alt=\"Backpropagation Process in Deep Neural Network\">as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network35.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Putting the value of e<sup>-H1</sup>&nbsp;in equation (30)</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network36.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>We calculate the partial derivative of the total net input to H1 with respect to w1 the same as we did for the output neuron:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network37.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>So, we put the values of&nbsp;<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network38.png\" alt=\"Backpropagation Process in Deep Neural Network\">&nbsp;in equation (13) to find the final result.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network39.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>Now, we will calculate the updated weight w1<sub>new</sub>&nbsp;with the help of the following formula</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-backpropagation-process-in-deep-neural-network40.png\" alt=\"Backpropagation Process in Deep Neural Network\"/></figure>\n\n\n\n<p>In the same way, we calculate w2<sub>new</sub>,w3<sub>new</sub>, and w4 and this will give us the following values</p>\n\n\n\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>w1<sub>new</sub>=0.149780716</strong><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>w2<sub>new</sub>=0.19956143</strong><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>w3<sub>new</sub>=0.24975114</strong><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<strong>w4<sub>new</sub>=0.29950229</strong></p>\n\n\n\n<p>We have updated all the weights. We found the error 0.298371109 on the network when we fed forward the 0.05 and 0.1 inputs. In the first round of Backpropagation, the total error is down to 0.291027924. After repeating this process 10,000, the total error is down to 0.0000351085. At this point, the outputs neurons generate 0.159121960 and 0.984065734 i.e., nearby our target value when we feed forward the 0.05 and 0.1.</p>\n","protected":false},"excerpt":{"rendered":"<p>Backpropagation&nbsp;is one of the important concepts of a neural network. Our task is to classify our data best. For this, we have to update the weights of parameter and bias, but how can we do that in a deep neural network? In the linear regression model, we use gradient descent to optimize the parameter. Similarly [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2265,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1361"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1361"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1361/revisions"}],"predecessor-version":[{"id":1369,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1361/revisions/1369"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2265"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1361"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1361"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1361"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1362,"date":"2020-05-21T08:55:05","date_gmt":"2020-05-21T08:55:05","guid":{"rendered":"http://python3.foobrdigital.com/?p=1362"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"implementation","status":"publish","type":"post","link":"https://python3.foobrdigital.com/implementation/","title":{"rendered":"Implementation"},"content":{"rendered":"\n<p>After knowing the process of Backpropagation lets start and see how a deep neural network is implemented using PyTorch. The process of implementing a deep neural network is similar to the implementation of the perceptron model. There are the following steps which we have to perform during the implementation.</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we will import all the require libraries such as a torch, numpy, datasets, and matplotlib.pyplot.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nfrom sklearn import datasets  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the second step, we define no of data points, and then we create a dataset by using make_blobs() function, which will create a cluster of the data point.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>no_of_points=500  \ndatasets.make_blobs()  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Now, we will create our dataset, and we will store our data points into the variable x while storing values into the variable y and we will make use of our label just a bit.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x,y=datasets.make_blobs()  </code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>Now, we change make_blobs () to make_cicrcle() because we want dataset in a circular form. We pass appropriate argument in make_circle() function. The first argument represents the no of sample points, the second argument is random state, and the third argument is noise which will refer to the standard deviation of the&nbsp;<strong>Gaussian</strong>&nbsp;noise, and the fourth arguments are the factor which will refer to the relative size of the smaller inner circular region in comparison to the larger.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x,y=datasets.make_circles(n_samples=no_of_points,random_state=123,noise=0.1,factor=0.2)=  </code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>Now, after customizing our dataset as desired, we can plot it and visualize it using plt.scatter() function. We define x and y coordinates of each label dataset. Let&#8217;s begin with the dataset which label is 0. It plots the top region of our data. Scatter function for 0 labeled dataset is defined as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.scatter(x&#91;y==0,0],x&#91;y==0,1])  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-implementation-of-deep-neural-network.png\" alt=\"Implementation of Deep Neural Network\"/></figure>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, we plot the points in the lower region of our data. The scatter function () for one labeled dataset is defined as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.scatter(x&#91;y==1,0],x&#91;y==1,1])  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-implementation-of-deep-neural-network2.png\" alt=\"Implementation of Deep Neural Network\"/></figure>\n\n\n\n<p>A single line can not classify the above dataset. For classifying this dataset will require a much deeper neural network.</p>\n\n\n\n<p>We put plt.scatter(x[y==0,0],x[y==0,1]) and plt.scatter(x[y==1,0],x[y==1,1]) into a function for further use as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def Scatter():  \n    plt.scatter(x&#91;y==0,0],x&#91;y==0,1])  \n    plt.scatter(x&#91;y==1,0],x&#91;y==1,1])  </code></pre>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>In this step, we will create our model class as we have implemented in linear regression and perceptron model. The difference is that here we use the hidden layer also in between the input and output layer. In init() method, we will pass an addition argument h1 as a hidden layer, and our input layer is connected with the hidden layer, and the hidden layer is then connected with the output layer. So</p>\n\n\n\n<pre class=\"wp-block-code\"><code>class Deep_neural_network(nn.Module):  \ndef __init__(self,input_size, h1, output_size):  \n                super().__init__()  \n                self.linear=nn.Linear(input_size, h1)   # input layer connect with hidden layer   \n             self.linear1=nn.Linear(h1, output_size)   # hidden layer connect with output layer  </code></pre>\n\n\n\n<p>Now, we have to add this extra hidden layer in our forward function So that any input must be passed through the entire depth of the neural network for prediction to be made. So</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def forward(self,x):  \n    x=torch.sigmoid(self.linear(x)) # Return the prediction x   \n    x=torch.sigmoid(self.linear1(x))    # Prediction will go through the next layer.  \n    return x                # Returning final outputs </code></pre>\n\n\n\n<p>Our initialization is finished, and now, we are ready to use it. Keep in mind to train a model x, and y coordinates both should be numpy array. So what we do we will change our x and y values into tensor like</p>\n\n\n\n<pre class=\"wp-block-code\"><code>xdata=torch.Tensor(x)  \nydata=torch.Tensor(y)  </code></pre>\n\n\n\n<p><strong>Step 7</strong></p>\n\n\n\n<p>We will initialize a new linear model using Deep_neural_network() constructor and pass input_size, output_size and hidden_size as an argument. We now, print the random weight and biased values which were assigned to it as follows:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print(list(model.parameters()))  </code></pre>\n\n\n\n<p>Before this, to ensure consistency in our random result, we can seed our random number generator with torch manual seed, and we can put a seed of two as follow</p>\n\n\n\n<pre class=\"wp-block-code\"><code>torch.manual_seed(2)  </code></pre>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>The criterion by which we will compute the error of our model is recalled&nbsp;<strong>Cross entropy</strong>. Our loss function will be measured based on binary cross entropy loss (BCELoss) because we are dealing with only two classes. It is imported from an nn module.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>criterion=nn.BCELoss()  </code></pre>\n\n\n\n<p>Now, our next step is to update parameters using the optimizer. So we define the optimizer which is used gradient descent algorithm. Here, we will use Adam optimizer. Adam optimizer is one of the many optimization algorithms. The Adam optimization algorithm is a combination of two other extensions of stochastic gradient descent such as&nbsp;<strong>Adagrad</strong>&nbsp;and&nbsp;<strong>RMSprop</strong>. Learning rate plays an important role in optimization.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>optimizer=torch.optim.Adam(model.parameters(),lr=0.01)   </code></pre>\n\n\n\n<p>If we choose a minimal learning rate, it leads to very slow convergence towards the minimum and if you choose very large learning rate can hinder the convergence. The Adam optimizer algorithm ultimately computes the adaptive learning rate for each parameter.</p>\n\n\n\n<p><strong>Step 9:</strong></p>\n\n\n\n<p>Now, we will train our model for a specified no of epochs as we have done in linear model and perceptron model. So the code will be similar to perceptron model as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>epochs=1000  \nlosses=&#91;]  \nFor i in range (epochs):  \n    ypred=model.forward(x)  #Prediction of y  \n    loss=criterion(ypred,y)   #Find loss  \n    losses.append()     # Add loss in list   \n    optimizer.zero_grad()   # Set the gradient to zero  \n    loss.backward()    #To compute derivatives   \n    optimizer.step()    # Update the parameters  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-implementation-of-deep-neural-network3.png\" alt=\"Implementation of Deep Neural Network\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>After knowing the process of Backpropagation lets start and see how a deep neural network is implemented using PyTorch. The process of implementing a deep neural network is similar to the implementation of the perceptron model. There are the following steps which we have to perform during the implementation. Step 1: In the first step, [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2266,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1362"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1362"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1362/revisions"}],"predecessor-version":[{"id":2289,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1362/revisions/2289"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2266"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1362"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1362"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1362"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1363,"date":"2020-05-21T08:58:52","date_gmt":"2020-05-21T08:58:52","guid":{"rendered":"http://python3.foobrdigital.com/?p=1363"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"testing-of-deep-neural-network","status":"publish","type":"post","link":"https://python3.foobrdigital.com/testing-of-deep-neural-network/","title":{"rendered":"Testing of Deep Neural Network"},"content":{"rendered":"\n<p>We will plot our dataset with a precise decision boundary which will separate our categorical result. In this, we will also test out model. There are the following steps to train our model:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we define a function&nbsp;<strong>plot_decision_boundary()</strong>&nbsp;which contains two arguments i.e., our training data x and out label y. This function will return a contour plot of the decision boundary.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def plot_decision_boundary(x, y):</code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In this step, we define a grid which properly spans our data. The process begins by defining the span of the x and y coordinates within our dataset. x_span and y_span will defined as 50 equally spaced points as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x_span=np.linspace(min(x&#91;:,0]),max(x&#91;:,0]))  \ny_span=np.linspace(min(y&#91;:,1]),max(y&#91;:,1]))</code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>In the next step, we will define xx and yy variables. Both xx and yy variables store a square two-dimensional array which will obtain from&nbsp;<strong>meshgrid()</strong>&nbsp;function of numpy.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>xx,yy=np.meshgrid(x_span,y_span)  </code></pre>\n\n\n\n<p>meshgrid() function takes both vector x_span and y_span as an argument. Both vectors contain 50 elements, and this function will return a two dimensional of 50 *50 matrix. The newly added rows will be repeated copies of the original row in the x_span vector and will return to xx variable. The process is the same for y_span; it will return two dimensional of 50*50 matrix in which the newly added column will be repeated copies of the original column in the y_span vector. This matrix will return to yy variable.</p>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>With the help of these newly created matrices xx and yy, we will create a Cartesian grid which covers our entire dataset. For this, we first have to convert the xx and yy matrix in one-dimensional using&nbsp;<strong>ravel()</strong>&nbsp;method.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print(xx.ravel(),yy.ravel())  </code></pre>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, we will have 50 x coordinates and to define our grid we have to concatenate these arrays in column y arrangement. This will be done with the help of c_[].</p>\n\n\n\n<pre class=\"wp-block-code\"><code>grid=np.c_&#91;xx.ravel(),yy.ravel()]  </code></pre>\n\n\n\n<p>Now, we will convert these into tensors using the torch.Tensor(). This will convert out 50*50 grid to tensor data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>grid=torch.Tensor(np.c_&#91;xx.ravel(),yy.ravel()])  </code></pre>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, ultimately, we can use&nbsp;<strong>model .forward()</strong>&nbsp;with the grid as the sole arguments. By feeding the entire grid tensor into the model.forward() function, the trained model is going to test all the points inside of our 50*50 grid, and this will return a tensor of predictions.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.forward(grid)  </code></pre>\n\n\n\n<p>This prediction indicates the probability of any given point being labeled as one and we will store this tensor in a variable&nbsp;<strong>pred_func</strong>.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pred_func=model.forward(grid)  </code></pre>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, what we will reshape the pred_func into the same shape of dimension as our original xx and yy dimension.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>z=pred_func.view(xx.shape).numpy()  </code></pre>\n\n\n\n<p>This will generate an error; we will us detach method which excludes any subgraph from gradient computation, which would be associated with the value from pred_fun.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>z=pred_func.view(xx.shape).detach().numpy()</code></pre>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>Now, our next step is to link our prediction result to their appropriate coordinate counterparts. For this purpose, we will use plt.contourf() which will create a contour plot of our predicted results with xx, yy and z</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.contourf(xx, yy,z)  </code></pre>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>Now, we will first call plot_decision_boundary() method, and then we will call scatter_plot() method which we defined earlier. This will visualize our data as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plot_decision_boundary(x,y)  \nscatter_plot()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-deep-neural-network-in-pytorch.png\" alt=\"Testing of Deep Neural Network in PyTorch\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-deep-neural-network-in-pytorch2.png\" alt=\"Testing of Deep Neural Network in PyTorch\"/></figure>\n\n\n\n<p><strong>Step 8</strong></p>\n\n\n\n<p>We will re-plot our fitted model, and for this, we have to make a prediction on a random point which we will initialize. We will take two points for better understanding of</p>\n\n\n\n<pre class=\"wp-block-code\"><code>p1=torch.Tensor(0.25,0.25])  </code></pre>\n\n\n\n<p><strong>Step 9</strong></p>\n\n\n\n<p>Now, the next step is to plot this point for visualization purpose so that we can determine the point is in which class either 1 or 0.</p>\n\n\n\n<ol><li>plt.plot(p1[0],p1[1],marker=&#8217;o&#8217;,markersize=5,color=&#8217;red&#8217;)&nbsp;&nbsp;</li></ol>\n\n\n\n<p>The point p1 is initially in the form of tensor, so we changed this point into numpy by typecasting.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(p1.numpy()&#91;0],p1.numpy()&#91;1],marker='o',markersize=5,color='red')  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-deep-neural-network-in-pytorch3.png\" alt=\"Testing of Deep Neural Network in PyTorch\"/></figure>\n\n\n\n<p><strong>Step 9</strong></p>\n\n\n\n<p>We can make a prediction of the point. We will predict the probability of the point belongs to the positive region 2 class 1. We know all the orange points are labeled as 1, and all the blue points are labeled as 0. So the probability is determined as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print(\"Red point positive probability={}\".format(model.forward(p1).item())) </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-deep-neural-network-in-pytorch4.png\" alt=\"Testing of Deep Neural Network in PyTorch\"/></figure>\n\n\n\n<p><strong>Step 10</strong></p>\n\n\n\n<p>Now, we will be going back to our class initialization and create a method called predict which have a parameter. We use self.forward(x) to find the probability. If the probability is greater than 0.5, then we will return class 1 otherwise return 0.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def predict(self,x):  \n    pred=self.forward(x)  \n        if pred>=0.5:  \n            return 1  \n        else:  \n            return 0   </code></pre>\n\n\n\n<p><strong>Step 11</strong></p>\n\n\n\n<p>At last, we will add the print statement which tells us about the class using the predict method as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print(\"Red point in calss={}\".format(model.predict(p1)))  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-deep-neural-network-in-pytorch5.png\" alt=\"Testing of Deep Neural Network in PyTorch\"/></figure>\n\n\n\n<p>It&#8217;s clear that our model works smoothly and give us an accurate result with random data.</p>\n\n\n\n<h2>Complete code</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nimport torch.nn as nn  \nfrom sklearn import datasets  \nno_of_points=500  \nx,y=datasets.make_circles(n_samples=no_of_points,random_state=123,noise=0.1,factor=0.2)  \nxdata=torch.Tensor(x)  \nydata=torch.Tensor(y)  \ndef scatter_plot():  \n    plt.scatter(x&#91;y==0,0],x&#91;y==0,1])  \n    plt.scatter(x&#91;y==1,0],x&#91;y==1,1])  \n    plt.show()  \n    \n  \nclass Deep_neural_network(nn.Module):  \n    def __init__(self,input_size, h1, output_size):  \n        super().__init__()  \n        self.linear=nn.Linear(input_size, h1)   # input layer connect with hidden layer   \n        self.linear1=nn.Linear(h1, output_size)   # hidden layer connect with output layer  \n    def forward(self,x):  \n        x=torch.sigmoid(self.linear(x)) # Return the prediction x   \n        x=torch.sigmoid(self.linear1(x))    # Prediction will go through the next layer.  \n        return x        # Returning final outputs   \n    def predict(self,z):  \n        pred=self.forward(z)  \n        if pred>=0.5:  \n            return 1  \n        else:  \n            return 0  \ntorch.manual_seed(2)  \nmodel= Deep_neural_network(2,4,1)   # 2 input nodes, 4 hidden nodes and 1 output node  \nprint(list(model.parameters()))  \ncriterion=nn.BCELoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.1)  \nepochs=1000  \nlosses=&#91;]  \nfor i in range(epochs):  \n    ypred=model.forward(xdata)  \n    loss=criterion(ypred,ydata)  \n    print(\"epoch:\",i,\"loss:\",loss.item())  \n    losses.append(loss)  \n    optimizer.zero_grad()  \n    loss.backward()  \n    optimizer.step()  \ndef plot_decision_boundary(x, y):  \n    x_span=np.linspace(min(x&#91;:,0]),max(x&#91;:,0]))  \n    y_span=np.linspace(min(x&#91;:,1]),max(x&#91;:,1]))  \n    xx,yy=np.meshgrid(x_span,y_span)  \n    grid=torch.Tensor(np.c_&#91;xx.ravel(),yy.ravel()])  \n    pred_func=model.forward(grid)  \n    z=pred_func.view(xx.shape).detach().numpy()  \n    plt.contourf(xx,yy,z)  \nz1=0.25  \nz2=0.25  \np1=torch.Tensor(&#91;z1,z2])  \nplt.plot(p1.numpy()&#91;0],p1.numpy()&#91;1],marker='o',markersize=5,color='red')  \nprint(\"Red point positive probability={}\".format(model.forward(p1).item()))  \nprint(\"Red point in calss={}\".format(model.predict(p1)))  \nplot_decision_boundary(x,y)  \nscatter_plot()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-deep-neural-network-in-pytorch5.png\" alt=\"Testing of Deep Neural Network in PyTorch\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-deep-neural-network-in-pytorch-output2.png\" alt=\"Testing of Deep Neural Network in PyTorch\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>We will plot our dataset with a precise decision boundary which will separate our categorical result. In this, we will also test out model. There are the following steps to train our model: Step 1: In the first step, we define a function&nbsp;plot_decision_boundary()&nbsp;which contains two arguments i.e., our training data x and out label y. [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2267,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1363"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1363"}],"version-history":[{"count":3,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1363/revisions"}],"predecessor-version":[{"id":2484,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1363/revisions/2484"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2267"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1363"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1363"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1363"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1364,"date":"2020-05-21T09:00:50","date_gmt":"2020-05-21T09:00:50","guid":{"rendered":"http://python3.foobrdigital.com/?p=1364"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"image-recognition","status":"publish","type":"post","link":"https://python3.foobrdigital.com/image-recognition/","title":{"rendered":"Image Recognition"},"content":{"rendered":"\n<p><strong>Image recognition</strong>&nbsp;is a process of extracting meaningful information, such as the content of an image, from a given image. In image recognition, it is essential to classify the major content in a given image, so it does not involve determining the position and pose of the recognized content.</p>\n\n\n\n<p>The term &#8220;<strong>Image Recognition</strong>&#8221; is introduced for computer technologies which recognize the certain animal, objects, people, or other targeted subjects with the help of algorithms and machine learning concepts.&nbsp;<strong>Image recognition</strong>&nbsp;is connected to&nbsp;<strong>computer vision</strong>, which is a comprehensive label to see like humans for the process of training computers and&nbsp;<strong>image processing</strong>. It is a catch-all term for computers which do intensive work on data.</p>\n\n\n\n<p>There are several ways to do image recognition. The use of a&nbsp;<strong>convolutional neural network</strong>&nbsp;lies on the top of many recognition techniques, and it filters images through a sequence of artificial neuron layer. The convolutional neural network was specially designed for image recognition and similar image processing. With the help of the combination of techniques such as max pooling, padding and stride configuration, CNN filters work on images to help machine learning programs get better at identifying the subject of the picture.</p>\n\n\n\n<h2>Challenges of Image Recognition</h2>\n\n\n\n<p>Image recognition is one of the techniques which is widely used in the present era. Because of its popularity and its continuous use, it faces many challenging problems. These problems are as follows:</p>\n\n\n\n<p><strong>1) Distortion</strong></p>\n\n\n\n<p>Objects do not change even if they are distorted. The system learns from the original image and forms a perception that this object can be in specific shape only. In the real world, shape changes, and as a result, there are inaccuracies occur when a system encounters a distort image of an object.</p>\n\n\n\n<p><strong>2) Inter-class variation</strong></p>\n\n\n\n<p>Certain object change within the class. They can be of different size, shape, but still, they represent the same class. For example, bottles, button, bags, chairs come different size and appearances.</p>\n\n\n\n<p><strong>3) Viewpoint variation</strong></p>\n\n\n\n<p>When images (in which the entities are aligned in a different direction) are fed to the system, it predicts inaccurate values. The system is unable to understand that changing the alignment of the image such as left, right, bottom and top, will not make it different and that&#8217;s because of it creates challenges in image recognition.</p>\n\n\n\n<p><strong>4) Scale variation</strong></p>\n\n\n\n<p>The classification of the object is affected if there is a variation in the size of the object. As closer we view the object, the bigger it looks in size and vice-versa.</p>\n\n\n\n<p><strong>5) Occlusion</strong></p>\n\n\n\n<p>Certain objects prevent the full view of an image and result in incomplete information being given to the system. It is necessary to develop an algorithm which is sensitive to these variations and contains a wide range of samples of the data.</p>\n\n\n\n<h2>Image classification in PyTorch</h2>\n\n\n\n<p>PyTorch is one of the most popular frameworks of Deep learning. Image classification is a supervised learning problem. Image classification is done with the help of a pre-trained model.</p>\n\n\n\n<h3>1) Pre-trained model</h3>\n\n\n\n<p>Pre-trained models are neural network models which are trained on large benchmark datasets like ImageNet. There is various pre-trained model such as&nbsp;<strong>AlexNet</strong>&nbsp;and&nbsp;<strong>ResNet101</strong>. Both the model has been trained on&nbsp;<strong>ImageNet</strong>&nbsp;dataset. The word pre-trained means that the deep learning architectures ResNet101 and AlexNet, for instance, have been already trained on some datasets and carry the resultant weights and biases with them.&nbsp;<strong>TorchVision</strong>&nbsp;has both the architectures and the pre-trained models.</p>\n\n\n\n<p><strong>a) Model Inference process</strong></p>\n\n\n\n<p>How to use the pre-trained model for predicting the class of input. There is a process involved in this which is referred to as&nbsp;<strong>Model Inference</strong>. This process has the following step:</p>\n\n\n\n<ol type=\"i\"><li>Reading the input image.</li><li>Performing transformation on the image.</li><li>Forward pass</li><li>Displaying the predictions based on the obtained scores.</li></ol>\n\n\n\n<p><strong>b) Loading Pre-trained network using TorchVision</strong></p>\n\n\n\n<p>We can easily use the pre-trained model with the help of TorchVision module. For this, we have first to install the torchvision and import models from torchvision module and with the help of&nbsp;<strong>dir (models)</strong>&nbsp;see the different models and architectures available with us.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install torchvision  \nfrom torchvision import models  \ndir(models)   </code></pre>\n\n\n\n<p><strong>c) Using AlexNet for image classification</strong></p>\n\n\n\n<p>We have the following steps which are used to perform when we perform image classification using AlexNet:</p>\n\n\n\n<p><strong>Step1:</strong>&nbsp;Load the pre-trained model<br><strong>Step2:</strong>&nbsp;Specify image transformation<br><strong>Step3:</strong>&nbsp;Load the input image and pre-process it<br><strong>Step4:</strong>&nbsp;Model Inference</p>\n\n\n\n<p><strong>d) Using ResNet for image classification</strong></p>\n\n\n\n<p>We have the following steps which are used to perform when we perform image classification using AlexNet:</p>\n\n\n\n<p><strong>Step1:</strong>&nbsp;Load the pre-trained model.<br><strong>Step2:</strong>&nbsp;Put the model in eval mode.<br><strong>Step3:</strong>&nbsp;Carryout model inferences.<br><strong>Step4:</strong>&nbsp;print the top 5 classes predicted by the model.</p>\n\n\n\n<p>In the next topic, we will discuss the&nbsp;<strong>MNIST dataset</strong>&nbsp;and how we can use a deep neural network to have a model fit image data. We will talk about the validation set, which is used to validate a neural network and check to see how well it generalizes to new data. After training an optimal neural network, we then use it to predict a new image from the web.</p>\n","protected":false},"excerpt":{"rendered":"<p>Image recognition&nbsp;is a process of extracting meaningful information, such as the content of an image, from a given image. In image recognition, it is essential to classify the major content in a given image, so it does not involve determining the position and pose of the recognized content. The term &#8220;Image Recognition&#8221; is introduced for [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2268,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1364"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1364"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1364/revisions"}],"predecessor-version":[{"id":2291,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1364/revisions/2291"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2268"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1364"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1364"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1364"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1365,"date":"2020-05-21T09:01:19","date_gmt":"2020-05-21T09:01:19","guid":{"rendered":"http://python3.foobrdigital.com/?p=1365"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"mnist-dataset","status":"publish","type":"post","link":"https://python3.foobrdigital.com/mnist-dataset/","title":{"rendered":"MNIST Dataset"},"content":{"rendered":"\n<p>In this topic, we will discuss a new type of dataset which we will use in&nbsp;<strong>Image Recognition</strong>. This dataset is known as&nbsp;<strong>MNIST dataset</strong>. The MNIST dataset can be found online, and it is essentially just a database of various handwritten digits. The MNIST dataset has a large amount of data and is commonly used to demonstrate the true power of deep neural networks.</p>\n\n\n\n<p>Suppose we have the following figure:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-mnist-dataset-of-image-recognition.png\" alt=\"MNIST Dataset of Image Recognition in PyTorch\"/></figure>\n\n\n\n<p>When we look at the image, our brain and eyes work together to recognize this image as number eight. Our brain is a very powerful tool, and it&#8217;s capable of categorizing this image as an eight very quickly. There are so many shapes of a number, and our mind can easily recognize these shapes and determine what number is it, but this task is not so simple for a computer to complete. There is only one way to do this, which is the use of deep neural network which allows us to train a computer to classify the handwritten digits effectively.</p>\n\n\n\n<p>So far, we have only dealt with data which contains simple data points on a&nbsp;<strong>Cartesian coordinate system</strong>. From starting till now, we have dealt with binary class datasets. Now, we will use the multiclass datasets, and when we use multiclass datasets, we will use the&nbsp;<strong>Softmax</strong>&nbsp;activation function in the output layer rather than the sigmoid function. The sigmoid activation function is quite useful for classifying binary datasets, and it was quite effective in arranging probability values between 0 and 1. The sigmoid function is not effective for multiclass datasets, and for this purpose, we use the&nbsp;<strong>Softmax</strong>&nbsp;activation function, which is capable of dealing with it.</p>\n\n\n\n<p>The MNIST dataset is a multiclass dataset which consists of 10 classes into which we can classify numbers from 0 to 9. The major difference between the datasets which we have used previously and the MNIST dataset is the method in which the MNIST data is inputted into the neural network.</p>\n\n\n\n<p>In the perceptron model and linear regression model, each data points were defined by simple X and Y coordinate. This means that the input layer needed two nodes for inputting single data points.</p>\n\n\n\n<p>In MNIST dataset, a single data point comes in the form of an image. These images, contained in MNIST datasets, are typically 28*28 pixels such that 28 pixels traversing the horizontal axis and 28 pixels traversing the vertical axis. It means that a single image from the MNIST database has a total of 784 pixels which must be analyzed. There are 784 nodes in the input layer of our neural network to analyze one of these images.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-mnist-dataset-of-image-recognition2.png\" alt=\"MNIST Dataset of Image Recognition in PyTorch\"/></figure>\n\n\n\n<p>Due to the additional input nodes and increased no of the classes that the numbers can be classified in 0 to 9. It is clear that our dataset is more complex than any of the datasets we analyze before. For classifying this dataset, a deep neural network is required with the effectiveness of some hidden layers.</p>\n\n\n\n<p>In our deep neural network, there are 784 nodes in the input layer, a few of hidden layers which feed-forward the input values and finally ten nodes in output layer for each of the respective handwritten numbers. The values are fed through the network, and the node which outputs the highest activation value in the output layer identifies the letter or number.</p>\n","protected":false},"excerpt":{"rendered":"<p>In this topic, we will discuss a new type of dataset which we will use in&nbsp;Image Recognition. This dataset is known as&nbsp;MNIST dataset. The MNIST dataset can be found online, and it is essentially just a database of various handwritten digits. The MNIST dataset has a large amount of data and is commonly used to [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2219,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1365"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1365"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1365/revisions"}],"predecessor-version":[{"id":1374,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1365/revisions/1374"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2219"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1365"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1365"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1365"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1366,"date":"2020-05-21T09:05:02","date_gmt":"2020-05-21T09:05:02","guid":{"rendered":"http://python3.foobrdigital.com/?p=1366"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"image-transforms","status":"publish","type":"post","link":"https://python3.foobrdigital.com/image-transforms/","title":{"rendered":"Image Transforms"},"content":{"rendered":"\n<p>Loading and transformation are two main concepts which are essential to do image recognition in PyTorch. Loading and transformation of the images is the starting step of the recognition process.</p>\n\n\n\n<p>There are the following steps which are the step by step procedure to do loading and transformation:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we install all the require library such as pip, torchvision, numpy, etc. If all the required library is already satisfied, then we import torch, and then we import datasets and transforms from torchvision. For plotting our dataset, we will import matplotlib.pyplot library and we will also import numpy to perform operations. The libraries are imported as:</p>\n\n\n\n<ol><li><strong>import</strong>&nbsp;torch&nbsp;&nbsp;</li><li class=\"\"><strong>import</strong>&nbsp;matplotlib.pyplot&nbsp;as&nbsp;plt&nbsp;&nbsp;</li><li><strong>import</strong>&nbsp;numpy&nbsp;as&nbsp;np&nbsp;&nbsp;</li><li class=\"\">from&nbsp;torchvision&nbsp;<strong>import</strong>&nbsp;datasets,&nbsp;transforms&nbsp;&nbsp;</li></ol>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the second step, we load the MNIST dataset using the MNIST () method of datasets. In the first argument, we specified the root directory of our data as following</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_dataset=datasets.MNIST(root='./data')   </code></pre>\n\n\n\n<p>In the second argument, we set train=&#8217;true&#8217;. We will do this to initialize the MNIST training dataset. After that, we set download =&#8217;true&#8217; and this will download a list into the data folder if it&#8217;s not already there.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Training_dataset=datasets.MNIST(root='./data',train=True,download=True)    </code></pre>\n\n\n\n<p>The last argument will be transform which is equal to&nbsp;<strong>transform1</strong>&nbsp;argument that will initialize before the&nbsp;<strong>training_dataset</strong>. This argument dictates any image manipulation which you wish to apply on your images.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  </code></pre>\n\n\n\n<p><strong>Note:</strong>&nbsp;Our MNIST images are 28*28 grayscale images which would imply that each image is a two dimensional number by array 28 pixels wide and 28 pixels long and each pixel intensity ranging from 0 to 255.</p>\n\n\n\n<p>We must transform the image being in an array to a tensor. We will use Compose () method of transforms which will allow us to chain multiple transformations together . So our first transformation, which is passed as a first argument of composed, will transform.ToTensor(). This will convert our numpy array in the range of 0 to 255 to a float tensor in the range from 0 to 1.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform1=transforms.Compose(&#91;transforms.ToTensor()])  </code></pre>\n\n\n\n<p>We will also apply the normalize transformation with the help of normalize() method of transforms as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform1=transforms.Compose(&#91;transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  </code></pre>\n\n\n\n<p>In the normalize() method, we specified the mean which we are used to normalizing all channels of our tensor image, and we also specified the center deviation. Now, we call our training dataset as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_dataset  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-image-transforms-in-image-recognition.png\" alt=\"Image Transforms in Image Recognition\"/></figure>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>We will further analyze images within this dataset by plotting it. To plot the tensor image, we must change it back to numpy array. We will do this work in a function def im_convert() contain one parameter which will be our tensor image.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def im_convert(tensor):  </code></pre>\n\n\n\n<p>Before converting tensor to numpy array, first, we will clone it. It will create a new copy of tensor, and then we use the detach() function and then we will use numpy as:</p>\n\n\n\n<ol><li>image=tensor.clone().detach().numpy()&nbsp;&nbsp;</li></ol>\n\n\n\n<p><strong>Note:</strong>&nbsp;The tensor which will be converted into numpy array has a shape with the first, second, and third dimensions. The first dimension represents the color channel, and the second and the third dimensions represent the width and height of the image and pixels.</p>\n\n\n\n<p>We know each image from the MNIST dataset is a grayscale corresponding to a single color channel with a width and height of 28*28 pixels. So, the shape would be (1, 28, 28).</p>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>For plotting our image, it is required that the image have a shape of (28, 28, 1). So, we will transpose our image by swapping axis zero, one, and two as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=image.transpose(1,2,0)    </code></pre>\n\n\n\n<p>This method swap axis 0 with axis 1 and axis 1 with axis 2.</p>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>In the next step, we de-normalized the image which we have to normalize before. Normalization is done by subtracting the mean and dividing by the standard deviation. We would multiply by the standard deviation and add the mean as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))   </code></pre>\n\n\n\n<p>To ensure that the range between 0 and 1, we used&nbsp;<strong>clip()</strong>&nbsp;function and pass zero and one as an argument. We will apply the clip function to a minimum value of 0 and the maximum value of 1 and return the image.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=image.clip(0,1)  \nreturn image  </code></pre>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>Now, we plot our MNIST dataset for better visualization. We will start by loading the image from&nbsp;<strong>training_loader()</strong>. The training loader is what we used to specify our training batches previously when training our neural network. For every epoch, we performed a single pass through the entire dataset. However, one epoch with sixty thousand training images would be too big to fit the computer all at once. So we will divide it into smaller batches using our train loader as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True) </code></pre>\n\n\n\n<p>The first argument is a dataset, which is equal to our training_dataset. The second argument is our batch size, which is equal to 100. The third argument, we set shuffle is equal to true.</p>\n\n\n\n<h4><strong>Note:</strong>&nbsp;The batch size of 100 would take 600 iterations to complete one epoch and that each iteration it will update the weights of the neural network and minimizing the error.</h4>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>In the next step, we wrap our train loader. It will create an object which allows us to go through the alterable training loader one element at a time. We access it one element at a time by calling next on our dataiter. The next () function will grab the first batch of our training data, and that training data will be split into images and labels as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>dataiter=iter(training_loader)  \nimages,labels=dataiter.next()  </code></pre>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>Now, we will plot the images in the batch along with their corresponding labels. This will be done with the help of figure function of plt and set fig size is equal to the tuple of integers 25*4, which will specify the width and height of the figure.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>fig=plt.figure(figsize=(25,4))  </code></pre>\n\n\n\n<p>Now, we plot 20 MNIST images from our batch. We use add_subplot() method to add a subplot to the current figure and pass 2, 10, and idx as arguments of the function. Here two is no of rows, ten is no of columns, and idx is index.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>ax=fig.add_subplot(2,10,idx+1)</code></pre>\n\n\n\n<p>Now, we will display our images with the help of im_show() function and give a title for each image plot as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.imshow(im_convert(images&#91;idx]))   \nax.set_title(&#91;labels&#91;idx].item()])  </code></pre>\n\n\n\n<p>Finally call plt.show() and it will give us the expected result.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete code</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nfrom torchvision import datasets,transforms   \ntransform1=transforms.Compose(&#91;transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \ndef im_convert(tensor):  \n    image=tensor.clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \ndataiter=iter(training_loader)  \nimages,labels=dataiter.next()  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1)  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(&#91;labels&#91;idx].item()])  \nplt.show()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-image-transforms-in-image-recognition2.png\" alt=\"Image Transforms in Image Recognition\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-image-transforms-in-image-recognition3.png\" alt=\"Image Transforms in Image Recognition\"/></figure>\n\n\n\n<p>Now, with the help of these label images, we will implement a neural network which will classify new test images.</p>\n","protected":false},"excerpt":{"rendered":"<p>Loading and transformation are two main concepts which are essential to do image recognition in PyTorch. Loading and transformation of the images is the starting step of the recognition process. There are the following steps which are the step by step procedure to do loading and transformation: Step 1: In the first step, we install [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2220,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1366"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1366"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1366/revisions"}],"predecessor-version":[{"id":2241,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1366/revisions/2241"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2220"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1366"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1366"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1366"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1376,"date":"2020-05-21T09:09:58","date_gmt":"2020-05-21T09:09:58","guid":{"rendered":"http://python3.foobrdigital.com/?p=1376"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"image-recognition-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/image-recognition-2/","title":{"rendered":"Image Recognition"},"content":{"rendered":"\n<p>Our next task is to train a neural network with the help of previously labeled images to classify new test images. So we will use the nn module to build our neural network.</p>\n\n\n\n<p>There are the following steps to implement the neural network for image recognition:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we will define the class which will be used to create our neural model instances. This class will be inherited from the nn module, so we first have to import the nn package.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from torch import nn   \nclass classifier (nn.Module):  </code></pre>\n\n\n\n<p>Our class will be followed by an init() method. In init() first argument will always self, second argument will be the number of input nodes which we will call, the third argument will be the number of nodes in the hidden layer, fourth argument will be the number of nodes in the second hidden layer and the last argument will be the number of nodes in the output layer.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def __init__(self,input_layer,hidden_layer1,hidden_layer2,output_layer):  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the second step, we recall the init() method for the provision of various method and attributes, and we will initialize the input layer, both the hidden layer and the output layer. One thing remembers that we will deal with the fully connected neural network. So</p>\n\n\n\n<pre class=\"wp-block-code\"><code>super(),__init__()  \nself.linear1=nn.Linear(input_layer,hidden_layer1)  \nself.linear2=nn.Linear(hidden_layer1,hidden_layer2)  \nself.linear3=nn.Linear(hidden_layer2,output_layer)   \ndef __init__(self,input_layer,hidden_layer1,hidden_layer2,output_layer):  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Now, we will make the prediction, but before it, we will import torch.nn.functional package, and then we will use the forward() function and place self as a first argument and x for whatever input we will try to make the prediction.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch.nn.functional as func  \ndef forward(self,x):  </code></pre>\n\n\n\n<p>Now, whatever input which will be passed in forward () function will pass to the object of linear1, and we will use&nbsp;<strong>relu</strong>&nbsp;function rather than&nbsp;<strong>sigmoid</strong>. The output of this will feed as an input into our second hidden layer and the output of our second hidden layer will feed to the output layer and return the output of our final layer.</p>\n\n\n\n<p><strong>Note: We will not apply any activation function in the output layer if we are dealing with multiclass dataset.</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>x=func.relu(self.linear1(x))  \nx=func.relu(self.linear2(x))  \nx=self.linear3(x)  \nreturn x  </code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>In the next step, we will set up out model constructor. According to our initializer we have to set input dimensions, hidden layer dimensions and output dimensions.</p>\n\n\n\n<p>The pixel intensity of the image will be fed to our input layer. Since each image is of 28*28 pixels which have a total of 784 pixels which will be fed into our neural network. So we will pass 784 as the first argument, we will take 125 and 60 nodes in the first and second hidden layer, and in the output layer, we will take ten nodes. So</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model=classification1(784,125,65,10)  </code></pre>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, we will define our loss function. The nn.CrossEntropyLoss() is used for multi-class classification. This function is the combination of log_softmax() function and NLLLoss() which is a negative log-likelihood loss. We use cross-entropy whatever training and classification problem with n classes. As such, it makes use of log probabilities, so we pass in the row output rather than the output of a softmax activation function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>criteron=nn.CrossEntropyLoss()  </code></pre>\n\n\n\n<p>After that, we will use the familiar optimizer, i.e., Adam as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>optimizer=torch.optim.Adam(model.parameters(),lr=0.001)   </code></pre>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>In the next step, we will specify no of epochs. We initialize no of epochs and analyzing the loss at every epoch with the plot. We will initialize two lists, i.e., loss_history and correct history.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>loss_history=&#91;]  \ncorrect_history=&#91;]   </code></pre>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>We will start by iterating through every epoch, and for every epoch, we must iterate through every single training batch that&#8217;s provided to us by the training loader. Each training batch contain one hundred images as well as one hundred labels in a train in train loader as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>for e in range(epochs):  \n    for input, labels in training_loader:   </code></pre>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>As we iterate through our batches of images, we must flatten them, and we must reshape them with the help of view method.<strong>Note:</strong>&nbsp;The shape of each image tensor is (1, 28, and 28) which means a total of 784 pixels.</p>\n\n\n\n<p>According to the structure of the neural network, our input values are going to be multiplied by our weight matrix connecting our input layer to the first hidden layer. To conduct this multiplication, we must make our images one dimensional. Instead of each image is 28 rows by two columns, we must flatten it into a single row of 784 pixels.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>inputs=input.view(input.shape&#91;0],-1)  </code></pre>\n\n\n\n<p>Now, with the help of these inputs, we get outputs as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>outputs=model(inputs)   </code></pre>\n\n\n\n<p><strong>Step 9:</strong></p>\n\n\n\n<p>With the help of the outputs, we will calculate the total categorical cross-entropy loss, and the output is ultimately compared with the actual labels. We will also determine the error based on the cross-entropy criterion. Before performing any part of a training pass, we must set optimizer as we have done before.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>loss1=criteron(outputs,labels)  \noptimizer.zero_grad()  \nloss1.backward()  \noptimizer.step()   </code></pre>\n\n\n\n<p><strong>Step 10:</strong></p>\n\n\n\n<p>To keep track of the losses at every epoch, we will initialize a variable loss, i.e., running_loss. For every loss which is computed as per batch, we must add all up for every single batch and then compute the final loss at every epoch.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>loss+=loss1.item()  </code></pre>\n\n\n\n<p>Now, we will append this accumulated loss for the entire epoch into our losses list. For this, we use an else statement after the looping statement. So once the for loop is finished, then the else statement is called. In this else statement we will print the accumulated loss which was computed for the entire dataset at that specific epoch.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>epoch_loss=loss/len(training_loader)  \nloss_history.append(epoch_loss) </code></pre>\n\n\n\n<p><strong>Step 11:</strong></p>\n\n\n\n<p>In the next step, we will find the accuracy of our network. We will initialize the correct variable and assign the value zero. We will compare the predictions made by the model for each training image to the actual labels of the images to show how many of them get correct within an epoch.</p>\n\n\n\n<p>For each image, we will take the maximum score value. In such that case a tuple is returned. The first value it gives back is the actual top value &#8211; the maximum score, which was made by the model for every single image within this batch of images. So, we are not interested in the first tuple value, and the second will correspond to the top predictions made by the model which we will call preds. It will return the index of the maximum value for that image.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>_,preds=torch.max(outputs,1)  </code></pre>\n\n\n\n<p><strong>Step 12:</strong></p>\n\n\n\n<p>Each image output will be a collection of values with indices ranging from 0 to 9 such that the MNIST dataset contains classes from 0 to 9. It follows that the prediction where the maximum value occurs corresponds to the prediction made by the model. We will compare all of these predictions made by the model to the actual labels of the images to see how many of them they got correct.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>correct+=torch.sum(preds==labels.data)  </code></pre>\n\n\n\n<p>This will give the number of correct predictions for every single batch of images. We will define the epoch accuracy in the same way as epoch loss and print both epoch loss and accuracy as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>epoch_acc=correct.float()/len(training_loader)    \nprint('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item())</code></pre>\n\n\n\n<p>This will give the expected result as</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-implementation-of-neural-network-in-image-recognition.png\" alt=\"Implementation of Neural Network in Image Recognition\"/></figure>\n\n\n\n<p><strong>Step 13:</strong></p>\n\n\n\n<p>Now, we will append the accuracy for the entire epoch into our correct_history list, and for better visualization, we will plot both epoch loss and accuracy as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(loss_history,label='Running Loss History')  \nplt.plot(correct_history,label='Running correct History')  </code></pre>\n\n\n\n<p><strong>Epoch Loss</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-implementation-of-neural-network-in-image-recognition2.png\" alt=\"Implementation of Neural Network in Image Recognition\"/></figure>\n\n\n\n<p><strong>Epoch accuracy</strong></p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-implementation-of-neural-network-in-image-recognition3.png\" alt=\"Implementation of Neural Network in Image Recognition\"/></figure>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete Code</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nfrom torch import nn  \nfrom torchvision import datasets, transforms  \n  \ntransform1=transforms.Compose(&#91;transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \ndef im_convert(tensor):  \n    image=tensor.clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \ndataiter=iter(training_loader)  \nimages,labels=dataiter.next()  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1)  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(&#91;labels&#91;idx].item()])  \nclass classification1(nn.Module):  \n    def __init__(self,input_layer,hidden_layer1,hidden_layer2,output_layer):  \n        super().__init__()  \n        self.linear1=nn.Linear(input_layer,hidden_layer1)  \n        self.linear2=nn.Linear(hidden_layer1,hidden_layer2)  \n        self.linear3=nn.Linear(hidden_layer2,output_layer)  \n    def forward(self,x):  \n        x=func.relu(self.linear1(x))  \n        x=func.relu(self.linear2(x))  \n        x=self.linear3(x)  \n        return x  \nmodel=classification1(784,125,65,10)  \ncriteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.0001)  \nepochs=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]  \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \n    for input,labels in training_loader:  \n        inputs=input.view(input.shape&#91;0],-1)  \n        outputs=model(inputs)  \n        loss1=criteron(outputs,labels)  \n        optimizer.zero_grad()  \n        loss1.backward()  \n        optimizer.step()  \n        _,preds=torch.max(outputs,1)  \n        loss+=loss1.item()  \n        correct+=torch.sum(preds==labels.data)  \n    else:  \n        epoch_loss=loss/len(training_loader)  \n        epoch_acc=correct.float()/len(training_loader)  \n        loss_history.append(epoch_loss)  \n        correct_history.append(epoch_acc)  \n        print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  </code></pre>\n","protected":false},"excerpt":{"rendered":"<p>Our next task is to train a neural network with the help of previously labeled images to classify new test images. So we will use the nn module to build our neural network. There are the following steps to implement the neural network for image recognition: Step 1: In the first step, we will define [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2222,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1376"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1376"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1376/revisions"}],"predecessor-version":[{"id":1383,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1376/revisions/1383"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2222"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1376"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1376"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1376"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1377,"date":"2020-05-21T09:13:14","date_gmt":"2020-05-21T09:13:14","guid":{"rendered":"http://python3.foobrdigital.com/?p=1377"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"validation","status":"publish","type":"post","link":"https://python3.foobrdigital.com/validation/","title":{"rendered":"Validation"},"content":{"rendered":"\n<p>In the training section, we trained our model on the MNIST dataset (Endless dataset), and it seemed to reach a reasonable loss and accuracy. If the model can take what it has learned and generalize itself to new data, then it would be a true testament to its performance. This will be done with the help of the following steps:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>We will create our validation set with the help of our training dataset, which we have created in the training section. In this time we will set train equals to false as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>validation_dataset=datasets.MNIST(root='./data',train=False,download=True,transform=transform1)  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>Now as we have declared a training loader in the training section similarly we will declare a validation loader in validation section. Validation loader will also create in the same way as we have created training loader, but this time we pass training loader rather than training the dataset, and we set shuffle equals to false because we will not be trained our validation data. There is no need to shuffle it because it is only for testing purpose.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>validation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False)  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Our next step is to analyze the validation loss and accuracy at every epoch. For this purpose, we have to create two lists for validation running lost, and validation running loss corrects.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_loss_history=&#91;]  \nval_correct_history=&#91;]</code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>In the next step, we will validate the model. The model will validate the same epoch. After we finished iterating through the entire training set to train our data, we will now iterate through our validation set to test our data.</p>\n\n\n\n<p>We will first measure for two things. The first one is the performance of our model, i.e., how many correct classifications. Our model makes on the test set on the validation set to check for overfitting. We will set running loss and running corrects of validation as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_loss=0.0  \nval_correct=0.0  </code></pre>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>We can now loop through our test data. So after the else statement, we will define a loop statement for labels and inputs as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>for val_input,val_labels in validation_loader:  </code></pre>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>As we iterate through our batches of images, we must flatten them, and we must reshape them with the help of view method.</p>\n\n\n\n<p><strong>Note:</strong>&nbsp;The shape of each image tensor is (1, 28, and 28) which means a total of 784 pixels.</p>\n\n\n\n<p>According to the structure of the neural network, our input values are going to be multiplied by our weight matrix connecting our input layer to the first hidden layer. To conduct this multiplication, we must make our images one dimensional. Instead of each image is 28 rows by two columns, we must flatten it into a single row of 784 pixels.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_inputs=val_input.view(val_input.shape&#91;0],-1)  </code></pre>\n\n\n\n<p>Now, with the help of these inputs, we get outputs as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_outputs=model(val_inputs)  </code></pre>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>With the help of the outputs, we will calculate the total categorical cross-entropy loss, and the output is ultimately compared with the actual labels.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_loss1=criteron(val_outputs,val_labels)  </code></pre>\n\n\n\n<p>We are not training our neural network, so there is no need to call zero_grad(), backward() or any of that. And there is also no need to compute derivative anymore. In the scope of operation to save memory, we call no_grad() method before For loop with the torch as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>with torch.no_grad():  </code></pre>\n\n\n\n<p>It will temporarily set all the require grad flag to be false.</p>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>Now, we will calculate the validation loss and accuracy in the same way as we have calculated the training loss and training accuracy as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>_,val_preds=torch.max(val_outputs,1)  \nval_loss+=val_loss1.item()  \nval_correct+=torch.sum(val_preds==val_labels.data)  </code></pre>\n\n\n\n<p><strong>Step 9:</strong></p>\n\n\n\n<p>Now, we will calculate the validation epoch loss which will be done as same as how we calculate the training epoch loss where we divide the total running loss by the length of the dataset. So it will be write as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_epoch_loss=val_loss/len(validation_loader)  \nval_epoch_acc=correct.float()/len(validation_loader)  \nval_loss_history.append(val_epoch_loss)  \nval_correct_history.append(epoch_acc)  </code></pre>\n\n\n\n<p><strong>Step 10:</strong></p>\n\n\n\n<p>We will print validation loss and validation accuracy as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-neural-network-for-image-recognition.png\" alt=\"Validation of Neural Network for Image Recognition\"/></figure>\n\n\n\n<p><strong>Step 11:</strong></p>\n\n\n\n<p>Nor, for better understanding, we will plot it for visualization purpose. We will plot it as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(loss_history,label='Training Loss')  \nplt.plot(val_loss_history,label='Validation Loss')  \nplt.legend()  \nplt.show()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-neural-network-for-image-recognition2.png\" alt=\"Validation of Neural Network for Image Recognition\"/><figcaption><br></figcaption></figure>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(correct_history,label='Training accuracy')  \nplt.plot(val_correct_history,label='Validation accuracy')  \nplt.legend()  \nplt.show()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-neural-network-for-image-recognition3.png\" alt=\"Validation of Neural Network for Image Recognition\"/></figure>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete Code</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nfrom torch import nn  \nfrom torchvision import datasets,transforms   \ntransform1=transforms.Compose(&#91;transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \nvalidation_dataset=datasets.MNIST(root='./data',train=False,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \nvalidation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False)  \ndef im_convert(tensor):  \n    image=tensor.clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \nclass classification1(nn.Module):  \n    def __init__(self,input_layer,hidden_layer1,hidden_layer2,output_layer):  \n        super().__init__()  \n        self.linear1=nn.Linear(input_layer,hidden_layer1)  \n        self.linear2=nn.Linear(hidden_layer1,hidden_layer2)  \n        self.linear3=nn.Linear(hidden_layer2,output_layer)  \n    def forward(self,x):  \n        x=func.relu(self.linear1(x))  \n        x=func.relu(self.linear2(x))  \n        x=self.linear3(x)  \n        return x  \nmodel=classification1(784,125,65,10)  \ncriteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.0001)  \nepochs=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]  \nval_loss_history=&#91;]  \nval_correct_history=&#91;]  \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \n    val_loss=0.0  \n    val_correct=0.0  \n    for input,labels in training_loader:  \n        inputs=input.view(input.shape&#91;0],-1)  \n        outputs=model(inputs)  \n        loss1=criteron(outputs,labels)  \n        optimizer.zero_grad()  \n        loss1.backward()  \n        optimizer.step()  \n        _,preds=torch.max(outputs,1)  \n        loss+=loss1.item()  \n        correct+=torch.sum(preds==labels.data)  \n    else:  \n        with torch.no_grad():  \n            for val_input,val_labels in validation_loader:  \n                val_inputs=val_input.view(val_input.shape&#91;0],-1)  \n                val_outputs=model(val_inputs)  \n                val_loss1=criteron(val_outputs,val_labels)   \n                _,val_preds=torch.max(val_outputs,1)  \n                val_loss+=val_loss1.item()  \n                val_correct+=torch.sum(val_preds==val_labels.data)  \n        epoch_loss=loss/len(training_loader)  \n        epoch_acc=correct.float()/len(training_loader)  \n        loss_history.append(epoch_loss)  \n        correct_history.append(epoch_acc)  \n        val_epoch_loss=val_loss/len(validation_loader)  \n        val_epoch_acc=correct.float()/len(validation_loader)  \n        val_loss_history.append(val_epoch_loss)  \n        val_correct_history.append(epoch_acc)  \n        print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  \n        print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  \nplt.plot(correct_history,label='Correct history ')  \nplt.plot(val_correct_history,label='Validation correct history')  \nplt.legend()  \nplt.show()  \nplt.plot(correct_history,label='Training accuracy')  \nplt.plot(val_correct_history,label='Validation accuracy')  \nplt.legend()  \nplt.show()  </code></pre>\n","protected":false},"excerpt":{"rendered":"<p>In the training section, we trained our model on the MNIST dataset (Endless dataset), and it seemed to reach a reasonable loss and accuracy. If the model can take what it has learned and generalize itself to new data, then it would be a true testament to its performance. This will be done with the [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2223,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1377"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1377"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1377/revisions"}],"predecessor-version":[{"id":1385,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1377/revisions/1385"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2223"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1377"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1377"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1377"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1378,"date":"2020-05-21T09:17:25","date_gmt":"2020-05-21T09:17:25","guid":{"rendered":"http://python3.foobrdigital.com/?p=1378"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"final-test","status":"publish","type":"post","link":"https://python3.foobrdigital.com/final-test/","title":{"rendered":"Final Test"},"content":{"rendered":"\n<p>In the last section, we implemented a neural network or created a model which classified the handwritten digits. Now, we test our model by grabbing an image from the web. We used the following image:</p>\n\n\n\n<figure class=\"wp-block-embed\"><div class=\"wp-block-embed__wrapper\">\nhttps://images.homedepot-static.com/productImages/007164ea-d47e-4f66-8d8c-fd9f621984a2/svn/architectural-mailboxes-house-letters-numbers-3585b-5-64_1000.jpg\n</div></figure>\n\n\n\n<p>When you paste this link on your browser, you will see the image of number five as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-image-recognition-model.png\" alt=\"Testing of Image Recognition Model in PyTorch\"/></figure>\n\n\n\n<p>After seeing this, we will realize that it is the number 5. Now, we will try to get our network to predict it.</p>\n\n\n\n<p>We have the following steps to make predictions of the number image:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we will perform a&nbsp;<strong>GET</strong>&nbsp;request to retrieve the image data. To make a&nbsp;<strong>GET</strong>&nbsp;request, we will need to import request as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import requests  </code></pre>\n\n\n\n<p>Now, we set a variable URL and assign the link as a string.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>url='https://images.homedepot-static.com/productImages/007164ea-d47e-4f66-8d8c-fd9f621984a2/svn/architectural-mailboxes-house-letters-numbers-3585b-5-64_1000.jpg' </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the next step, we set a variable response whose value will get from the&nbsp;<strong>get()</strong>&nbsp;method of request. The&nbsp;<strong>get()</strong>&nbsp;method will consist of two arguments i.e., URL and stream and stream will be equals to true.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>response=requests.get(url,stream=True)  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>We will use the raw content of our response to obtain the image. For this, we first have to import&nbsp;<strong>Image</strong>&nbsp;from&nbsp;<strong>PIL (Python Image Library)</strong>&nbsp;as.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from PIL import Image  </code></pre>\n\n\n\n<p>We use the&nbsp;<strong>open()</strong>&nbsp;method of image and pass the raw content of response as an argument. The value which will be returned from this method will assign to a variable named img as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>img=Image.open(response.raw)  </code></pre>\n\n\n\n<p>Now, we plot the image to make sure that everything is working well.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.imshow(img)  \nplt.show()  </code></pre>\n\n\n\n<p>When we run it, it will generate an error because of PIL. We must have to install pillow first to run this code. We must have to run the&nbsp;<strong>conda install -c anaconda pillow</strong>&nbsp;command on anaconda command prompt to install pillow.</p>\n\n\n\n<p>When you run the code, it will give the expected output.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-image-recognition-model2.png\" alt=\"Testing of Image Recognition Model in PyTorch\"/></figure>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>We need to ensure that the image corresponds to what the neural network is trained to learn. Our image is of 1000*1000 pixels, so we need to make it into 28*28 grayscale image like ones in the training data. In our trained image dataset, images have a black background and white foreground, and in the above image there is white background and black foreground. Now, our first task is to preprocessing this image.</p>\n\n\n\n<p>We will use the&nbsp;<strong>invert ()</strong>&nbsp;method of&nbsp;<strong>PIL.ImageOps</strong>&nbsp;and pass our image as an argument. This method will invert the color of our image.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>img=PIL.ImageOps.invert(img)  </code></pre>\n\n\n\n<p>This image is in the RGB format with three channels of pixel intensity values, and this will problematic for numerous reasons. For this purpose, we must have to convert this image to be a binary black and white image, and we will convert this image as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>img=img.convert('1')   </code></pre>\n\n\n\n<p>We will transform this image in the same way as we have transformed all of our other training images. We have to transform the image in 28*28 pixels, so we have to add an argument&nbsp;<strong>resize</strong>&nbsp;in our transformed chain composition as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform1=transforms.Compose(&#91;transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \nimg=transform1(img)</code></pre>\n\n\n\n<p>Now, our images are in the form of tensor, so we have to change it into numpy array. Before plotting our image, we have to import&nbsp;<strong>PIL.ImageOps</strong>&nbsp;and then plot the image as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import PIL.ImageOps  \nplt.imshow(im_convert(img))  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-image-recognition-model3.png\" alt=\"Testing of Image Recognition Model in PyTorch\"/></figure>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, we will feed this image into our neural network to make predictions. We will do it in the same way as we have done with MNIST.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>img=img.view(img.shape&#91;0],-1)  \noutput=model(img)  \n  \n_,pred=torch.max(output,1)  \nprint(pred.item())  </code></pre>\n\n\n\n<p>It will give us the expected prediction as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-image-recognition-model4.png\" alt=\"Testing of Image Recognition Model in PyTorch\"/></figure>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>In the next step, we wrap our validation loader. It will create an object which allows us to go through the alterable validation loader one element at a time. We access it one element at a time by calling next on our dataiter. The next () function will grab the first batch of our validate data, and that validate data will be split into images and labels as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>dataiter=iter(validation_loader)  \nimages,labels=dataiter.next()  </code></pre>\n\n\n\n<p>To make a prediction, we have to reshape the images as we have done before and we will require the output of all the images and prediction as well.</p>\n\n\n\n<pre class=\"wp-block-code\"><code> images_=images.view(images.shape&#91;0],-1)  \noutput=model(images_)  \n_,preds=torch.max(output,1)  </code></pre>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>Now, we will plot the images in the batch along with their corresponding labels. it will be done with the help of figure function of plt and set fig size is equal to the tuple of integers 25*4, which will specify the width and height of the figure.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>fig=plt.figure(figsize=(25,4))  </code></pre>\n\n\n\n<p>Now, we plot 20 MNIST images from our batch. We use add_subplot() method to add a subplot to the current figure and pass 2, 10, and idx as arguments of the function. Here two is no of rows, ten is no of columns, and idx is index.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>ax=fig.add_subplot(2,10,idx+1)  </code></pre>\n\n\n\n<p>Now, we will display our images with the help of im_show() function and give a title for each image plot as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.imshow(im_convert(images&#91;idx]))   \nax.set_title(\"{}({})\".format(str(preds&#91;idx].item()),str(labels&#91;idx].item())),color=(\"green\" if preds&#91;idx]==labels&#91;idx] else \"red\"))  </code></pre>\n\n\n\n<p>Finally call plt.show() and it will give us the expected result.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-image-recognition-model5.png\" alt=\"Testing of Image Recognition Model in PyTorch\"/></figure>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete code:</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nimport PIL.ImageOps  \nfrom torch import nn  \nfrom torchvision import datasets,transforms   \nimport requests  \nfrom PIL import Image  \ntransform1=transforms.Compose(&#91;transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \nvalidation_dataset=datasets.MNIST(root='./data',train=False,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \nvalidation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False)  \ndef im_convert(tensor):  \n    image=tensor.clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \ndataiter=iter(training_loader)  \nimages,labels=dataiter.next()  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1)  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(&#91;labels&#91;idx].item()])  \nclass classification1(nn.Module):  \n    def __init__(self,input_layer,hidden_layer1,hidden_layer2,output_layer):  \n        super().__init__()  \n        self.linear1=nn.Linear(input_layer,hidden_layer1)  \n        self.linear2=nn.Linear(hidden_layer1,hidden_layer2)  \n        self.linear3=nn.Linear(hidden_layer2,output_layer)  \n    def forward(self,x):  \n        x=func.relu(self.linear1(x))  \n        x=func.relu(self.linear2(x))  \n        x=self.linear3(x)  \n        return x  \nmodel=classification1(784,125,65,10)  \ncriteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.0001)  \nepochs=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]  \nval_loss_history=&#91;]  \nval_correct_history=&#91;]  \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \n    val_loss=0.0  \n    val_correct=0.0  \n    for input,labels in training_loader:  \n        inputs=input.view(input.shape&#91;0],-1)  \n        outputs=model(inputs)  \n        loss1=criteron(outputs,labels)  \n        optimizer.zero_grad()  \n        loss1.backward()  \n        optimizer.step()  \n        _,preds=torch.max(outputs,1)  \n        loss+=loss1.item()  \n        correct+=torch.sum(preds==labels.data)  \n    else:  \n        with torch.no_grad():  \n            for val_input,val_labels in validation_loader:  \n                val_inputs=val_input.view(val_input.shape&#91;0],-1)  \n                val_outputs=model(val_inputs)  \n                val_loss1=criteron(val_outputs,val_labels)   \n                _,val_preds=torch.max(val_outputs,1)  \n                val_loss+=val_loss1.item()  \n                val_correct+=torch.sum(val_preds==val_labels.data)  \n        epoch_loss=loss/len(training_loader.dataset)  \n        epoch_acc=correct.float()/len(training_dataset)  \n        loss_history.append(epoch_loss)  \n        correct_history.append(epoch_acc)  \n          \n        val_epoch_loss=val_loss/len(validation_loader.dataset)  \n        val_epoch_acc=val_correct.float()/len(validation_dataset)  \n        val_loss_history.append(val_epoch_loss)  \n        val_correct_history.append(val_epoch_acc)  \n        print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  \n        print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  \n  \nurl='https://images.homedepot-static.com/productImages/007164ea-d47e-4f66-8d8c-fd9f621984a2/svn/architectural-mailboxes-house-letters-numbers-3585b-5-64_1000.jpg'  \nresponse=requests.get(url,stream=True)  \nimg=Image.open(response.raw)  \nimg=PIL.ImageOps.invert(img)  \nimg=img.convert('1')  \nimg=transform1(img)   \nplt.imshow(im_convert(img))  \nimg=img.view(img.shape&#91;0],-1)  \noutput=model(img)  \n_,pred=torch.max(output,1)  \nprint(pred.item())  \n  \ndataiter=iter(validation_loader)  \nimages,labels=dataiter.next()  \nimages_=images.view(images.shape&#91;0],-1)  \noutput=model(images_)  \n_,preds=torch.max(output,1)  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1,xticks=&#91;],yticks=&#91;])  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(\"{}({})\".format(str(preds&#91;idx].item()),str(labels&#91;idx].item())),color=(\"green\" if preds&#91;idx]==labels&#91;idx] else \"red\"))  \nplt.show() </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-image-recognition-model6.png\" alt=\"Testing of Image Recognition Model in PyTorch\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-image-recognition-model7.png\" alt=\"Testing of Image Recognition Model in PyTorch\"/></figure>\n\n\n\n<p>It predicts all of them correctly except one, and that is to be expected from our&nbsp;<strong>Deep Neural Network</strong>&nbsp;because realistically image classification is best done with a&nbsp;<strong>convolutional neural network</strong>.</p>\n","protected":false},"excerpt":{"rendered":"<p>In the last section, we implemented a neural network or created a model which classified the handwritten digits. Now, we test our model by grabbing an image from the web. We used the following image: When you paste this link on your browser, you will see the image of number five as: After seeing this, [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2224,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1378"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1378"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1378/revisions"}],"predecessor-version":[{"id":2242,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1378/revisions/2242"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2224"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1378"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1378"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1378"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1379,"date":"2020-05-21T09:18:24","date_gmt":"2020-05-21T09:18:24","guid":{"rendered":"http://python3.foobrdigital.com/?p=1379"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"cnn","status":"publish","type":"post","link":"https://python3.foobrdigital.com/cnn/","title":{"rendered":"CNN"},"content":{"rendered":"\n<p><strong>Convolutional Neural Network</strong>&nbsp;is one of the main categories to do image classification and image recognition in neural networks. Scene labeling, objects detections, and face recognition, etc., are some of the areas where convolutional neural networks are widely used.</p>\n\n\n\n<p>CNN takes an image as input, which is classified and process under a certain category such as dog, cat, lion, tiger, etc. The computer sees an image as an array of pixels and depends on the resolution of the image. Based on image resolution, it will see as&nbsp;<strong>h * w * d</strong>, where h= height w= width and d= dimension. For example, An RGB image is&nbsp;<strong>6 * 6 * 3</strong>&nbsp;array of the matrix, and the grayscale image is&nbsp;<strong>4 * 4 * 1</strong>&nbsp;array of the matrix.</p>\n\n\n\n<p>In CNN, each input image will pass through a sequence of convolution layers along with pooling, fully connected layers, filters (Also known as kernels). After that, we will apply the Soft-max function to classify an object with probabilistic values 0 and 1.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network.jpg\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<h2>Convolution Layer</h2>\n\n\n\n<p>Convolution layer is the first layer to extract features from an input image. By learning image features using a small square of input data, the convolutional layer preserves the relationship between pixels. It is a mathematical operation which takes two inputs such as image matrix and a kernel or filter.</p>\n\n\n\n<ul><li>The dimension of the image matrix is&nbsp;<strong>h×w×d</strong>.</li><li>The dimension of the filter is&nbsp;<strong>f<sub>h</sub>×f<sub>w</sub>×d</strong>.</li><li>The dimension of the output is&nbsp;<strong>(h-f<sub>h</sub>+1)×(w-f<sub>w</sub>+1)×1</strong>.</li></ul>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network2.png\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<p>Let&#8217;s start with consideration a 5*5 image whose pixel values are 0, 1, and filter matrix 3*3 as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network3.png\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<p>The convolution of 5*5 image matrix multiplies with 3*3 filter matrix is called &#8220;<strong>Features Map</strong>&#8221; and show as an output.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network4.png\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<p>Convolution of an image with different filters can perform an operation such as blur, sharpen, and edge detection by applying filters.</p>\n\n\n\n<h2>Strides</h2>\n\n\n\n<p>Stride is the number of pixels which are shift over the input matrix. When the stride is equaled to 1, then we move the filters to 1 pixel at a time and similarly, if the stride is equaled to 2, then we move the filters to 2 pixels at a time. The following figure shows that the convolution would work with a stride of 2.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network5.png\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<h2>Padding</h2>\n\n\n\n<p>Padding plays a crucial role in building the convolutional neural network. If the image will get shrink and if we will take a neural network with 100&#8217;s of layers on it, it will give us a small image after filtered in the end.</p>\n\n\n\n<p>If we take a three by three filter on top of a grayscale image and do the convolving then what will happen?</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network6.png\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<p>It is clear from the above picture that the pixel in the corner will only get covers one time, but the middle pixel will get covered more than once. It means that we have more information on that middle pixel, so there are two downsides:</p>\n\n\n\n<ul><li>Shrinking outputs</li><li>Losing information on the corner of the image.</li></ul>\n\n\n\n<p>To overcome this, we have introduced padding to an image.&nbsp;<strong>&#8220;Padding is an additional layer which can add to the border of an image.&#8221;</strong></p>\n\n\n\n<h2>Pooling Layer</h2>\n\n\n\n<p>Pooling layer plays an important role in pre-processing of an image. Pooling layer reduces the number of parameters when the images are too large. Pooling is &#8220;<strong>downscaling</strong>&#8221; of the image obtained from the previous layers. It can be compared to shrinking an image to reduce its pixel density. Spatial pooling is also called downsampling or subsampling, which reduces the dimensionality of each map but retains the important information. There are the following types of spatial pooling:</p>\n\n\n\n<h3>Max Pooling</h3>\n\n\n\n<p>Max pooling is a&nbsp;<strong>sample-based discretization process</strong>. Its main objective is to downscale an input representation, reducing its dimensionality and allowing for the assumption to be made about features contained in the sub-region binned.</p>\n\n\n\n<p>Max pooling is done by applying a max filter to non-overlapping sub-regions of the initial representation.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network7.png\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network8.png\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<h3>Average Pooling</h3>\n\n\n\n<p>Down-scaling will perform through average pooling by dividing the input into rectangular pooling regions and computing the average values of each region.</p>\n\n\n\n<p><strong>Syntax</strong></p>\n\n\n\n<pre class=\"wp-block-preformatted\">layer = averagePooling2dLayer(poolSize)\nlayer = averagePooling2dLayer(poolSize,Name,Value)\n</pre>\n\n\n\n<h3>Sum Pooling</h3>\n\n\n\n<p>The sub-region for&nbsp;<strong>sum pooling</strong>&nbsp;or&nbsp;<strong>mean pooling</strong>&nbsp;are set exactly the same as for&nbsp;<strong>max-pooling</strong>&nbsp;but instead of using the max function we use sum or mean.</p>\n\n\n\n<h2>Fully Connected Layer</h2>\n\n\n\n<p>The fully connected layer is a layer in which the input from the other layers will be flattened into a vector and sent. It will transform the output into the desired number of classes by the network.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network9.png\" alt=\"Convolutional Neural Network\"/></figure>\n\n\n\n<p>In the above diagram, the feature map matrix will be converted into the vector such as&nbsp;<strong>x1, x2, x3&#8230; xn</strong>&nbsp;with the help of fully connected layers. We will combine features to create a model and apply the activation function such as&nbsp;<strong>softmax</strong>&nbsp;or&nbsp;<strong>sigmoid</strong>&nbsp;to classify the outputs as a car, dog, truck, etc.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network10.png\" alt=\"Convolutional Neural Network\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>Convolutional Neural Network&nbsp;is one of the main categories to do image classification and image recognition in neural networks. Scene labeling, objects detections, and face recognition, etc., are some of the areas where convolutional neural networks are widely used. CNN takes an image as input, which is classified and process under a certain category such as [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2225,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1379"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1379"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1379/revisions"}],"predecessor-version":[{"id":1388,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1379/revisions/1388"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2225"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1379"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1379"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1379"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1380,"date":"2020-05-21T09:21:47","date_gmt":"2020-05-21T09:21:47","guid":{"rendered":"http://python3.foobrdigital.com/?p=1380"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"image-transforms-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/image-transforms-2/","title":{"rendered":"Image Transforms"},"content":{"rendered":"\n<p>Loading and transformation are two main concepts which are essential to do image recognition in PyTorch. Loading and transformation of the images is the starting step of the recognition process.</p>\n\n\n\n<p>There are the following steps which are the step by step procedure to do loading and transformation:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we install all the require library such as pip, torchvision, numpy, etc. If all the required library is already satisfied, then we import torch, and then we import datasets and transforms from torchvision. For plotting our dataset, we will import matplotlib.pyplot library and we will also import numpy to perform operations. The libraries are imported as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nfrom torchvision import datasets, transforms  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the second step, we load the MNIST dataset using the MNIST () method of datasets. In the first argument, we specified the root directory of our data as following</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_dataset=datasets.MNIST(root='./data')   </code></pre>\n\n\n\n<p>In the second argument, we set train=&#8217;true&#8217;. We will do this to initialize the MNIST training dataset. After that, we set download =&#8217;true&#8217; and this will download a list into the data folder if it&#8217;s not already there.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Training_dataset=datasets.MNIST(root='./data',train=True,download=True)    </code></pre>\n\n\n\n<p>The last argument will be transform which is equal to&nbsp;<strong>transform1</strong>&nbsp;argument that will initialize before the&nbsp;<strong>training_dataset</strong>. This argument dictates any image manipulation which you wish to apply on your images.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  </code></pre>\n\n\n\n<p><strong>Note:</strong>&nbsp;Our MNIST images are 28*28 grayscale images which would imply that each image is a two dimensional number by array 28 pixels wide and 28 pixels long and each pixel intensity ranging from 0 to 255.</p>\n\n\n\n<p>We must transform the image being in an array to a tensor. We will use Compose () method of transforms which will allow us to chain multiple transformations together . So our first transformation, which is passed as a first argument of composed, will transform.ToTensor(). This will convert our numpy array in the range of 0 to 255 to a float tensor in the range from 0 to 1.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform1=transforms.Compose(&#91;transforms.ToTensor()])  </code></pre>\n\n\n\n<p>We will also apply the normalize transformation with the help of normalize() method of transforms as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform1=transforms.Compose(&#91;transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  </code></pre>\n\n\n\n<p>In the normalize() method, we specified the mean which we are used to normalizing all channels of our tensor image, and we also specified the center deviation. Now, we call our training dataset as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_dataset  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-image-transforms-in-image-recognition.png\" alt=\"Image Transforms in Image Recognition\"/></figure>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>We will further analyze images within this dataset by plotting it. To plot the tensor image, we must change it back to numpy array. We will do this work in a function def im_convert() contain one parameter which will be our tensor image.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def im_convert(tensor):  </code></pre>\n\n\n\n<p>Before converting tensor to numpy array, first, we will clone it. It will create a new copy of tensor, and then we use the detach() function and then we will use numpy as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=tensor.clone().detach().numpy()  </code></pre>\n\n\n\n<p><strong>Note:</strong>&nbsp;The tensor which will be converted into numpy array has a shape with the first, second, and third dimensions. The first dimension represents the color channel, and the second and the third dimensions represent the width and height of the image and pixels.</p>\n\n\n\n<p>We know each image from the MNIST dataset is a grayscale corresponding to a single color channel with a width and height of 28*28 pixels. So, the shape would be (1, 28, 28).</p>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>For plotting our image, it is required that the image have a shape of (28, 28, 1). So, we will transpose our image by swapping axis zero, one, and two as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=image.transpose(1,2,0)    </code></pre>\n\n\n\n<p>This method swap axis 0 with axis 1 and axis 1 with axis 2.</p>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>In the next step, we de-normalized the image which we have to normalize before. Normalization is done by subtracting the mean and dividing by the standard deviation. We would multiply by the standard deviation and add the mean as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))   </code></pre>\n\n\n\n<p>To ensure that the range between 0 and 1, we used&nbsp;<strong>clip()</strong>&nbsp;function and pass zero and one as an argument. We will apply the clip function to a minimum value of 0 and the maximum value of 1 and return the image.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=image.clip(0,1)  \nreturn image  </code></pre>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>Now, we plot our MNIST dataset for better visualization. We will start by loading the image from&nbsp;<strong>training_loader()</strong>. The training loader is what we used to specify our training batches previously when training our neural network. For every epoch, we performed a single pass through the entire dataset. However, one epoch with sixty thousand training images would be too big to fit the computer all at once. So we will divide it into smaller batches using our train loader as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)   </code></pre>\n\n\n\n<p>The first argument is a dataset, which is equal to our training_dataset. The second argument is our batch size, which is equal to 100. The third argument, we set shuffle is equal to true.</p>\n\n\n\n<p><strong>Note:</strong>&nbsp;The batch size of 100 would take 600 iterations to complete one epoch and that each iteration it will update the weights of the neural network and minimizing the error.</p>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>In the next step, we wrap our train loader. It will create an object which allows us to go through the alterable training loader one element at a time. We access it one element at a time by calling next on our dataiter. The next () function will grab the first batch of our training data, and that training data will be split into images and labels as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>dataiter=iter(training_loader)  \nimages,labels=dataiter.next()</code></pre>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>Now, we will plot the images in the batch along with their corresponding labels. This will be done with the help of figure function of plt and set fig size is equal to the tuple of integers 25*4, which will specify the width and height of the figure.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>fig=plt.figure(figsize=(25,4))  </code></pre>\n\n\n\n<p>Now, we plot 20 MNIST images from our batch. We use add_subplot() method to add a subplot to the current figure and pass 2, 10, and idx as arguments of the function. Here two is no of rows, ten is no of columns, and idx is index.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>ax=fig.add_subplot(2,10,idx+1)  </code></pre>\n\n\n\n<p>Now, we will display our images with the help of im_show() function and give a title for each image plot as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.imshow(im_convert(images&#91;idx]))   \nax.set_title(&#91;labels&#91;idx].item()])</code></pre>\n\n\n\n<p>Finally call plt.show() and it will give us the expected result.</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete code</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nfrom torchvision import datasets,transforms   \ntransform1=transforms.Compose(&#91;transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \ndef im_convert(tensor):  \n    image=tensor.clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \ndataiter=iter(training_loader)  \nimages,labels=dataiter.next()  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1)  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(&#91;labels&#91;idx].item()])  \nplt.show()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-image-transforms-in-image-recognition2.png\" alt=\"Image Transforms in Image Recognition\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-image-transforms-in-image-recognition3.png\" alt=\"Image Transforms in Image Recognition\"/></figure>\n\n\n\n<p>Now, with the help of these label images, we will implement a neural network which will classify new test images.</p>\n","protected":false},"excerpt":{"rendered":"<p>Loading and transformation are two main concepts which are essential to do image recognition in PyTorch. Loading and transformation of the images is the starting step of the recognition process. There are the following steps which are the step by step procedure to do loading and transformation: Step 1: In the first step, we install [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2226,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1380"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1380"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1380/revisions"}],"predecessor-version":[{"id":2243,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1380/revisions/2243"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2226"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1380"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1380"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1380"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1395,"date":"2020-05-21T09:24:29","date_gmt":"2020-05-21T09:24:29","guid":{"rendered":"http://python3.foobrdigital.com/?p=1395"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"convolutional-neural-network-implementation","status":"publish","type":"post","link":"https://python3.foobrdigital.com/convolutional-neural-network-implementation/","title":{"rendered":"Convolutional Neural Network implementation"},"content":{"rendered":"\n<p>We used a deep neural network to classify the endless dataset, and we found that it will not classify our data best. When we used the deep neural network, the model accuracy was not sufficient, and the model could improve. This improvement will be made with the help of the convolutional neural network. Let&#8217;s start the implementation of our&nbsp;<strong>Convolutional Neural Network</strong>&nbsp;for&nbsp;<strong>Image Recognition</strong>.</p>\n\n\n\n<p><strong>There are the following steps to implement the CNN for image recognition:</strong></p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we will define the class which will be used to create our neural model instances. CNN model includes&nbsp;<strong>LeNet model, AlexNet model, ZFNet model,</strong>&nbsp;and&nbsp;<strong>GoogleNet model</strong>. These models are of increasing complexity and performance, and we will use&nbsp;<strong>LeNet model</strong>. This model is simple, effective, and should be sufficient for accurate classification of the endless dataset.</p>\n\n\n\n<p>The&nbsp;<strong>LeNet model</strong>&nbsp;looks like:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-cnn-implementation.png\" alt=\"PyTorch Convolutional Neural Network implementation\"/></figure>\n\n\n\n<p>The class will be inherited from the nn module, so we first have to import the nn package.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from torch import nn   \nclass LeNet (nn.Module):</code></pre>\n\n\n\n<p>Our class will be followed by an init() method. In init() method first argument will always self.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def __init__(self):  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the second step, we recall the init() method for the provision of various method and attributes. We will initialize the convolution layer with four input parameters i.e., number of input channels (It is an input layer so we will be used 1 input channel ), number of output channels(we will be used 20 output channels for effective feature extraction), kernel size(we will be used 5 for kernel size) and stride length( we use 1 for stride length because if we are chosen a larger stride length, it will result in less effective extraction). We will unwrap this entire command into a variable and attached to self-object within our class.</p>\n\n\n\n<p>Similarly, we will define our next convolution layer and will adjust its parameters accordingly.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>super().__init__()  \nself.conv1=nn.Con2d(1, 20, 5, 1)  \nself.conv2=nn.Con2d(20, 50, 5, 1)  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>In the next step, we will define our two fully connected layers using nn.Linear() with appropriate arguments.</p>\n\n\n\n<p>The first convolution will decrease the dimensions of the input images from 28 by 28 to 24 by 24. The data will then feed through a 2 by 2 pooling layer which cuts the size of the images and converts it into 12 by 12. The next convolution layer decreases the size of 12 by 12 image to 8 by 8 images. Another 5 by 5 pooling layer cut the size of 8 by 8 images into 4 by 4 images. So the input channels which will pass into the first fully connected layer will be 4×4×50 and 500 output channels as a second argument.</p>\n\n\n\n<p>Similarly, we will define the second fully connected layers by adjusting its parameters accordingly.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.fully1=nn.Linear(4*4*50,500)  \nself.fully2=nn.Linear(500,10)  </code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>Now, we will define the pooling layer and the activation functions of each layer in the forward function, but before it, we will import the torch.nn.functional package, and then we will use the forward() function and place self as a first argument and x for whatever input we will try to make the prediction.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch.nn.functional as func  \ndef forward(self,x): </code></pre>\n\n\n\n<p>Now, we will define our&nbsp;<strong>relu</strong>&nbsp;function and connect to our first convolution layer, and then we will define the pooling layer with the help of max_pool2d() with appropriate argument.</p>\n\n\n\n<p>The first argument will be feed-forward x value, and the next two-arguments will define the size of the max-pooling kernel and will be unwrapped into the x variable.</p>\n\n\n\n<p>Similarly, this process will do for our second convolution and pooling layer.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x=func.relu(self.conv1(x))  \nx=func.max_pool2d(x, 2,2)  \nx=func.relu(self.conv1(x))  \nx=func.max_pool2d(x, 2,2)  \nx=x.view(-1, 4*4*50)    #Reshaping the output into desired shape  \nx=func.relu(self.fully1(x)) #Applying relu activation function to our first fully connected layer  \nx=self.fully2(x)    #We will not apply activation function here because we are dealing with multiclass dataset  \nreturn x  </code></pre>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>In the next step, we will set up out model constructor. There is no need to pass anything in initializer. So</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model=LeNet()      </code></pre>\n\n\n\n<p>Our CNN model is implemented and now, we will discuss about its implementation in Implementation of CNN</p>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete Code:</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nimport PIL.ImageOps  \nfrom torch import nn  \nfrom torchvision import datasets,transforms   \ntransform1=transforms.Compose(&#91;transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \ndef im_convert(tensor):  \n    image=tensor.clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \ndataiter=iter(training_loader)  \nimages,labels=dataiter.next()  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1)  \n    plt.imshow(im_convert(images&#91;idx]))  \n   ax.set_title(&#91;labels&#91;idx].item()])  \nclass LeNet(nn.Module):  \n        def __init__(self):  \n            super().__init__()  \n            self.conv1=nn.Conv2d(1,20,5,1)  \n            self.conv2=nn.Conv2d(20,50,5,1)  \n            self.fully1=nn.Linear(4*4*50,500)  \n            self.fully2=nn.Linear(500,10)  \n        def forward(self,x):  \n            x=func.relu(self.conv1(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=func.relu(self.conv2(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=x.view(-1,4*4*50) #Reshaping the output into desired shape  \n            x=func.relu(self.fully1(x)) #Applying relu activation function to our first fully connected layer  \n            x=self.fully2(x)    #We will not apply activation function here because we are dealing with multiclass dataset  \n            return x      \nmodel=LeNet() </code></pre>\n","protected":false},"excerpt":{"rendered":"<p>We used a deep neural network to classify the endless dataset, and we found that it will not classify our data best. When we used the deep neural network, the model accuracy was not sufficient, and the model could improve. This improvement will be made with the help of the convolutional neural network. Let&#8217;s start [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2227,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1395"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1395"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1395/revisions"}],"predecessor-version":[{"id":1404,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1395/revisions/1404"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2227"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1395"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1395"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1395"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1396,"date":"2020-05-21T09:29:09","date_gmt":"2020-05-21T09:29:09","guid":{"rendered":"http://python3.foobrdigital.com/?p=1396"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"training-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/training-2/","title":{"rendered":"Training"},"content":{"rendered":"\n<p>In the last topic, we implemented our CNN model. Now, our next task is to train it. For training our CNN model, we will involve CUDA tensor type which will implement the same function as CPU tensors, but they utilize for computation.</p>\n\n\n\n<p><strong>There are the following steps to train our CNN model:</strong></p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step of the training section, we will specify the device with the help of&nbsp;<strong>torch.device()</strong>. We will check for CUDA; if CUDA will be available, then we used Cuda else we will use CPU.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the next step, we will assign our model to our device as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model=LeNet.to(device)  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Now, we will define our loss function. The loss function will define in the same way as we have defined in our previous model in which we have used a deep neural network.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>criteron=nn.CrossEntropyLoss()  </code></pre>\n\n\n\n<p>After that, we will use the familiar optimizer, i.e., Adam as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>optimizer=torch.optim.Adam(model.parameters(),lr=0.00001)</code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>In the next step, we will specify number of epochs. We initialize number of epochs and analyzing the loss at every epoch with the plot. We will initialize two lists, i.e., loss_history and correct history.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>epoch=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]  </code></pre>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>We will start by iterating through every epoch, and for every epoch, we must iterate through every single training batch that&#8217;s provided to us by the training loader. Each training batch contains one hundred images as well as one hundred labels in a train in training loader as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>for e in range(epochs):  \n    for input, labels in training_loader:  </code></pre>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>We are dealing with the convolutional neural network in which the inputs are first being passed. We will pass the images in the four dimensionalities, so there is no need to flatten them.</p>\n\n\n\n<p>As we have assigned our model to our device, in the same way, we assign inputs and labels to our devices also.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>input=input.to(device)  \nlabels=labels.to(device) </code></pre>\n\n\n\n<p>Now, with the help of these inputs, we get outputs as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>outputs=model(inputs)   </code></pre>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>In the next step, we will perform the optimization algorithm in the same way as we have done before in image recognition.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>loss1=criteron(outputs,labels)  \noptimizer.zero_grad()  \nloss1.backward()  \noptimizer.step()</code></pre>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>To keep track of the losses at every epoch, we will initialize a variable loss, i.e., running_loss. For every loss which is computed as per batch, we must add all up for every single batch and then compute the final loss at every epoch.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>loss+=loss1.item()  </code></pre>\n\n\n\n<p>Now, we will append this accumulated loss for the entire epoch into our losses list. For this, we use an else statement after the looping statement. So once the for loop is finished, then the else statement is called. In this else statement we will print the accumulated loss which was computed for the entire dataset at that specific epoch.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>epoch_loss=loss/len(training_loader)  \nloss_history.append(epoch_loss)   </code></pre>\n\n\n\n<p><strong>Step 11:</strong></p>\n\n\n\n<p>In the next step, we will find the accuracy of our network. We will initialize the correct variable and assign the value zero. We will compare the predictions made by the model for each training image to the actual labels of the images to show how many of them get correct within an epoch.</p>\n\n\n\n<p>For each image, we will take the maximum score value. In such that case a tuple is returned. The first value it gives back is the actual top value &#8211; the maximum score, which was made by the model for every single image within this batch of images. So, we are not interested in the first tuple value, and the second will correspond to the top predictions made by the model which we will call preds. It will return the index of the maximum value for that image.-</p>\n\n\n\n<pre class=\"wp-block-code\"><code>_,preds=torch.max(outputs,1)  </code></pre>\n\n\n\n<p><strong>Step 12:</strong></p>\n\n\n\n<p>Each image output will be a collection of values with indices ranging from 0 to 9 such that the MNIST dataset contains classes from 0 to 9. It follows that the prediction where the maximum value occurs corresponds to the prediction made by the model. We will compare all of these predictions made by the model to the actual labels of the images to see how many of them they got correct.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>correct+=torch.sum(preds==labels.data)  </code></pre>\n\n\n\n<p>This will give the number of correct predictions for every single batch of images. We will define the epoch accuracy in the same way as epoch loss and print both epoch loss and accuracy as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>epoch_acc=correct.float()/len(training_loader)    \nprint('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))</code></pre>\n\n\n\n<p>This will give the expected result as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/training-of-cnn-pytorch.png\" alt=\"PyTorch Training\"/></figure>\n\n\n\n<p><strong>Step 13:</strong></p>\n\n\n\n<p>Now, we will append the accuracy for the entire epoch into our correct_history list, and for better visualization, we will plot both epoch loss and accuracy as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(loss_history,label='Running Loss History')  \nplt.plot(correct_history,label='Running correct History')  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/training-of-cnn-pytorch1.png\" alt=\"PyTorch Training\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/training-of-cnn-pytorch2.png\" alt=\"PyTorch Training\"/></figure>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete Code:</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nimport PIL.ImageOps  \nfrom torch import nn  \nfrom torchvision import datasets,transforms   \ndevice=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \ntransform1=transforms.Compose(&#91;transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \nclass LeNet(nn.Module):  \n        def __init__(self):  \n            super().__init__()  \n            self.conv1=nn.Conv2d(1,20,5,1)  \n            self.conv2=nn.Conv2d(20,50,5,1)  \n            self.fully1=nn.Linear(4*4*50,500)  \n            self.fully2=nn.Linear(500,10)  \n        def forward(self,x):  \n            x=func.relu(self.conv1(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=func.relu(self.conv2(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=x.view(-1,4*4*50) #Reshaping the output into desired shape  \n            x=func.relu(self.fully1(x)) #Applying relu activation function to our first fully connected layer  \n            x=self.fully2(x)    #We will not apply activation function here because we are dealing with multiclass dataset  \n            return x      \nmodel=LeNet().to(device)  \ncriteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.00001)   \nepochs=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]   \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \n    for inputs,labels in training_loader:  \n        inputs=inputs.to(device)  \n        labels=labels.to(device)  \n        outputs=model(inputs)  \n        loss1=criteron(outputs,labels)  \n        optimizer.zero_grad()  \n        loss1.backward()  \n        optimizer.step()  \n        _,preds=torch.max(outputs,1)  \n        loss+=loss1.item()  \n        correct+=torch.sum(preds==labels.data)  \n    else:  \n        epoch_loss=loss/len(training_loader)  \n        epoch_acc=correct.float()/len(training_loader)  \n        loss_history.append(epoch_loss)  \n        correct_history.append(epoch_acc)  \n  \n    print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  \nplt.plot(loss_history,label='Running Loss History')  \nplt.plot(correct_history,label='Running correct History')  \nplt.show()  </code></pre>\n","protected":false},"excerpt":{"rendered":"<p>In the last topic, we implemented our CNN model. Now, our next task is to train it. For training our CNN model, we will involve CUDA tensor type which will implement the same function as CPU tensors, but they utilize for computation. There are the following steps to train our CNN model: Step 1: In [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2228,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1396"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1396"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1396/revisions"}],"predecessor-version":[{"id":2244,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1396/revisions/2244"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2228"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1396"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1396"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1396"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1397,"date":"2020-05-21T09:33:40","date_gmt":"2020-05-21T09:33:40","guid":{"rendered":"http://python3.foobrdigital.com/?p=1397"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"validation-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/validation-2/","title":{"rendered":"Validation"},"content":{"rendered":"\n<p>In the training section, we trained our CNN model on the MNIST dataset (Endless dataset), and it seemed to reach a reasonable loss and accuracy. If the model can take what it has learned and generalize itself to new data, then it would be a true testament to its performance. This will be done in the same way as we have done in our previous topic.</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>We will create our validation set with the help of our training dataset, which we have created in the training section. In this time we will set train equals to false as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>validation_dataset=datasets.MNIST(root='./data',train=False,download=True,transform=transform1)  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>Now, similar to why we have declared a training loader in the training section, we will define a validation loader. Validation loader will also create in the same way as we have created training loader, but this time we pass training loader rather than training the dataset, and we set shuffle equals to false because we will not be trained our validation data. There is no need to shuffle it because it is only for testing purpose.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>validation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False)  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Our next step is to analyze the validation loss and accuracy at every epoch. For this purpose, we have to create two lists for validation running lost, and validation running loss corrects.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_loss_history=&#91;]  \nval_correct_history=&#91;]  </code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>In the next step, we will validate the model. The model will validate the same epoch. After we finished iterating through the entire training set to train our data, we will now iterate through our validation set to test our data.</p>\n\n\n\n<p>We will first measure for two things. The first one is the performance of our model, i.e., how many correct classifications. Our model makes on the test set on the validation set to check for overfitting. We will set running loss and running corrects of validation as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_loss=0.0  \nval_correct=0.0  </code></pre>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>We can now loop through our test data. So after the else statement, we will define a loop statement for labels and inputs as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>for val_input,val_labels in validation_loader:  </code></pre>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>We are dealing with the convolutional neural network to which the inputs are first being passed. We will focus on the four dimensionalities of these images. So there is no need to flatten them.</p>\n\n\n\n<p>As we have assigned our model to our device, in the same way, we assign inputs and labels to our devices also.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>input=input.to(device)  \nlabels=input.to(device)  </code></pre>\n\n\n\n<p>Now, with the help of these inputs, we get outputs as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_outputs=model(val_inputs)  </code></pre>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>With the help of the outputs, we will calculate the total categorical cross-entropy loss, and the output is ultimately compared with the actual labels.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_loss1=criteron(val_outputs,val_labels)  </code></pre>\n\n\n\n<p>We are not training our neural network, so there is no need to call zero_grad(), backward() or any of that. And there is also no need to compute derivative anymore. In the scope of operation to save memory, we call no_grad() method before For loop with the torch as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>with torch.no_grad():  </code></pre>\n\n\n\n<p>It will temporarily set all the require grad flag to be false.</p>\n\n\n\n<p><strong>Step 8:</strong></p>\n\n\n\n<p>Now, we will calculate the validation loss and accuracy in the same way as we have calculated the training loss and training accuracy as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>_,val_preds=torch.max(val_outputs,1)  \nval_loss+=val_loss1.item()  \nval_correct+=torch.sum(val_preds==val_labels.data)  </code></pre>\n\n\n\n<p><strong>Step 9:</strong></p>\n\n\n\n<p>Now, we will calculate the validation epoch loss which will be done as same as how we calculate the training epoch loss where we divide the total running loss by the length of the dataset. So it will be write as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>val_epoch_loss=val_loss/len(validation_loader)  \nval_epoch_acc=val_correct.float()/len(validation_loader)  \nval_loss_history.append(val_epoch_loss)  \nval_correct_history.append(val_epoch_acc)  </code></pre>\n\n\n\n<p><strong>Step 10:</strong></p>\n\n\n\n<p>We will print validation loss and validation accuracy as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-cnn.png\" alt=\"Validation of Convolutional Neural Network\"/></figure>\n\n\n\n<p><strong>Step 11:</strong></p>\n\n\n\n<p>Now, we will plot it for visualization purpose. We will plot it as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(loss_history,label='Training Loss')  \nplt.plot(val_loss_history,label='Validation Loss')  \nplt.legend()  \nplt.show()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-cnn2.png\" alt=\"Validation of Convolutional Neural Network\"/><figcaption><br></figcaption></figure>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.plot(correct_history,label='Training accuracy')  \nplt.plot(val_correct_history,label='Validation accuracy')  \nplt.legend()  \nplt.show()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-cnn3.png\" alt=\"Validation of Convolutional Neural Network\"/></figure>\n\n\n\n<p>It is clear from the above diagrams that in CNN overfitting occurs. To reduce this overfitting, we will introduce another quick technique named Dropout Layer.</p>\n\n\n\n<p><strong>Step 12:</strong></p>\n\n\n\n<p>In the next step, we will move to our LeNet class and add a specific layer type which will reduce overfitting of our data. This layer type is called Dropout layer. This layer essentially functions by randomly setting a fraction rate of input units to 0, and each update during training.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-cnn4.png\" alt=\"Validation of Convolutional Neural Network\"/></figure>\n\n\n\n<p>The above diagram shows a standard neural network as well as it shows the same neural network after applying dropout. We can see that some nodes have been turned off and are no longer communicating with information along with the network.</p>\n\n\n\n<p>We will use more than one dropout layer which will be used in a given network to obtain the desired performance. We will place these dropout layer between the convolutional layers and between the fully connected layers. The dropout layer is used in between layers which have a high number of parameters because these high parameter layers are more likely to overfit and memorize the training data. So we will set our dropout layer in between the fully connected layer.</p>\n\n\n\n<p>We will initialize our dropout layer with the help of nn.Dropout module and pass the dropout rate as an argument in our initializer. The probability of a given node being dropped out will be set 0.5 as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.dropout1=nn.dropout(0.5)   </code></pre>\n\n\n\n<p><strong>Step 13:</strong></p>\n\n\n\n<p>In the next step, we will define our second dropout layer in between our fully connected layer in forward function as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x=self.dropout1(x)  </code></pre>\n\n\n\n<p>Now, we will run our program and it will give us more accurate result as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-cnn5.png\" alt=\"Validation of Convolutional Neural Network\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-cnn6.png\" alt=\"Validation of Convolutional Neural Network\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-validation-of-cnn7.png\" alt=\"Validation of Convolutional Neural Network\"/></figure>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete Code</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nimport PIL.ImageOps  \nfrom torch import nn  \nfrom torchvision import datasets,transforms   \ndevice=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \ntransform1=transforms.Compose(&#91;transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \nvalidation_dataset=datasets.MNIST(root='./data',train=False,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \nvalidation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False)  \nclass LeNet(nn.Module):  \n        def __init__(self):  \n            super().__init__()  \n            self.conv1=nn.Conv2d(1,20,5,1)  \n            self.conv2=nn.Conv2d(20,50,5,1)  \n            self.fully1=nn.Linear(4*4*50,500)  \n            self.dropout1=nn.Dropout(0.5)   \n            self.fully2=nn.Linear(500,10)  \n        def forward(self,x):  \n            x=func.relu(self.conv1(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=func.relu(self.conv2(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=x.view(-1,4*4*50) #Reshaping the output into desired shape  \n            x=func.relu(self.fully1(x)) #Applying relu activation function to our first fully connected layer  \n            x=self.dropout1(x)  \n            x=self.fully2(x)    #We will not apply activation function here because we are dealing with multiclass dataset  \n            return x      \nmodel=LeNet().to(device)  \ncriteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.00001)   \nepochs=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]  \nval_loss_history=&#91;]  \nval_correct_history=&#91;]  \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \n    val_loss=0.0  \n    val_correct=0.0  \n    for input,labels in training_loader:  \n        input=input.to(device)  \n        labels=labels.to(device)  \n        outputs=model(input)  \n        loss1=criteron(outputs,labels)  \n        optimizer.zero_grad()  \n        loss1.backward()  \n        optimizer.step()  \n        _,preds=torch.max(outputs,1)  \n        loss+=loss1.item()  \n        correct+=torch.sum(preds==labels.data)  \n    else:  \n        with torch.no_grad():  \n            for val_input,val_labels in validation_loader:  \n                val_input=val_input.to(device)  \n                val_labels=val_labels.to(device)  \n                val_outputs=model(val_input)  \n                val_loss1=criteron(val_outputs,val_labels)   \n                _,val_preds=torch.max(val_outputs,1)  \n                val_loss+=val_loss1.item()  \n                val_correct+=torch.sum(val_preds==val_labels.data)  \n        epoch_loss=loss/len(training_loader)  \n        epoch_acc=correct.float()/len(training_loader)  \n        loss_history.append(epoch_loss)  \n        correct_history.append(epoch_acc)  \n        val_epoch_loss=val_loss/len(validation_loader)  \n        val_epoch_acc=val_correct.float()/len(validation_loader)  \n        val_loss_history.append(val_epoch_loss)  \n        val_correct_history.append(val_epoch_acc)  \n        print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  \n        print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  \n  \nplt.plot(loss_history,label='Training Loss')  \nplt.plot(val_loss_history,label='Validation Loss')  \nplt.legend()  \nplt.show()  \nplt.plot(correct_history,label='Training accuracy')  \nplt.plot(val_correct_history,label='Validation accuracy')  \nplt.legend()  \nplt.show()  </code></pre>\n","protected":false},"excerpt":{"rendered":"<p>In the training section, we trained our CNN model on the MNIST dataset (Endless dataset), and it seemed to reach a reasonable loss and accuracy. If the model can take what it has learned and generalize itself to new data, then it would be a true testament to its performance. This will be done in [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2229,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1397"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1397"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1397/revisions"}],"predecessor-version":[{"id":1415,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1397/revisions/1415"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2229"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1397"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1397"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1397"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1398,"date":"2020-05-21T09:37:45","date_gmt":"2020-05-21T09:37:45","guid":{"rendered":"http://python3.foobrdigital.com/?p=1398"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"testing-3","status":"publish","type":"post","link":"https://python3.foobrdigital.com/testing-3/","title":{"rendered":"Testing"},"content":{"rendered":"\n<p>In the last section, we implemented a neural network or created a model which classified the handwritten digits. Now, we test our model by grabbing an image from the web. We used the following image:</p>\n\n\n\n<figure class=\"wp-block-embed\"><div class=\"wp-block-embed__wrapper\">\nhttp://calstormbasketball.com/wp-content/uploads/2018/08/5020657994731_01c.jpeg\n</div></figure>\n\n\n\n<p>When you paste this link on your browser, you will see the image of number five as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-cnn-pytorch.png\" alt=\"PyTorch Testing\"/></figure>\n\n\n\n<p>After seeing this, we will realize that it is the number 5. Now, we will try to get our network to predict it.</p>\n\n\n\n<p><strong>We have the following steps to make predictions of the number image:</strong></p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we will perform a&nbsp;<strong>GET</strong>&nbsp;request to retrieve the image data. To make a&nbsp;<strong>GET</strong>&nbsp;request, we will need to import request as:</p>\n\n\n\n<ol><li><strong>import</strong>&nbsp;requests&nbsp;&nbsp;</li></ol>\n\n\n\n<p>Now, we set a variable URL and assign the link as a string.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>url=' http://calstormbasketball.com/wp-content/uploads/2018/08/5020657994731_01c.jpeg '  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the next step, we set a variable response whose value will get from the&nbsp;<strong>get()</strong>&nbsp;method of request. The&nbsp;<strong>get()</strong>&nbsp;method will consist of two arguments, i.e., URL and stream and stream will be equals to true.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>response=requests.get(url,stream=True)  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>We will use the raw content of our response to obtain the image. For this, we first have to import&nbsp;<strong>Image</strong>&nbsp;from&nbsp;<strong>PIL (Python Image Library)</strong>&nbsp;as.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from PIL import Image  </code></pre>\n\n\n\n<p>We use the&nbsp;<strong>open()</strong>&nbsp;method of image and pass the raw content of response as an argument. The value which will be returned from this method will assign to a variable named img as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>img=Image.open(response.raw)  </code></pre>\n\n\n\n<p>Now, we plot the image to make sure that everything is working well.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.imshow(img)  \nplt.show()</code></pre>\n\n\n\n<p>When we run it, it will generate an error because of PIL. We must have to install pillow first to run this code. We must have to run the&nbsp;<strong>conda install -c anaconda pillow</strong>&nbsp;command on anaconda command prompt to install pillow.</p>\n\n\n\n<p>When you run the code, it will give the expected output.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-cnn-pytorch1.png\" alt=\"PyTorch Testing\"/></figure>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>We need to ensure that the image corresponds to what the neural network is trained to learn. Our image is of 1000*1000 pixels, so we need to make it into 28*28 grayscale image like ones in the training data. In our trained image dataset, images have a black background and white foreground, and in the above image, there is a white background and black foreground. Now, our first task is to preprocessing this image.</p>\n\n\n\n<p>We will use the&nbsp;<strong>invert ()</strong>&nbsp;method of&nbsp;<strong>PIL.ImageOps</strong>&nbsp;and pass our image as an argument. This method will invert the color of our image.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>img=PIL.ImageOps.invert(img)  </code></pre>\n\n\n\n<p>This image is in the RGB format with three channels of pixel intensity values, and this will problematic for numerous reasons. For this purpose, we must have to convert this image to be a binary black and white image, and we will convert this image as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>img=img.convert('1')   </code></pre>\n\n\n\n<p>We will transform this image in the same way as we have transformed all of our other training images. We have to transform the image in 28*28 pixels, so we have to add an argument&nbsp;<strong>resize</strong>&nbsp;in our transformed chain composition as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform1=transforms.Compose(&#91;transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \nimg=transform1(img)  </code></pre>\n\n\n\n<p>Now, our images are in the form of tensor, so we have to change it into numpy array. Before plotting our image, we have to import&nbsp;<strong>PIL.ImageOps</strong>&nbsp;and then plot the image as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import PIL.ImageOps  \nplt.imshow(im_convert(img))  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-cnn-pytorch2.png\" alt=\"PyTorch Testing\"/></figure>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>Now, we will feed this image into our neural network to make predictions. We will add the image into the device and to ensure four-dimensional input for four-dimensional weight. We will un-squeeze the image and assign it to a new variable image as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=img.to(device)  \nimage=image&#91;0].unsqueeze().unsqueeze(0)  </code></pre>\n\n\n\n<p>This will return a new tensor with a dimension of size one which will be inserted at the specified position zero.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>output=model(image)  \n_,pred=torch.max(output,1)  \nprint(pred.item())  </code></pre>\n\n\n\n<p>It will give us the expected prediction as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-cnn-pytorch3.png\" alt=\"PyTorch Testing\"/></figure>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>In the next step, we wrap our validation loader. It will create an object which allows us to go through the alterable validation loader one element at a time. We access it one element at a time by calling next on our dataiter. The next () function will grab the first batch of our validate data, and that validate data will be split into images and labels as</p>\n\n\n\n<pre class=\"wp-block-code\"><code>dataiter=iter(validation_loader)  \nimages,labels=dataiter.next()    </code></pre>\n\n\n\n<p>There is no need to reshape the image. We will add the images and labels to our device, and we will require the output of all the images and prediction as well.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>images_=images.to(device)  \nlabels=labels.to(device)  \noutput=model(images_)  \n_,preds=torch.max(output,1) </code></pre>\n\n\n\n<p><strong>Step 7:</strong></p>\n\n\n\n<p>Now, we will plot the images in the batch along with their corresponding labels. It will be done with the help of figure function of plt and set fig size is equal to the tuple of integers 25*4, which will specify the width and height of the figure.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>fig=plt.figure(figsize=(25,4))  </code></pre>\n\n\n\n<p>Now, we plot 20 MNIST images from our batch. We use add_subplot() method to add a subplot to the current figure and pass 2, 10, and idx as arguments of the function. Here two is no of rows, ten is no of columns, and idx is index.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>ax=fig.add_subplot(2,10,idx+1)  </code></pre>\n\n\n\n<p>Now, we will display our images with the help of im_show() function and give a title for each image plot as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>plt.imshow(im_convert(images&#91;idx]))   \nax.set_title(\"{}({})\".format(str(preds&#91;idx].item()),str(labels&#91;idx].item())),  \ncolor=(\"green\" if preds&#91;idx]==labels&#91;idx] else \"red\"))  </code></pre>\n\n\n\n<p>Finally call plt.show() and it will give us an error. This error will be of&nbsp;<strong>im_convert()</strong>&nbsp;function i.e. can&#8217;t convert CUDA tensor to numpy. So we we have to use&nbsp;<strong>tensor.cpu()</strong>&nbsp;as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=tensor.cpu().clone().detach().numpy()  </code></pre>\n\n\n\n<p>Now, we will re call our plt.show() and it will give us the expected outputs as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-cnn-pytorch4.png\" alt=\"PyTorch Testing\"/></figure>\n\n\n\n<hr class=\"wp-block-separator\"/>\n\n\n\n<h2>Complete code:</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nimport PIL.ImageOps  \nfrom torch import nn  \nfrom torchvision import datasets,transforms   \nimport requests  \nfrom PIL import Image  \ntransform1=transforms.Compose(&#91;transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \nvalidation_dataset=datasets.MNIST(root='./data',train=False,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \nvalidation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False)  \ndef im_convert(tensor):  \n    image=tensor.cpu().clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \ndataiter=iter(training_loader)  \nimages,labels=dataiter.next()  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1)  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(&#91;labels&#91;idx].item()])class classification1(nn.Module):  \n  \n  \n  \n  \n    def __init__(self,input_layer,hidden_layer1,hidden_layer2,output_layer):  \n        super().__init__()  \n        self.linear1=nn.Linear(input_layer,hidden_layer1)  \n        self.linear2=nn.Linear(hidden_layer1,hidden_layer2)  \n        self.linear3=nn.Linear(hidden_layer2,output_layer)  \n    def forward(self,x):  \n        x=func.relu(self.linear1(x))  \n        x=func.relu(self.linear2(x))  \n        x=self.linear3(x)  \n        return x  \nmodel=classification1(784,125,65,10)  \ncriteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.0001)  \nepochs=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]  \nval_loss_history=&#91;]  \nval_correct_history=&#91;]  \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \n    val_loss=0.0  \n    val_correct=0.0  \n    for input,labels in training_loader:  \n        inputs=input.view(input.shape&#91;0],-1)  \n        outputs=model(inputs)  \n        loss1=criteron(outputs,labels)  \n        optimizer.zero_grad()  \n        loss1.backward()  \n        optimizer.step()  \n        _,preds=torch.max(outputs,1)  \n        loss+=loss1.item()  \n        correct+=torch.sum(preds==labels.data)  \n    else:  \n        with torch.no_grad():  \n            for val_input,val_labels in validation_loader:  \n                val_inputs=val_input.view(val_input.shape&#91;0],-1)  \n                val_outputs=model(val_inputs)  \n                val_loss1=criteron(val_outputs,val_labels)   \n                _,val_preds=torch.max(val_outputs,1)  \n                val_loss+=val_loss1.item()  \n                val_correct+=torch.sum(val_preds==val_labels.data)  \n        epoch_loss=loss/len(training_loader.dataset)  \n        epoch_acc=correct.float()/len(training_dataset)  \n        loss_history.append(epoch_loss)  \n        correct_history.append(epoch_acc)  \n          \n        val_epoch_loss=val_loss/len(validation_loader.dataset)  \n        val_epoch_acc=val_correct.float()/len(validation_dataset)  \n        val_loss_history.append(val_epoch_loss)  \n        val_correct_history.append(val_epoch_acc)  \n        print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  \n        print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  \nurl='http://calstormbasketball.com/wp-content/uploads/2018/08/5020657994731_01c.jpeg'  \nresponse=requests.get(url,stream=True)  \nimg=Image.open(response.raw)  \nimg=PIL.ImageOps.invert(img)  \nimg=img.convert('1')  \nimg=transform1(img)   \nplt.imshow(im_convert(img))  \n  \nimages=img.to(device)  \nimages=images&#91;0].unsqueeze(0).unsqueeze(0)  \noutput=model(images)  \n_,pred=torch.max(output,1)  \nprint(pred.item())  \n  \ndataiter=iter(validation_loader)  \nimages,labels=dataiter.next()  \nimages_=images.to(device)  \nlabels=labels.to(device)  \noutput=model(images_)  \n_,preds=torch.max(output,1)  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1,xticks=&#91;],yticks=&#91;])  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(\"{}({})\".format(str(preds&#91;idx].item()),str(labels&#91;idx].item())),color=(\"green\" if preds&#91;idx]==labels&#91;idx] else \"red\"))  \nplt.show()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-cnn-pytorch5.png\" alt=\"PyTorch Testing\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/testing-of-cnn-pytorch6.png\" alt=\"PyTorch Testing\"/></figure>\n\n\n\n<p>So, it is clear that CNN classifies the images in the best way in comparison to Deep Neural Network. This is the reason we prefer&nbsp;<strong>Convolutional Neural Network</strong>&nbsp;rather than&nbsp;<strong>Deep Neural Network</strong>.</p>\n","protected":false},"excerpt":{"rendered":"<p>In the last section, we implemented a neural network or created a model which classified the handwritten digits. Now, we test our model by grabbing an image from the web. We used the following image: When you paste this link on your browser, you will see the image of number five as: After seeing this, [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2231,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1398"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1398"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1398/revisions"}],"predecessor-version":[{"id":2245,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1398/revisions/2245"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2231"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1398"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1398"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1398"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1399,"date":"2020-05-21T09:39:56","date_gmt":"2020-05-21T09:39:56","guid":{"rendered":"http://python3.foobrdigital.com/?p=1399"},"modified":"2020-12-16T16:59:03","modified_gmt":"2020-12-16T16:59:03","slug":"image-classification","status":"publish","type":"post","link":"https://python3.foobrdigital.com/image-classification/","title":{"rendered":"Image Classification"},"content":{"rendered":"\n<p>In the previous topic, we learn how to use the endless dataset to recognized number image. The endless dataset is an introductory dataset for deep learning because of its simplicity. The endless dataset is a hello world for deep learning.</p>\n\n\n\n<p>The&nbsp;<strong>CIFAR 10(Canadian Institute for Advanced Research)</strong>&nbsp;will be harder to classify and will come with new barriers which we will need to overcome. It is a collection of the image which is commonly used to train machine learning and computer vision algorithms. The CIFAR 10 dataset contains 50000 training images and 10000 validation images such that the images can be classified between 10 different classes.</p>\n\n\n\n<p>The CIFAR-10 dataset consists of 60000 thirty by thirty color images in 10 classes means 6000 images per class. This dataset is divided into one test batch and five training batches. Every batch contains 10000 images. In the test batch, there are 1000 images which are randomly selected from each class. The training batch contains remaining images in random order. Some of the training batches may contain more images from one class than another.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/cifar-10-and-cifar-100-dataset.png\" alt=\"CIFAR-10 and CIFAR-100 Dataset in PyTorch\"/></figure>\n\n\n\n<p>The classes will be completely mutually exclusive. There will be no overlapping between automobiles and trucks. Automobiles include things which are similar to sedans and SUVs. Trucks class includes only big trucks, and it neither includes pickup trucks. As opposed to the MNIST dataset, the objects within these classes are much more complex in nature and extremely varied. If we are looked through the CIFAR dataset, we realize that there is not just one type of bird or cat. The bird and cat class contains many different types of birds and cat varying in size, color, magnification, different angles, and different poses.</p>\n\n\n\n<p>With the endless dataset, although there are many ways in which we can write the number one and number two. It just was not as varied, and on the top of that, the endless dataset is a gray scalar. The CIFAR dataset contains a larger 32 by 32 color images, and each image is with three different color channels. Now our biggest question is that the LeNet model which performed so well on the endless dataset will it be enough to classify CIFAR dataset?</p>\n\n\n\n<h2>CIFAR-100 Dataset</h2>\n\n\n\n<p>It is just like the CIFAR-10 dataset. The only difference is that it has 100 classes containing 600 images per class. There are 100 testing images and 500 training images per class. These 100 classes are grouped into 20 superclasses, and each image comes with a &#8220;coarse&#8221; label (the superclass to which it belongs) and a &#8220;fine&#8221; label (the class to which it belongs).</p>\n\n\n\n<p>There are the following classes in the CIFAR-100 dataset:</p>\n\n\n\n<table><tbody><tr><th>S. No</th><th>Superclass</th><th>Classes</th></tr><tr><td><strong>1.</strong></td><td>aquatic mammals</td><td>beaver, dolphin, otter, seal, whale</td></tr><tr><td><strong>2.</strong></td><td>flowers</td><td>orchids, poppies, roses, sunflowers, tulips</td></tr><tr><td><strong>3.</strong></td><td>fish</td><td>aquarium fish, flatfish, ray, shark, trout</td></tr><tr><td><strong>4.</strong></td><td>food containers</td><td>bottles, bowls, cans, cups, plates</td></tr><tr><td><strong>5.</strong></td><td>household electrical devices</td><td>clock, computer keyboard, lamp, telephone, television</td></tr><tr><td><strong>6.</strong></td><td>fruit and vegetables</td><td>apples, mushrooms, oranges, pears, sweet peppers</td></tr><tr><td><strong>7.</strong></td><td>household furniture</td><td>bed, chair, couch, table, wardrobe</td></tr><tr><td><strong>8.</strong></td><td>large carnivores</td><td>bear, leopard, lion, tiger, wolf</td></tr><tr><td><strong>9.</strong></td><td>insects bee, beetle, butterfly, caterpillar, cockroach</td></tr><tr><td><strong>10.</strong></td><td>large man-made outdoor things</td><td>bridge, castle, house, road, skyscraper</td></tr><tr><td><strong>11.</strong></td><td>large natural outdoor scenes</td><td>cloud, forest, mountain, plain, sea</td></tr><tr><td><strong>12.</strong></td><td>medium-sized mammals</td><td>fox, porcupine, possum, raccoon, skunk</td></tr><tr><td><strong>13.</strong></td><td>large omnivores and herbivores</td><td>camel, cattle, chimpanzee, elephant, kangaroo</td></tr><tr><td><strong>14.</strong></td><td>non-insect invertebrates</td><td>crab, lobster, snail, spider, worm</td></tr><tr><td><strong>15.</strong></td><td>reptiles</td><td>crocodile, dinosaur, lizard, snake, turtle</td></tr><tr><td><strong>16.</strong></td><td>people</td><td>baby, boy, girl, man, woman</td></tr><tr><td><strong>17.</strong></td><td>trees</td><td>maple, oak, palm, pine, willow</td></tr><tr><td><strong>18.</strong></td><td>small mammals</td><td>hamster, mouse, rabbit, shrew, squirrel</td></tr><tr><td><strong>19.</strong></td><td>vehicles 1</td><td>bicycle, bus, motorcycle, pickup truck, train</td></tr><tr><td><strong>20.</strong></td><td>vehicles 2</td><td>lawn-mower, rocket, streetcar, tank, tractor</td></tr></tbody></table>\n\n\n\n<p></p>\n","protected":false},"excerpt":{"rendered":"<p>In the previous topic, we learn how to use the endless dataset to recognized number image. The endless dataset is an introductory dataset for deep learning because of its simplicity. The endless dataset is a hello world for deep learning. The&nbsp;CIFAR 10(Canadian Institute for Advanced Research)&nbsp;will be harder to classify and will come with new [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2232,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1399"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1399"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1399/revisions"}],"predecessor-version":[{"id":2483,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1399/revisions/2483"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2232"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1399"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1399"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1399"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1400,"date":"2020-05-21T09:42:23","date_gmt":"2020-05-21T09:42:23","guid":{"rendered":"http://python3.foobrdigital.com/?p=1400"},"modified":"2020-12-16T16:59:02","modified_gmt":"2020-12-16T16:59:02","slug":"lenet-model","status":"publish","type":"post","link":"https://python3.foobrdigital.com/lenet-model/","title":{"rendered":"LeNet Model"},"content":{"rendered":"\n<p>In the previous topic, we found that our LeNet Model with Convolutional Neural Network was able to do the classification of MNIST dataset images. MNIST dataset contains the number of images which are the grayscale images, but in CHIFAR-10 dataset the images are colored and of different things. So our biggest question is that will our LeNet model classify the images of CIFAR-10 dataset. We will copy the code of our previous topic, i.e., Testing of CNN and do the following changes in the image transforms, implementation, training, validation, and the testing section of the code:</p>\n\n\n\n<p><strong>Note:</strong>&nbsp;If you are new here, then you must have to get knowledge of our previous topic for understanding this efficiently.</p>\n\n\n\n<h2>Changes in the section of Image Transform:</h2>\n\n\n\n<p>In the Image Transform section we will do the following changes:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In this, we are working with CIFAR-10 dataset so our first step is to load CIFAR-10 dataset rather than MNIST dataset. We load CIFAR-10 dataset by doing changes in the training dataset as well as validation data set in the following way:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_dataset=datasets.CIFAR10(root='./data',train=True,download=True,transform=transform1)  \nvalidation_dataset=datasets.CIFAR10(root='./data',train=False,download=True,transform=transform1)  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>In the next step, we will do the changes in our transform statement. We know that the MNIST image are of size 28 by 28 pixels but the CIFAR10 images are of size 32 by 32 pixels. So we will do the changes in the transform.compose() method&#8217;s first argument as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform1=transforms.Compose(&#91;transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  </code></pre>\n\n\n\n<p>Now, if we plot our CIFAR-10 images then it will give us the following output:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-lenet-model-for-cifar-10-dataset.png\" alt=\"Pytorch Testing of LeNet Model for CIFAR-10 Dataset\"/></figure>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>In the CIFAR10 images, we know that the images are classify in the classes. For better understanding and visualization we specify each images with its class. So we declare a list of classes in which we specifies the classes in order after im_convert () method as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>classes={'plane','car','bird','cat','dear','dog'.'frog','horse','ship','truck'}  </code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>The labels represent the ordered numerical representation of these classes so we will use each respective label to index through our classes list and the output will be appropriate class. We will change the set_title() method as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>ax.set_title(classes&#91;labels&#91;idx].item()])  </code></pre>\n\n\n\n<p>It will give the following output:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-lenet-model-for-cifar-10-dataset-1.png\" alt=\"Pytorch Testing of LeNet Model for CIFAR-10 Dataset\"/></figure>\n\n\n\n<h2>Changes in Implementation, Training, and Validation section:</h2>\n\n\n\n<p>Our Lenet model was implemented for MNIST images. MNIST images are the grayscale image, but we have to implement our model for CIFAR-10 dataset, which contains colored images. So we have to do the following changes in our code:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>Previously, we were working with one channel grayscale images, and now we work with three-channel color images which are passes into the neural network. So in the first convolutional layer, we set 3 rather than one as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.conv1=nn.Conv2d(3,20,5,1)  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>Now, we have to train a large number of parameters. After the convolution of a 5 by 5 kernel, the images becomes 28 by 28 and then with next pooling 14 by 14 performing another convolution with the same size kernel. The image once again gets smaller by 4 by 4 decrement and becomes a 10 by 10. And finally, with another max-pooling, the vector which will then be fed into the fully connected network will be a 5 by 5 by 50.</p>\n\n\n\n<p>So we have to change our first fully connected layer in our initializer as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.fully1=nn.Linear(5*5*50,500)  </code></pre>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Now, we also have to change the shape of our output. For this, we have to change our view statement in the forward function as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>xx=x.view(-1,5*5*50) #Reshaping the output into desired shape  </code></pre>\n\n\n\n<p>Now, we find the total loss and validation loss as well as accuracy and validation accuracy and plot it then it will give us the following output:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-lenet-model-for-cifar-10-dataset-2.png\" alt=\"Pytorch Testing of LeNet Model for CIFAR-10 Dataset\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-lenet-model-for-cifar-10-dataset-3.png\" alt=\"Pytorch Testing of LeNet Model for CIFAR-10 Dataset\"/></figure>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>Now, we will use it to predict images from the web to simply gain a visual perspective of the model accuracy. We will use the following image:&nbsp;https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/hires/2018/2-dog.jpg</p>\n\n\n\n<p>When we plot this image, it will be shown as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-lenet-model-for-cifar-10-dataset-4.png\" alt=\"Pytorch Testing of LeNet Model for CIFAR-10 Dataset\"/></figure>\n\n\n\n<p><strong>Step 5:</strong></p>\n\n\n\n<p>In the next step, we will remove our invert and convert method because this time our image will be extremely converted to a bio level format, and our network was trained on color images. We will transform the image and plot the images as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>url='https://ichef.bbci.co.uk/news/912/cpsprodpb/160B4/production/_103229209_horsea.png'  \nresponse=requests.get(url,stream=True)  \nimg=Image.open(response.raw)  \nimg=transform1(img)   \nplt.imshow(im_convert(img))  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-lenet-model-for-cifar-10-dataset-5.png\" alt=\"Pytorch Testing of LeNet Model for CIFAR-10 Dataset\"/></figure>\n\n\n\n<p>After the transformation, we obtain a more abstracted representation of the image. It reduces to a smaller 32 by 32 representation.</p>\n\n\n\n<p><strong>Step 6:</strong></p>\n\n\n\n<p>Now, we make prediction on this image so we will squeeze the image and find the prediction using class as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image1=img.to(device).unsqueeze(0)    \noutput=model(image1)  \n_,pred=torch.max(output,1)  \nprint(classes&#91;pred.item()])  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-lenet-model-for-cifar-10-dataset-6.png\" alt=\"Pytorch Testing of LeNet Model for CIFAR-10 Dataset\"/></figure>\n\n\n\n<h2>Changes in Testing section:</h2>\n\n\n\n<p>The testing section will be same as before. The same process of CNN testing will be follow but in colorful images we will use classes to predict each validation image as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>dataiter=iter(validation_loader)    \nimages,labels=dataiter.next()    \nimagesimages_=images.to(device)    \nlabelslabels=labels.to(device)    \noutput=model(images_)    \n_,preds=torch.max(output,1)    \nfig=plt.figure(figsize=(25,4))    \nfor idx in np.arange(20):    \n    ax=fig.add_subplot(2,10,idx+1,xticks=&#91;],yticks=&#91;])    \n  plt.imshow(im_convert(images&#91;idx]))      \n  ax.set_title(\"{}({})\".format(str(classes&#91;preds&#91;idx].item()]),str(classes&#91;labels&#91;idx].item())),color=(\"green\" if preds&#91;idx]==labels&#91;idx] else \"red\"))    \nplt.show()    </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-testing-of-lenet-model-for-cifar-10-dataset-7.png\" alt=\"Pytorch Testing of LeNet Model for CIFAR-10 Dataset\"/></figure>\n\n\n\n<p>It seems to predict most of the images accurately. Overall it is very good that our model is so much able to generalize itself to new data based on its trained parameters.</p>\n\n\n\n<h2>Complete code:</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nimport PIL.ImageOps  \nfrom torch import nn  \nfrom torchvision import datasets,transforms   \nimport requests  \nfrom PIL import Image  \n  \ndevice=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \ntransform1=transforms.Compose(&#91;transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.CIFAR10(root='./data',train=True,download=True,transform=transform1)  \nvalidation_dataset=datasets.CIFAR10(root='./data',train=False,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \nvalidation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False)  \ndef im_convert(tensor):  \n    image=tensor.cpu().clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \n      \nclasses=('plane','car','bird','cat','dear','dog','frog','horse','ship','truck')  \ndataiter=iter(training_loader)  \nimages,labels=dataiter.next()  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n    ax=fig.add_subplot(2,10,idx+1)  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(classes&#91;labels&#91;idx].item()])  \nclass LeNet(nn.Module):  \n        def __init__(self):  \n            super().__init__()  \n            self.conv1=nn.Conv2d(3,20,5,1)  \n            self.conv2=nn.Conv2d(20,50,5,1)  \n            self.fully1=nn.Linear(5*5*50,500)  \n            self.dropout1=nn.Dropout(0.5)   \n            self.fully2=nn.Linear(500,10)  \n        def forward(self,x):  \n            x=func.relu(self.conv1(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=func.relu(self.conv2(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=x.view(-1,5*5*50) #Reshaping the output into desired shape  \n            x=func.relu(self.fully1(x)) #Applying relu activation function to our first fully connected layer  \n            x=self.dropout1(x)  \n            x=self.fully2(x)    #We will not apply activation function here because we are dealing with multiclass dataset  \n            return x      \nmodel=LeNet().to(device)  \ncriteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.00001)   \nepochs=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]  \nval_loss_history=&#91;]  \nval_correct_history=&#91;]  \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \n    val_loss=0.0  \n    val_correct=0.0  \n    for input,labels in training_loader:  \n        input=input.to(device)  \n        labels=labels.to(device)  \n        outputs=model(input)  \n        loss1=criteron(outputs,labels)  \n        optimizer.zero_grad()  \n        loss1.backward()  \n        optimizer.step()  \n        _,preds=torch.max(outputs,1)  \n        loss+=loss1.item()  \n        correct+=torch.sum(preds==labels.data)  \n    else:  \n        with torch.no_grad():  \n            for val_input,val_labels in validation_loader:  \n                val_input=val_input.to(device)  \n                val_labels=val_labels.to(device)  \n                val_outputs=model(val_input)  \n                val_loss1=criteron(val_outputs,val_labels)   \n                _,val_preds=torch.max(val_outputs,1)  \n                val_loss+=val_loss1.item()  \n                val_correct+=torch.sum(val_preds==val_labels.data)  \n        epoch_loss=loss/len(training_loader)  \n        epoch_acc=correct.float()/len(training_loader)  \n        loss_history.append(epoch_loss)  \n        correct_history.append(epoch_acc)  \n        val_epoch_loss=val_loss/len(validation_loader)  \n        val_epoch_acc=val_correct.float()/len(validation_loader)  \n        val_loss_history.append(val_epoch_loss)  \n        val_correct_history.append(val_epoch_acc)  \n        print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  \n        print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  \nplt.plot(loss_history,label='Training Loss')    \nplt.plot(val_loss_history,label='Validation Loss')    \nplt.legend()    \nplt.show()  \nplt.plot(correct_history,label='Training accuracy')    \nplt.plot(val_correct_history,label='Validation accuracy')    \nplt.legend()    \nplt.show()    \nurl='https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/hires/2018/2-dog.jpg'  \nresponse=requests.get(url,stream=True)  \nimg=Image.open(response.raw)  \nimg=transform1(img)     \nimage1=img.to(device).unsqueeze(0)  \noutput=model(image1)  \n_,pred=torch.max(output,1)  \nprint(classes&#91;pred.item()])  \ndataiter=iter(validation_loader)    \nimages,labels=dataiter.next()    \nimages_=images.to(device)    \nlabels=labels.to(device)    \noutput=model(images_)    \n_,preds=torch.max(output,1)    \nfig=plt.figure(figsize=(25,4))    \nfor idx in np.arange(20):    \n    ax=fig.add_subplot(2,10,idx+1,xticks=&#91;],yticks=&#91;])    \n    plt.imshow(im_convert(images&#91;idx]))    \n    ax.set_title(\"{}({})\".format(str(classes&#91;preds&#91;idx].item()]),str(classes&#91;labels&#91;idx].item()]),color=(\"green\" if preds&#91;idx]==labels&#91;idx] else \"red\"))    \nplt.show()  </code></pre>\n","protected":false},"excerpt":{"rendered":"<p>In the previous topic, we found that our LeNet Model with Convolutional Neural Network was able to do the classification of MNIST dataset images. MNIST dataset contains the number of images which are the grayscale images, but in CHIFAR-10 dataset the images are colored and of different things. So our biggest question is that will [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2233,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1400"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1400"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1400/revisions"}],"predecessor-version":[{"id":2246,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1400/revisions/2246"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2233"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1400"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1400"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1400"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1401,"date":"2020-05-21T09:44:40","date_gmt":"2020-05-21T09:44:40","guid":{"rendered":"http://python3.foobrdigital.com/?p=1401"},"modified":"2020-12-16T16:59:02","modified_gmt":"2020-12-16T16:59:02","slug":"hyperparameter","status":"publish","type":"post","link":"https://python3.foobrdigital.com/hyperparameter/","title":{"rendered":"Hyperparameter"},"content":{"rendered":"\n<p>In the last topic, we trained our Lenet model and CIFAR dataset. We found that our LeNet model makes a correct prediction for most of the images as well as we also found overfitting in the accuracy. While our model was not very well trained, it was still able to predict a majority of the validation images.</p>\n\n\n\n<p>The CIFAR dataset is going to be more difficult to classify due to the added depth variety and inherent complexity of the training images.</p>\n\n\n\n<p>Our very same LeNet model which performed very well with the MNIST datasets is now having issues in classifying our CIFAR dataset accurately.</p>\n\n\n\n<p>There are two main issues from which we are currently dealing with. The accuracy not being high enough, and the network seems to be overfitting our training data. The first issue can be tackled using a variety of modification to our LeNet model code. The modification which we will apply are very case dependent and fine-tuning of our model capacity. It is often a very specific process which is unique for each specific deep learning task.</p>\n\n\n\n<p>However, the fine-tuning of our model is important and can improve our model performance significantly. We must always try and modify our model to see just how these modifications improve the effectiveness of our model. We will apply the following modification:</p>\n\n\n\n<p>1) The first modification will be focused on the learning rate. The Adam optimizer computes individual adaptive learning rates. It is still important to specify a fitting learning rate for optimal performance. A learning rate that is too high can often lead to lower accuracy. A lower learning rate can help a neural network to learn more effectively when a more complex dataset is involved.</p>\n\n\n\n<p><strong>Note:</strong>&nbsp;A learning rate which is too small can significantly slow down our training performance.</p>\n\n\n\n<p>With the help of both analytical and empirical, we conclude that the training process is quite slow, and the training and validation accuracies are not significantly improved from one epoch to the next.</p>\n\n\n\n<p>We will set the learning rate from 0.001 rather than 0.0001.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>criteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.001)  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-hyperparameter-tuning-technique.png\" alt=\"Pytorch Hyperparameter Tuning Technique\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-hyperparameter-tuning-technique-1.png\" alt=\"Pytorch Hyperparameter Tuning Technique\"/></figure>\n\n\n\n<p>2) The second modification is very effective. We will simply add more convolution of layers. By adding more convolution, our network can extract features more effectively and also lead to improving accuracy.</p>\n\n\n\n<p><strong>Note:</strong>&nbsp;A common architecture of defining a convolution layer is one where each layer doubles the depth of the output of the preceding layer.</p>\n\n\n\n<p>In our first convolutional layer, there will be 3 input channel and the depth of conv1 corresponding to 16 output channel. This is then going to be double to 32 and then 64 as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.conv1=nn.Conv2d(3,16,5,1)  \nself.conv2=nn.Conv2d(16,32,5,1) </code></pre>\n\n\n\n<p>When we proceeded from one convolution layer to the next,- the depth of the output of the convolution layer had increased consistently. By doing so, we internally increased the number of filters to extract highly sophisticated information related to the forward an input. Convolution layers are used to make the network much deeper that extract more and more complex features.</p>\n\n\n\n<p>So we will make another convolutional layer conv3 as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.conv3=nn.Conv2d(32,64,5,1)  </code></pre>\n\n\n\n<p>The appropriate vector which is being fed into our fully connected layer will be five by five, which is same as before, but the number of output channel will be 64.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.fully1=nn.Linear(5*5*64,500)  </code></pre>\n\n\n\n<p>To ensure consistency, we will also change the number of output channels in our forward&#8217;s view method as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>xx=x.view(-1,5*5*64)  </code></pre>\n\n\n\n<p>After initializing third convolutional layer, we will apply relu function on it as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x=func.relu(self.conv3(x))  \nx=func.max_pool2d(x,2,2) </code></pre>\n\n\n\n<p>A larger kernel implies more parameters. We will use a smaller kernel size to remove overfitting. We will use a kernel size of three, which will be suitable for our code. Previously in the MNIST dataset, we did not use any padding in our convolutional layer, but now we are dealing with a more complex dataset. It would make sense to preserve the edge pixels of our image by including padding to ensure maximal feature extraction. We will set padding to 1 for all convolutional layer as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.conv1=nn.Conv2d(3,16,3,1, padding=1)  \nself.conv2=nn.Conv2d(16,32,3,1, padding=1)  \nself.conv3=nn.Conv2d(32,64,3,1, padding=1)   </code></pre>\n\n\n\n<p>The final vector which is fed into the fully connected layer is dictated by the image size that will half at every max-pooling layer. The image size will be reduced as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-hyperparameter-tuning-technique-2.png\" alt=\"Pytorch Hyperparameter Tuning Technique\"/></figure>\n\n\n\n<p>So we will change our nn.Linear method of initializer as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>self.fully1=nn.Linear(4*4*64,500)  </code></pre>\n\n\n\n<p>Similarly, we will change the forward&#8217;s view method as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>xx=x.view(-1,4*4*64)  </code></pre>\n\n\n\n<p>Now, we will train it, and it will give us the following expected output:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-hyperparameter-tuning-technique-3.png\" alt=\"Pytorch Hyperparameter Tuning Technique\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-hyperparameter-tuning-technique-4.png\" alt=\"Pytorch Hyperparameter Tuning Technique\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>In the last topic, we trained our Lenet model and CIFAR dataset. We found that our LeNet model makes a correct prediction for most of the images as well as we also found overfitting in the accuracy. While our model was not very well trained, it was still able to predict a majority of the [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2234,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1401"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1401"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1401/revisions"}],"predecessor-version":[{"id":1436,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1401/revisions/1436"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2234"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1401"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1401"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1401"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1437,"date":"2020-05-21T09:48:33","date_gmt":"2020-05-21T09:48:33","guid":{"rendered":"http://python3.foobrdigital.com/?p=1437"},"modified":"2020-12-16T16:59:02","modified_gmt":"2020-12-16T16:59:02","slug":"data-augmentation","status":"publish","type":"post","link":"https://python3.foobrdigital.com/data-augmentation/","title":{"rendered":"Data Augmentation"},"content":{"rendered":"\n<p>Previously, we saw a significant increment in model accuracy. Our model was effectively trained to classify the training data. It did not generalize well for the validation data to fix the overfishing issue. Now, let&#8217;s discuss one more technique to improve the model training process. This technique is known as data augmentation. It is the process by which we create new data for our model to use during the training process.</p>\n\n\n\n<p>This is done by taking our existing dataset and transforming or altering the image in useful ways to create new images.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-data-augmentation-process.png\" alt=\"Data Augmentation Process\"/></figure>\n\n\n\n<p>After applying the transformation, the newly created images are known as augmented images because they essentially allow us to augment our dataset by adding new data to it. The data augmentation technique is useful because it allows our model to look at each image in our dataset from a variety of different perspective. This allows our model to extract relevant features more accurately and to obtain more feature-related data from each training image.</p>\n\n\n\n<p>Now our biggest question is how we will use that augmentation to reduce overfitting. The overfitting occurs when our model is too closely fit the training set.</p>\n\n\n\n<p>There is no need to start collecting new images and adding them to our datasets. We can use data augmentation which introduces minor alteration to our existing datasets such darker shading, flips, zooming, rotations or translation. Our model will interpret them as separate distinct images. It will not only reduce over fitting but it also prevents our network from learning irrelevant patterns and boosts overall performance. We have the following steps to perform data augmentation:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>To perform data augmentation on training dataset, we have to make to make a separate transform statement. For validation dataset the transform will remain same. So we first copy our transform1 statement and treat it as transform_train as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform_train=transforms.Compose(&#91;transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])</code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>Now, we will add alternation in our transform_train statement. The alternations will be a RandomHorizontalFlip, RandomRotation which is used for rotation of an image by a certain angle and that angle will be passes as an argument.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform_train=transforms.Compose(&#91;transforms.Resize((32,32)),  \n        transform.RandomHorizontalFlip(),  \n        transform.RandomRotation(),  \n        transforms.ToTensor(),  \n        transforms.Normalize((0.5,),(0.5,))])  </code></pre>\n\n\n\n<p>To add even more variety to our dataset, we will use a fine type transformation. Fine transformation represent simple transformation which preserve straight lines and planes with the object. Scaling, translation, shear and zooming is a transformation which fits this category.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform_train=transforms.Compose(&#91;transforms.Resize((32,32)),  \n        transform.RandomHorizontalFlip(),  \n        transform.RandomRotation(),  \n        transform.RandomAffine(0,shear=10,scale=(0.8,1.2)),  \n        transforms.ToTensor(),  \n        transforms.Normalize((0.5,),(0.5,))])  </code></pre>\n\n\n\n<p>In RandomAffine(), the first argument is decrease which we set zero to deactivate rotation, second argument is the shear transformation and the last one is the scaling transformation and use a topple to define the range of zoom which we have required. We defined a lower and upper limit of 0.8 and 1.2 to scale images to 80 or 120 percent of their size.</p>\n\n\n\n<p><strong>Step 3:</strong></p>\n\n\n\n<p>Now, we move onto our next augmentation to create new augmented images with a randomized variety of brightness, contrast and saturation. We will add another transformation i.e. ColorJitter as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>transform_train=transforms.Compose(&#91;transforms.Resize((32,32)),  \n        transform.RandomHorizontalFlip(),  \n        transform.RandomRotation(10),  \n        transform.RandomAffine(0,shear=10,scale=(0.8,1.2)),  \n        transform.ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2)  \n        transforms.ToTensor(),  \n        transforms.Normalize((0.5,),(0.5,))])  </code></pre>\n\n\n\n<p><strong>Step 4:</strong></p>\n\n\n\n<p>Before executing our code, we have to change the training_dataset statement because now we have another transform for the training dataset. So</p>\n\n\n\n<pre class=\"wp-block-code\"><code>training_dataset=datasets.CIFAR10(root='./data',train=True,download=True,transform=transform_train)  </code></pre>\n\n\n\n<p>Now, we will execute our code, and after execution, it will give us the expected output with a correct prediction.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-data-augmentation-process2.png\" alt=\"Data Augmentation Process\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-data-augmentation-process3.png\" alt=\"Data Augmentation Process\"/></figure>\n\n\n\n<h2>Complete Code:</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \nimport torch.nn.functional as func  \nimport PIL.ImageOps  \nfrom torch import nn  \nfrom torchvision import datasets,transforms   \nimport requests  \nfrom PIL import Image  \ndevice=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \ntransform_train=transforms.Compose(&#91;transforms.Resize((32,32)),  \n                               transforms.RandomHorizontalFlip(),  \n                               transforms.RandomRotation(10),  \n                               transforms.RandomAffine(0,shear=10,scale=(0.8,1.2)),  \n                               transforms.ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2),  \n                               transforms.ToTensor(),  \n                               transforms.Normalize((0.5,),(0.5,))])  \ntransform1=transforms.Compose(&#91;transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \ntraining_dataset=datasets.CIFAR10(root='./data',train=True,download=True,transform=transform_train)  \nvalidation_dataset=datasets.CIFAR10(root='./data',train=False,download=True,transform=transform1)  \ntraining_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True)  \nvalidation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False)  \ndef im_convert(tensor):  \n    image=tensor.cpu().clone().detach().numpy()  \n    image=image.transpose(1,2,0)  \n    print(image.shape)  \n    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n    image=image.clip(0,1)  \n    return image  \nclasses=('plane','car','bird','cat','dear','dog','frog','horse','ship','truck')  \ndataiter=iter(training_loader)  \nimages,labels=dataiter.next()  \nfig=plt.figure(figsize=(25,4))  \nfor idx in np.arange(20):  \n  \n    ax=fig.add_subplot(2,10,idx+1)  \n    plt.imshow(im_convert(images&#91;idx]))  \n    ax.set_title(classes&#91;labels&#91;idx].item()])  \nclass LeNet(nn.Module):  \n        def __init__(self):  \n            super().__init__()  \n            self.conv1=nn.Conv2d(3,16,3,1, padding=1)  \n            self.conv2=nn.Conv2d(16,32,3,1, padding=1)  \n            self.conv3=nn.Conv2d(32,64,3,1, padding=1)     \n            self.fully1=nn.Linear(4*4*64,500)  \n            self.dropout1=nn.Dropout(0.5)   \n            self.fully2=nn.Linear(500,10)  \n        def forward(self,x):  \n            x=func.relu(self.conv1(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=func.relu(self.conv2(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=func.relu(self.conv3(x))  \n            x=func.max_pool2d(x,2,2)  \n            x=x.view(-1,4*4*64) #Reshaping the output into desired shape  \n            x=func.relu(self.fully1(x)) #Applying relu activation function to our first fully connected layer  \n            x=self.dropout1(x)  \n            x=self.fully2(x)    #We will not apply activation function here because we are dealing with multiclass dataset  \n            return x      \nmodel=LeNet().to(device)  \ncriteron=nn.CrossEntropyLoss()  \noptimizer=torch.optim.Adam(model.parameters(),lr=0.001)  \nepochs=12  \nloss_history=&#91;]  \ncorrect_history=&#91;]  \nval_loss_history=&#91;]  \nval_correct_history=&#91;]  \nfor e in range(epochs):  \n    loss=0.0  \n    correct=0.0  \n    val_loss=0.0  \n    val_correct=0.0  \n    for input,labels in training_loader:  \n        input=input.to(device)  \n        labels=labels.to(device)  \n        outputs=model(input)  \n        loss1=criteron(outputs,labels)  \n        optimizer.zero_grad()  \n        loss1.backward()  \n        optimizer.step()  \n        _,preds=torch.max(outputs,1)  \n        loss+=loss1.item()  \n        correct+=torch.sum(preds==labels.data)  \n    else:  \n        with torch.no_grad():  \n            for val_input,val_labels in validation_loader:  \n                val_input=val_input.to(device)  \n                val_labels=val_labels.to(device)  \n                val_outputs=model(val_input)  \n                val_loss1=criteron(val_outputs,val_labels)   \n                _,val_preds=torch.max(val_outputs,1)  \n                val_loss+=val_loss1.item()  \n                val_correct+=torch.sum(val_preds==val_labels.data)  \n        epoch_loss=loss/len(training_loader)  \n        epoch_acc=correct.float()/len(training_loader)  \n        loss_history.append(epoch_loss)  \n        correct_history.append(epoch_acc)  \n        val_epoch_loss=val_loss/len(validation_loader)  \n        val_epoch_acc=val_correct.float()/len(validation_loader)  \n        val_loss_history.append(val_epoch_loss)  \n        val_correct_history.append(val_epoch_acc)  \n        print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  \n        print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  \n  \nurl='https://akm-img-a-in.tosshub.com/indiatoday/images/story/201810/white_stork.jpeg?B2LINO47jclcIb3QCW.Bj9nto934Lox4'  \nresponse=requests.get(url,stream=True)  \nimg=Image.open(response.raw)  \nimg=transform1(img)     \nimage1=img.to(device).unsqueeze(0)  \noutput=model(image1)  \n_,pred=torch.max(output,1)  \nprint(classes&#91;pred.item()])  \n  \ndataiter=iter(validation_loader)    \nimages,labels=dataiter.next()    \nimages_=images.to(device)    \nlabels=labels.to(device)    \noutput=model(images_)    \n_,preds=torch.max(output,1)    \nfig=plt.figure(figsize=(25,4))    \nfor idx in np.arange(20):    \n      ax=fig.add_subplot(2,10,idx+1,xticks=&#91;],yticks=&#91;])     \n      plt.imshow(im_convert(images&#91;idx]))      \nax.set_title(\"{}({})\".format(str(classes&#91;preds&#91;idx].item()]),str(classes&#91;labels&#91;idx].item()]),color=(\"green\" if classes&#91;preds&#91;idx]]==classes&#91;labels&#91;idx]] else \"red\")))  \nplt.show()  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-data-augmentation-process4.png\" alt=\"Data Augmentation Process\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-data-augmentation-process5.png\" alt=\"Data Augmentation Process\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>Previously, we saw a significant increment in model accuracy. Our model was effectively trained to classify the training data. It did not generalize well for the validation data to fix the overfishing issue. Now, let&#8217;s discuss one more technique to improve the model training process. This technique is known as data augmentation. It is the [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2235,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1437"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1437"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1437/revisions"}],"predecessor-version":[{"id":1446,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1437/revisions/1446"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2235"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1437"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1437"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1437"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1438,"date":"2020-05-21T09:49:38","date_gmt":"2020-05-21T09:49:38","guid":{"rendered":"http://python3.foobrdigital.com/?p=1438"},"modified":"2020-12-16T16:59:02","modified_gmt":"2020-12-16T16:59:02","slug":"style-transferring","status":"publish","type":"post","link":"https://python3.foobrdigital.com/style-transferring/","title":{"rendered":"Style Transferring"},"content":{"rendered":"\n<p>In this topic, we will implement an artificial system based on Deep Neural Network, which will create artistic images of high perceptual quality. This system will use neural representation to separate, recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images.</p>\n\n\n\n<p>Neural style transfer is a way to generate images in the style of another image. The neural-style algorithm takes a content-image (a style image) as input and returns the content image as if it printed using the artistic style of the style image.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/style-transferring-in-pytorch.png\" alt=\"Style Transferring in PyTorch\"/></figure>\n\n\n\n<h2>How does the neural style transfer algorithm work?</h2>\n\n\n\n<p>When we implement this algorithm, we define two distances; one for the content(Dc) and another for the style(Ds). Dc measures how different the content is between two images and Ds measures how different the style is between two images. We take the third image as an input and transform it in order to both minimize its content-distance with the content-image and its style-distance with the style-image.</p>\n\n\n\n<h3>Required Libraries</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import torch  \nimport torch.optim as  optim  \n#we will import transforms and models because we will transform our images and we will use pre-trained model VGG-19   \nfrom torchvision import transforms, models  \nfrom PIL import Image  \nimport matplotlib.pyplot as plt  \nimport numpy as np </code></pre>\n\n\n\n<h3>Initialization of VGG-19 model</h3>\n\n\n\n<p>VGG-19 model Is similar to VGG-16 model. The VGG model was introduced by Simonyan and Zisserman. VGG-19 is trained on more than a million images from the ImageNet database. This model has 19 layers deep neural network, which can classify images into 1000 objects categories.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/style-transferring-in-pytorch2.png\" alt=\"Style Transferring in PyTorch\"/></figure>\n\n\n\n<p>In our initialization process, we will only import the features of the model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>#importing model features   \nvgg=models.vgg19(pretrained=True).features  #we are using pre-trained model   \n# Maintain parameter constant setting  \nfor param in vgg.parameters():  \n    param.requires_grad_(False)  </code></pre>\n\n\n\n<p>When we run this code, downloading will be started, and our model features will be downloaded successfully.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/style-transferring-in-pytorch3.png\" alt=\"Style Transferring in PyTorch\"/></figure>\n\n\n\n<h3>Add the model to our device</h3>\n\n\n\n<p>When our model features are downloaded and imported, we have to add it on device either CUDA or CPU. The torch.device is the method by which we will do this process.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>#Implementing device   \ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n#Attaching our vgg model to our device   \nvgg.to(device) </code></pre>\n\n\n\n<p>When we run this, it will give us expected output as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/style-transferring-in-pytorch4.png\" alt=\"Style Transferring in PyTorch\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>In this topic, we will implement an artificial system based on Deep Neural Network, which will create artistic images of high perceptual quality. This system will use neural representation to separate, recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Neural style transfer is a way to [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2236,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1438"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1438"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1438/revisions"}],"predecessor-version":[{"id":1448,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1438/revisions/1448"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2236"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1438"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1438"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1438"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1439,"date":"2020-05-21T09:52:10","date_gmt":"2020-05-21T09:52:10","guid":{"rendered":"http://python3.foobrdigital.com/?p=1439"},"modified":"2020-12-16T16:59:02","modified_gmt":"2020-12-16T16:59:02","slug":"image-loading","status":"publish","type":"post","link":"https://python3.foobrdigital.com/image-loading/","title":{"rendered":"Image loading"},"content":{"rendered":"\n<p>After importing all the necessary libraries and adding VGG-19 to our device, we have to load images in the memory on which we want to apply for style transfer. We have a content image, and style image and the target image will be the combination of both these images. Not every image needs to have the same size or pixel. To make the images equal, we will also apply the image transformation process.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/image-loading-and-transformation-for-style-transferring.png\" alt=\"Image loading and transformation for Style Transferring in PyTorch\"/></figure>\n\n\n\n<h2>Image Loading</h2>\n\n\n\n<p>We have to load the content image and style image in memory so that we can perform the operation on that. The loading process plays a vital role in the style transferring process. We need images in memory and style transferring process will not be possible before the loading process.</p>\n\n\n\n<p><strong>Code:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>#defining a method with three parameters i.e. image location, maximum size and shape   \ndef load_image(img_path,max_size=400,shape=None):  \n# Open the image, convert it into RGB and store in a variable   \n    image=Image.open(img_path).convert('RGB')  \n    # comparing image size with the maximum size   \n    if max(image.size)>max_size:  \n      size=max_size  \n    else:  \n      size=max(image.size)  \n    # checking for the image shape  \n    if shape is not None:  \n       size=shape  \n    #Applying appropriate transformation to our image such as Resize, ToTensor and Normalization  \n    in_transform=transforms.Compose(&#91;  \n        transforms.Resize(size),  \n        transforms.ToTensor(),  \n        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])  \n    #Calling in_transform with our image   \n    image=in_transform(image).unsqueeze(0) #unsqueeze(0) is used to add extra layer of dimensionality to the image  \n    #Returning image   \n    return image  \n#Calling load_image() with our image and add it to our device  \ncontent=load_image('ab.jpg').to(device)  \nstyle=load_image('abc.jpg',shape=content.shape&#91;-2:]).to(device)  </code></pre>\n\n\n\n<h2>Image Conversion</h2>\n\n\n\n<p>Before importing our images, we need to convert our images from tensor as to numpy images to ensure the compatibility with the plot package. We have done this before with the familiar image_converts helper function which we have previously used in&nbsp;<em>Image Transforms in Image Recognition</em>.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def im_convert(tensor):  \n  image=tensor.cpu().clone().detach().numpy()     \n  image=image.transpose(1,2,0)  \n  image=image*np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5))  \n  image=image.clip(0,1)  \n  return image  </code></pre>\n\n\n\n<p>If we run this helper method then it will generate the error. We have to remove the single dimensional entries from the shape of the image and from the shape of the array. So we will squeeze our image before the transpose method.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>image=image.squeeze()  </code></pre>\n\n\n\n<h2>Plotting the images</h2>\n\n\n\n<p><strong>Code:</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>fig, (ax1,ax2)=plt.subplots(1,2,figsize=(20,10))  \nax1.imshow(im_convert(content))  \nax1.axis('off')  \nax2.imshow(im_convert(style))  \nax2.axis('off') </code></pre>\n\n\n\n<p>When we run it on Google Colab Notebook, it will give us the expected output as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/image-loading-and-transformation-for-style-transferring2.png\" alt=\"Image loading and transformation for Style Transferring in PyTorch\"/></figure>\n\n\n\n<hr class=\"wp-block-separator\"/>\n","protected":false},"excerpt":{"rendered":"<p>After importing all the necessary libraries and adding VGG-19 to our device, we have to load images in the memory on which we want to apply for style transfer. We have a content image, and style image and the target image will be the combination of both these images. Not every image needs to have [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2237,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1439"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1439"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1439/revisions"}],"predecessor-version":[{"id":2247,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1439/revisions/2247"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2237"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1439"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1439"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1439"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1440,"date":"2020-05-21T09:53:19","date_gmt":"2020-05-21T09:53:19","guid":{"rendered":"http://python3.foobrdigital.com/?p=1440"},"modified":"2020-12-16T16:59:02","modified_gmt":"2020-12-16T16:59:02","slug":"feature","status":"publish","type":"post","link":"https://python3.foobrdigital.com/feature/","title":{"rendered":"Feature"},"content":{"rendered":"\n<p>After loading the images into memory, we will implement the style transfer. It is necessary to separate the style of the image from its contents to achieve the style transfer. After that, it is also possible to transfer the style elements of one image to the content elements of the second image. This process is done using mainly feature extraction from standard convolutional neural networks.</p>\n\n\n\n<p>These features are then manipulated to extract either content information or style information. This process involves three images a style image, a content image and finally a target image. The style of the&nbsp;<strong>style image</strong>&nbsp;is combined with the content in the content image to create a final target image.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-feature-extraction-for-style-transferring.png\" alt=\"Feature Extraction for Style Transferring\"/></figure>\n\n\n\n<p>This process begins by selecting a few layers within our model to extract features from. We will get a good idea of how our image is being processed throughout the neural network by selecting a few layers to extract features from. We extract the model features of our style image and content image as well. After that, we extract features from our target image and compare it to our style image feature and our content image feature.</p>\n\n\n\n<h2>Getting features from the images</h2>\n\n\n\n<pre class=\"wp-block-code\"><code># Defining simple method with two arguments, i.e. our image and our model  \ndef get_features(image,model):  \n#choosing specific layer within our VGG-19 model that we are going to extract features from   \n# Defining layers dictionary object which contains the specific layers    \n  layers={'0':'conv1_1', #Mapping 0 to conv1_1  \n          '5':'conv2_1', #Mapping 5 to conv2_1  \n          '10':'conv3_1', #Mapping 10 to conv3_1  \n          '19':'conv4_1', #Mapping 19 to conv4_1  \n          '21':'conv4_2', #Mapping 21 to conv4_2  \n          '28':'conv5_1',} #Mapping 28 to conv5_1  </code></pre>\n\n\n\n<p>Now we have six feature extraction layers. In these six feature extraction layer, we will use five of these for style extraction and only one of them for content extraction. We will use conv4_2 for content extraction. This only single layer is sufficient for extracting content. This layer is deeper into our neural network and provide high depth image feature. This is the reason that pre-trained object detection convolutional neural network become very effective in representing content elements.</p>\n\n\n\n<p>Getting style features from various features throughout the network allowing for optimal style creation. Extracting style features from numerous layers will allow for the most effective style extraction and recreation.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>#Defining an empty dictionary called features to store all the extracted features   \nfeatures={}  \n  #Running a loop which iterates over all of the layers in our model   \n  for name, layer in model._modules.items():   \n    #Running our image through the specific layer and store into the new image  \n    image=layer(image)  \n    #checking the name of the current layer which we are iterating through is inside layers  \n    if name in layers:  \n      #If true then store the output from that specific layer   \n      features&#91;layers&#91;name]]=image   \n  #returning feature dictionary   \n  return features  </code></pre>\n\n\n\n<p>Once we initialize our get feature method, we have to call it with our content image and our VGG model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>content_features=get_features(content,vgg)  </code></pre>\n\n\n\n<p>in the same way, we will do it for our style image as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>style_features=get_features(style, vgg)  </code></pre>\n","protected":false},"excerpt":{"rendered":"<p>After loading the images into memory, we will implement the style transfer. It is necessary to separate the style of the image from its contents to achieve the style transfer. After that, it is also possible to transfer the style elements of one image to the content elements of the second image. This process is [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2238,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1440"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1440"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1440/revisions"}],"predecessor-version":[{"id":1456,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1440/revisions/1456"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2238"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1440"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1440"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1440"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1458,"date":"2020-05-21T09:55:15","date_gmt":"2020-05-21T09:55:15","guid":{"rendered":"http://python3.foobrdigital.com/?p=1458"},"modified":"2020-12-16T16:59:02","modified_gmt":"2020-12-16T16:59:02","slug":"gram-matrix","status":"publish","type":"post","link":"https://python3.foobrdigital.com/gram-matrix/","title":{"rendered":"Gram Matrix"},"content":{"rendered":"\n<p>Previously we extracted all the relevant features which we wanted for our content and style images. The convolutional neural network does a good job for extracting the content element from any image which is fed into it.</p>\n\n\n\n<p>The extracted style features require one additional pre-processing step to be more useful. The researcher used the gram matrix for more effective style feature extraction and made it an important step. Any feature extracted from the convolutional network still holds content related information such as object structure and positioning.</p>\n\n\n\n<p>This content-related information is eliminated by applying the gram matrix to these extracted features, and it will not affect the style information. Style extraction from images is a broad topic on its own. Applying a gram matrix to features extracted from convolutional neural networks helps to create texture information related to the data.</p>\n\n\n\n<p>The Gram Matrix is defined using the following simple equation:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>                  Gram=V^T V</code></pre>\n\n\n\n<p>Here, V is an arbitrary vector and multiply with its transpose.</p>\n\n\n\n<h2>Defining gram_matrix() function</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>#Initializing gram_matrix function for our tensor image   \ndef gram_matrix(tensor):  \n   #Unwrapping the tensor dimensions into respective variables i.e. batch size, distance, height and width   \n  _,d,h,w=tensor.size()   \n  #Reshaping data into a two dimensional of array or two dimensional of tensor  \n  tensor=tensor.view(d,h*w)  \n  #Multiplying the original tensor with its own transpose using torch.mm   \n  #tensor.t() will return the transpose of original tensor  \n  gram=torch.mm(tensor,tensor.t())  \n  #Returning gram matrix   \n  return gram  </code></pre>\n\n\n\n<h2>Applying gram_matrix() function to the Style features</h2>\n\n\n\n<p>We have the feature extraction function and gram matrix function to make the process of style transfer. Now, we will apply the gram_matrix() function to the style feature which we extracted earlier.</p>\n\n\n\n<p>Now we will create a dictionary for style grams and map each layer to the gram matrix of its corresponding feature. The key to our dictionary is going to be a specific layer. While the value which is going to contain the gram matrix of the respective style feature for that same layer. After that, we will iterate each layer inside of our style feature dictionary to get the gram matrix of all the features which we previously extracted.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>style_grams={layer:gram_matrix(style_features&#91;layer]) for layer in style_features} </code></pre>\n\n\n\n<h2>Initialization of style weights dictionary</h2>\n\n\n\n<p>We have all our extracted features and a dictionary which contain the respective gram matrix of all the features which are extracted. We have chosen five layers to extract features from ii and provides a variety of ways for re-construction of the image style, which also leaves view for customizability. We will choose to prioritize certain layers over other layers by associating certain weight parameters with each layer.</p>\n\n\n\n<p><strong>Note:</strong>&nbsp;Layers close to the beginning of the model are usually effective at re-creating style features while later layers offer additional variety towards the style element.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>#Initializing style_weights dictionary  \nstyle_weights={'conv1_1':1.,      #Key 1 with max value 1  \n               'conv2_1':0.75,  #Key 2 with max value 0.75  \n               'conv3_1':0.2,    #Key 3 with max value 0.2  \n               'conv4_1':0.2,   #Key 4 with max value 0.2  \n               'conv5_1':0.2}   #Key 5 with max value 0.2  </code></pre>\n\n\n\n<p>Another weight parameter which we need to define is the amount of balance that we dictated between the content image and the style image. This allows us to customize our final target image by defining the ratio of style to content.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>content_weight=1  \nstyle_weight=1e6   </code></pre>\n\n\n\n<p>Now, we will use the style and content image data to optimize our target image. So we will start with our original target image. Our target image will obtain from the content .clone statement as:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>target=content.clone().requires_grad_(True).to(device)   </code></pre>\n\n\n\n<p>Now, we have all three of our images and will perform the optimization process later.</p>\n","protected":false},"excerpt":{"rendered":"<p>Previously we extracted all the relevant features which we wanted for our content and style images. The convolutional neural network does a good job for extracting the content element from any image which is fed into it. The extracted style features require one additional pre-processing step to be more useful. The researcher used the gram [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2239,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1458"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1458"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1458/revisions"}],"predecessor-version":[{"id":2248,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1458/revisions/2248"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2239"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1458"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1458"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1458"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":1459,"date":"2020-05-21T09:57:04","date_gmt":"2020-05-21T09:57:04","guid":{"rendered":"http://python3.foobrdigital.com/?p=1459"},"modified":"2020-12-16T16:59:01","modified_gmt":"2020-12-16T16:59:01","slug":"optimization-process","status":"publish","type":"post","link":"https://python3.foobrdigital.com/optimization-process/","title":{"rendered":"Optimization process"},"content":{"rendered":"\n<p>We have all the three images, and now, we can perform our optimization process. To perform the optimization process, we have to perform the following steps:</p>\n\n\n\n<p><strong>Step 1:</strong></p>\n\n\n\n<p>In the first step, we define a few basic parameters that help us to visualize the training process and for us to facilitate the training process. The first parameters show us our target image every time so that we can check the optimization process. We define our Adam optimizer with our target image and set learning rate with it. And last but not least, we define the number of optimization steps which our training process should take.</p>\n\n\n\n<p>We need to have a balance between results and time efficiency as the training process can take very long to complete. So we will define our steps, and in our case, we limit our steps to 2100.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>show_every=300  \noptimizer=optim.Adam(&#91;target],lr=0.003)  \nsteps=2100  </code></pre>\n\n\n\n<p><strong>Step 2:</strong></p>\n\n\n\n<p>Now, we implement a few code line for data visualization. We define an image array which is going to store target images throughout the training process. After the training process, we can create a video out of these images to get a visual of how the style and content images combine to optimize the target image. We will unwrap the shape of our target image.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>height,width,channels=im_convert(target).shape  \nimage_array=np.empty(shape=(300,height,width,channels))  </code></pre>\n\n\n\n<p>We will define a capture frame which helps us to capture a frame every time. And in last we will define a counter variable which will keep track of the array index.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>capture_frame=steps/300  \ncounter=0  </code></pre>\n\n\n\n<h2>Iteration process of optimization</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>#Defining a loop statement from 1 to steps+1  \nfor ii in range(1,steps+1): #To ensure that our loop runs for the defined number of steps   \n  # Extracting feature for our current target image   \n  target_features=get_features(target,vgg)  \n  #Calculating the content loss for the iteration  \n  content_loss=torch.mean((target_features&#91;'conv4_2']content_features&#91;'conv4_2'])**2)  \n  #Initializing style loss   \n  style_loss=0  \n #The style loss is the result of a combine loss from five different layer within our model.  \n #For this reason we iterate through the five style features to get the error at each layer.   \n  for layer in style_weights:  \n    #Collecting the target feature for the specific layer from the target feature variable   \n    target_feature=target_features&#91;layer]  \n    #Applying gram matrix function to our target feature  \n    target_gram=gram_matrix(target_feature)  \n    #Getting style_gram value for our style image from the style grams variable  \n    style_gram=style_grams&#91;layer]  \n    #Calculating the layer style loss as content loss  \n    layer_style_loss=style_weights&#91;layer]*torch.mean((target_gram-style_gram)**2)  \n    #Obtaining feature dimensions    \n    _,d,h,w=target_feature.shape      \n    #Calculating total style loss  \n    style_loss += layer_style_loss/(d*h*w)  \n  #Calculating total loss  \n  total_loss=content_weight*content_loss+style_weight*style_loss  \n  #Using the optimizer to update parameters within our target image   \n  optimizer.zero_grad()  \n  total_loss.backward()  \n  optimizer.step()  \n  #Process  for visualization throughout the training process  \n  #Comparing the iteration variable with our show every    \n  if ii % show_every==0:   \n    #Printing total loss  \n    print('Total loss:',total_loss.item())  \n    #Printing the iteration   \n    print('Iteration',ii)  \n    #Printting the target images   \n    plt.imshow(im_convert(target))  \n    #Removing the axis on the image   \n    plt.axis('off')  \n    # Showing image   \n    plt.show()  \n   #Comparing the iteration variable with our capture frame variable   \n   if ii%capture_frame==0: # Capturing a frame at every 700 iteration  \n     #Storing the target image into the image_array  \n     image_array&#91;counter]=im_convert(target)  \n     # Increment in the counter variable   \n     counter=counter+1  </code></pre>\n\n\n\n<p>When we run the code, it will give us the expected output as:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-optimization-process-for-style-transferring.png\" alt=\"Optimization process for Style Transferring\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-optimization-process-for-style-transferring2.png\" alt=\"Optimization process for Style Transferring\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-optimization-process-for-style-transferring3.png\" alt=\"Optimization process for Style Transferring\"/></figure>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-optimization-process-for-style-transferring4.png\" alt=\"Optimization process for Style Transferring\"/></figure>\n\n\n\n<h2>Plotting content, style and final target image</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>#Making a grid arrangement with a single row and three columns for our three images  \nfig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(20,10))  \n#Plotting content image   \nax1.imshow(im_convert(content))  \nax1.axis('off')  \n#Plotting style image  \nax2.imshow(im_convert(style))  \nax2.axis('off')  \n#Plotting target image  \nax3.imshow(im_convert(target))  \nax3.axis('off')  </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-optimization-process-for-style-transferring5.png\" alt=\"Optimization process for Style Transferring\"/></figure>\n\n\n\n<h2>Complete code</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>#Required Libraries  \nimport torch  \nimport torch.optim as optim  \nfrom torchvision import transforms, models  \nfrom PIL import Image  \nimport matplotlib.pyplot as plt  \nimport numpy as np  \n  \n#Creating Model  \nvgg=models.vgg19(pretrained=True).features  \nfor param in vgg.parameters():  \n    param.requires_grad_(False)  \n  \n#Add model to device  \ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \nvgg.to(device)  \n  \n#Load Iamge  \ndef load_image(img_path,max_size=400,shape=None):  \n    image=Image.open(img_path).convert('RGB')  \n    if max(image.size)>max_size:  \n      size=max_size  \n    else:  \n      size=max(image.size)  \n        \n    if shape is not None:  \n       size=shape  \n      \n    in_transform=transforms.Compose(&#91;  \n        transforms.Resize(size),  \n        transforms.ToTensor(),  \n        transforms.Normalize((0.5,0.5,0.5),  \n                            (0.5,0.5,0.5))  \n    ])  \n    image=in_transform(image).unsqueeze(0)  \n    return image  \n      \n      \ncontent=load_image('ab.jpg').to(device)  \nstyle=load_image('abc.jpg',shape=content.shape&#91;-2:]).to(device)  \n  \n#Image Conversion  \ndef im_convert(tensor):  \n  image=tensor.cpu().clone().detach().numpy()  \n  image=image.squeeze()  \n  image=image.transpose(1,2,0)  \n  image=image*np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5))  \n  image=image.clip(0,1)  \n  return image  \n   \n#Plotting Images  \nfig, (ax1,ax2)=plt.subplots(1,2,figsize=(20,10))  \nax1.imshow(im_convert(content))  \nax1.axis('off')  \nax2.imshow(im_convert(style))  \nax2.axis('off')  \n  \n#Getting Features  \ndef get_features(image,model):  \n  layers={'0':'conv1_1',  \n          '5':'conv2_1',  \n         '10':'conv3_1',  \n         '19':'conv4_1',  \n         '21':'conv4_2',  \n         '28':'conv5_1',}  \n  features={}  \n  for name, layer in model._modules.items():  \n    image=layer(image)  \n    if name in layers:  \n      features&#91;layers&#91;name]]=image  \n  return features  \n  \n#Making content and style features  \ncontent_features=get_features(content,vgg)  \nstyle_features=get_features(style, vgg)  \n  \n#Creating gram matrix  \ndef gram_matrix(tensor):  \n  _,d,h,w=tensor.size()  \n  tensor=tensor.view(d,h*w)  \n  gram=torch.mm(tensor,tensor.t())  \n  return gram  \n    \n#Creating style grams  \nstyle_grams={layer:gram_matrix(style_features&#91;layer]) for layer in style_features}  \n  \n#Initializing style weights  \nstyle_weights={'conv1_1':1.,  \n               'conv2_1':0.75,  \n               'conv3_1':0.2,  \n               'conv4_1':0.2,  \n               'conv5_1':0.2}  \ncontent_weight=1  \nstyle_weight=1e6  \ntarget=content.clone().requires_grad_(True).to(device)  \n  \n#Performing optimization  \nshow_every=300  \noptimizer=optim.Adam(&#91;target],lr=0.003)  \nsteps=2100  \nheight,width,channels=im_convert(target).shape  \nimage_array=np.empty(shape=(300,height,width,channels))  \ncapture_frame=steps/300  \ncounter=0  \nfor ii in range(1,steps+1):  \n  target_features=get_features(target,vgg)  \n  content_loss=torch.mean((target_features&#91;'conv4_2']-content_features&#91;'conv4_2'])**2)  \n  style_loss=0  \n  for layer in style_weights:  \n    target_feature=target_features&#91;layer]  \n    target_gram=gram_matrix(target_feature)  \n    style_gram=style_grams&#91;layer]  \n    layer_style_loss=style_weights&#91;layer]*torch.mean((target_gram-style_gram)**2)  \n    _,d,h,w=target_feature.shape  \n    style_loss += layer_style_loss/(d*h*w)  \ntotal_loss=content_weight*content_loss+style_weight*style_loss  \noptimizer.zero_grad()  \ntotal_loss.backward()  \noptimizer.step()  \n  \n#Plotting output images  \nif ii % show_every==0:  \n  print('Total loss:',total_loss.item())  \n  print('Iteration',ii)  \n  plt.imshow(im_convert(target))  \n  plt.axis('off')  \n  plt.show()  \nif ii%capture_frame==0:  \n  image_array&#91;counter]=im_convert(target)  \n  counter=counter+1  \n      \n#Plotting content, style and target images  \nfig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(20,10))  \nax1.imshow(im_convert(content))  \nax1.axis('off')  \nax2.imshow(im_convert(style))  \nax2.axis('off')  \nax3.imshow(im_convert(target))  \nax3.axis('off')   </code></pre>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-optimization-process-for-style-transferring6.png\" alt=\"Optimization process for Style Transferring\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>We have all the three images, and now, we can perform our optimization process. To perform the optimization process, we have to perform the following steps: Step 1: In the first step, we define a few basic parameters that help us to visualize the training process and for us to facilitate the training process. The [&hellip;]</p>\n","protected":false},"author":5,"featured_media":2240,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17,77,151],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1459"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/5"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=1459"}],"version-history":[{"count":2,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1459/revisions"}],"predecessor-version":[{"id":2482,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/1459/revisions/2482"}],"wp:featuredmedia":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media/2240"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=1459"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=1459"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=1459"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}}]