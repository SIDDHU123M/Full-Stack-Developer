[{"id":2753,"date":"2020-07-08T09:50:50","date_gmt":"2020-07-08T09:50:50","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1676"},"modified":"2020-12-16T16:53:11","modified_gmt":"2020-12-16T16:53:11","slug":"introduction-12","status":"publish","type":"post","link":"https://python3.foobrdigital.com/introduction-12/","title":{"rendered":"Introduction"},"content":{"rendered":"\n<p>In this chapter, we will understand the concept of concurrency in Python and learn about the different threads and processes.</p>\n\n\n\n<h2>What is Concurrency?</h2>\n\n\n\n<p>In simple words, concurrency is the occurrence of two or more events at the same time. Concurrency is a natural phenomenon because many events occur simultaneously at any given time.</p>\n\n\n\n<p>In terms of programming, concurrency is when two tasks overlap in execution. With concurrent programming, the performance of our applications and software systems can be improved because we can concurrently deal with the requests rather than waiting for a previous one to be completed.</p>\n\n\n\n<h2>Historical Review of Concurrency</h2>\n\n\n\n<p>Following points will give us the brief historical review of concurrency −</p>\n\n\n\n<h3>From the concept of railroads</h3>\n\n\n\n<p>Concurrency is closely related with the concept of railroads. With the railroads, there was a need to handle multiple trains on the same railroad system in such a way that every train would get to its destination safely.</p>\n\n\n\n<h3>Concurrent computing in academia</h3>\n\n\n\n<p>The interest in computer science concurrency began with the research paper published by Edsger W. Dijkstra in 1965. In this paper, he identified and solved the problem of mutual exclusion, the property of concurrency control.</p>\n\n\n\n<h3>High-level concurrency primitives</h3>\n\n\n\n<p>In recent times, programmers are getting improved concurrent solutions because of the introduction of high-level concurrency primitives.</p>\n\n\n\n<h3>Improved concurrency with programming languages</h3>\n\n\n\n<p>Programming languages such as Google’s Golang, Rust and Python have made incredible developments in areas which help us get better concurrent solutions.</p>\n\n\n\n<h2>What is thread &amp; multithreading?</h2>\n\n\n\n<p><strong>Thread</strong>&nbsp;is the smallest unit of execution that can be performed in an operating system. It is not itself a program but runs within a program. In other words, threads are not independent of one other. Each thread shares code section, data section, etc. with other threads. They are also known as lightweight processes.</p>\n\n\n\n<p>A thread consists of the following components −</p>\n\n\n\n<ul><li>Program counter which consist of the address of the next executable instruction</li><li>Stack</li><li>Set of registers</li><li>A unique id</li></ul>\n\n\n\n<p><strong>Multithreading</strong>, on the other hand, is the ability of a CPU to manage the use of operating system by executing multiple threads concurrently. The main idea of multithreading is to achieve parallelism by dividing a process into multiple threads. The concept of multithreading can be understood with the help of the following example.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Suppose we are running a particular process wherein we open MS Word to type content into it. One thread will be assigned to open MS Word and another thread will be required to type content in it. And now, if we want to edit the existing then another thread will be required to do the editing task and so on.</p>\n\n\n\n<h2>What is process &amp; multiprocessing?</h2>\n\n\n\n<p>A<strong>process</strong>is defined as an entity, which represents the basic unit of work to be implemented in the system. To put it in simple terms, we write our computer programs in a text file and when we execute this program, it becomes a process that performs all the tasks mentioned in the program. During the process life cycle, it passes through different stages – Start, Ready, Running, Waiting and Terminating.</p>\n\n\n\n<p>Following diagram shows the different stages of a process −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/multiprocessing.jpg\" alt=\"Multiprocessing\"/></figure>\n\n\n\n<p>A process can have only one thread, called primary thread, or multiple threads having their own set of registers, program counter and stack. Following diagram will show us the difference −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/multiprocessing_one.jpg\" alt=\"Multiprocessing One\"/></figure>\n\n\n\n<p><strong>Multiprocessing,</strong>&nbsp;on the other hand, is the use of two or more CPUs units within a single computer system. Our primary goal is to get the full potential from our hardware. To achieve this, we need to utilize full number of CPU cores available in our computer system. Multiprocessing is the best approach to do so.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/multiprocessing_two.jpg\" alt=\"Multiprocessing Two\"/></figure>\n\n\n\n<p>Python is one of the most popular programming languages. Followings are some reasons that make it suitable for concurrent applications −</p>\n\n\n\n<h3>Syntactic sugar</h3>\n\n\n\n<p>Syntactic sugar is syntax within a programming language that is designed to make things easier to read or to express. It makes the language “sweeter” for human use: things can be expressed more clearly, more concisely, or in an alternative style based on preference. Python comes with Magic methods, which can be defined to act on objects. These Magic methods are used as syntactic sugar and bound to more easy-to-understand keywords.</p>\n\n\n\n<h3>Large Community</h3>\n\n\n\n<p>Python language has witnessed a massive adoption rate amongst data scientists and mathematicians, working in the field of AI, machine learning, deep learning and quantitative analysis.</p>\n\n\n\n<h3>Useful APIs for concurrent programming</h3>\n\n\n\n<p>Python 2 and 3 have large number of APIs dedicated for parallel/concurrent programming. Most popular of them are&nbsp;<strong>threading, concurrent.features, multiprocessing, asyncio, gevent and greenlets,</strong>&nbsp;etc.</p>\n\n\n\n<h2>Limitations of Python in implementing concurrent applications</h2>\n\n\n\n<p>Python comes with a limitation for concurrent applications. This limitation is called&nbsp;<strong>GIL (Global Interpreter Lock)</strong>&nbsp;is present within Python. GIL never allows us to utilize multiple cores of CPU and hence we can say that there are no true threads in Python. We can understand the concept of GIL as follows −</p>\n\n\n\n<h3>GIL (Global Interpreter Lock)</h3>\n\n\n\n<p>It is one of the most controversial topics in the Python world. In CPython, GIL is the mutex &#8211; the mutual exclusion lock, which makes things thread safe. In other words, we can say that GIL prevents multiple threads from executing Python code in parallel. The lock can be held by only one thread at a time and if we want to execute a thread then it must acquire the lock first. The diagram shown below will help you understand the working of GIL.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/limitations.jpg\" alt=\"Limitations\"/></figure>\n\n\n\n<p>However, there are some libraries and implementations in Python such as&nbsp;<strong>Numpy, Jpython</strong>and&nbsp;<strong>IronPytbhon.</strong>&nbsp;These libraries work without any interaction with GIL.</p>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, we will understand the concept of concurrency in Python and learn about the different threads and processes. What is Concurrency? In simple words, concurrency is the occurrence of two or more events at the same time. Concurrency is a natural phenomenon because many events occur simultaneously at any given time. In terms [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2753"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2753"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2753/revisions"}],"predecessor-version":[{"id":2999,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2753/revisions/2999"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2753"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2753"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2753"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2754,"date":"2020-07-08T09:52:34","date_gmt":"2020-07-08T09:52:34","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1678"},"modified":"2020-12-16T16:53:11","modified_gmt":"2020-12-16T16:53:11","slug":"concurrency-vs-parallelism","status":"publish","type":"post","link":"https://python3.foobrdigital.com/concurrency-vs-parallelism/","title":{"rendered":"Concurrency vs Parallelism"},"content":{"rendered":"\n<p>Both concurrency and parallelism are used in relation to multithreaded programs but there is a lot of confusion about the similarity and difference between them. The big question in this regard: is concurrency parallelism or not? Although both the terms appear quite similar but the answer to the above question is NO, concurrency and parallelism are not same. Now, if they are not same then what is the basic difference between them?</p>\n\n\n\n<p>In simple terms, concurrency deals with managing the access to shared state from different threads and on the other side, parallelism deals with utilizing multiple CPUs or its cores to improve the performance of hardware.</p>\n\n\n\n<h2>Concurrency in Detail</h2>\n\n\n\n<p>Concurrency is when two tasks overlap in execution. It could be a situation where an application is progressing on more than one task at the same time. We can understand it diagrammatically; multiple tasks are making progress at the same time, as follows −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/concurrency.jpg\" alt=\"Concurrency\"/></figure>\n\n\n\n<h2>Levels of Concurrency</h2>\n\n\n\n<p>In this section, we will discuss the three important levels of concurrency in terms of programming −</p>\n\n\n\n<h3>Low-Level Concurrency</h3>\n\n\n\n<p>In this level of concurrency, there is explicit use of atomic operations. We cannot use such kind of concurrency for application building, as it is very error-prone and difficult to debug. Even Python does not support such kind of concurrency.</p>\n\n\n\n<h3>Mid-Level Concurrency</h3>\n\n\n\n<p>In this concurrency, there is no use of explicit atomic operations. It uses the explicit locks. Python and other programming languages support such kind of concurrency. Mostly application programmers use this concurrency.</p>\n\n\n\n<h3>High-Level Concurrency</h3>\n\n\n\n<p>In this concurrency, neither explicit atomic operations nor explicit locks are used. Python has&nbsp;<strong>concurrent.futures</strong>&nbsp;module to support such kind of concurrency.</p>\n\n\n\n<h2>Properties of Concurrent Systems</h2>\n\n\n\n<p>For a program or concurrent system to be correct, some properties must be satisfied by it. Properties related to the termination of system are as follows −</p>\n\n\n\n<h3>Correctness property</h3>\n\n\n\n<p>The correctness property means that the program or the system must provide the desired correct answer. To keep it simple, we can say that the system must map the starting program state to final state correctly.</p>\n\n\n\n<h3>Safety property</h3>\n\n\n\n<p>The safety property means that the program or the system must remain in a&nbsp;<strong>“good”</strong>&nbsp;or&nbsp;<strong>“safe”</strong>&nbsp;state and never does anything&nbsp;<strong>“bad”</strong>.</p>\n\n\n\n<h3>Liveness property</h3>\n\n\n\n<p>This property means that a program or system must&nbsp;<strong>“make progress”</strong>&nbsp;and it would reach at some desirable state.</p>\n\n\n\n<h3>Actors of concurrent systems</h3>\n\n\n\n<p>This is one common property of concurrent system in which there can be multiple processes and threads, which run at the same time to make progress on their own tasks. These processes and threads are called actors of the concurrent system.</p>\n\n\n\n<h3>Resources of Concurrent Systems</h3>\n\n\n\n<p>The actors must utilize the resources such as memory, disk, printer etc. in order to perform their tasks.</p>\n\n\n\n<h3>Certain set of rules</h3>\n\n\n\n<p>Every concurrent system must possess a set of rules to define the kind of tasks to be performed by the actors and the timing for each. The tasks could be acquiring of locks, memory sharing, modifying the state, etc.</p>\n\n\n\n<h2>Barriers of Concurrent Systems</h2>\n\n\n\n<p>While implementing concurrent systems, the programmer must take into consideration the following two important issues, which can be the barriers of concurrent systems −</p>\n\n\n\n<h3>Sharing of data</h3>\n\n\n\n<p>An important issue while implementing the concurrent systems is the sharing of data among multiple threads or processes. Actually, the programmer must ensure that locks protect the shared data so that all the accesses to it are serialized and only one thread or process can access the shared data at a time. In case, when multiple threads or processes are all trying to access the same shared data then not all but at least one of them would be blocked and would remain idle. In other words, we can say that we would be able to use only one process or thread at a time when lock is in force. There can be some simple solutions to remove the above-mentioned barriers −</p>\n\n\n\n<h3>Data Sharing Restriction</h3>\n\n\n\n<p>The simplest solution is not to share any mutable data. In this case, we need not to use explicit locking and the barrier of concurrency due to mutual data would be solved.</p>\n\n\n\n<h3>Data Structure Assistance</h3>\n\n\n\n<p>Many times the concurrent processes need to access the same data at the same time. Another solution, than using of explicit locks, is to use a data structure that supports concurrent access. For example, we can use the&nbsp;<strong>queue</strong>&nbsp;module, which provides thread-safe queues. We can also use&nbsp;<strong>multiprocessing.JoinableQueue</strong>&nbsp;classes for multiprocessing-based concurrency.</p>\n\n\n\n<h3>Immutable Data Transfer</h3>\n\n\n\n<p>Sometimes, the data structure that we are using, say concurrency queue, is not suitable then we can pass the immutable data without locking it.</p>\n\n\n\n<h3>Mutable Data Transfer</h3>\n\n\n\n<p>In continuation of the above solution, suppose if it is required to pass only mutable data, rather than immutable data, then we can pass mutable data that is read only.</p>\n\n\n\n<h3>Sharing of I/O Resources</h3>\n\n\n\n<p>Another important issue in implementing concurrent systems is the use of I/O resources by threads or processes. The problem arises when one thread or process is using the I/O for such a long time and other is sitting idle. We can see such kind of barrier while working with an I/O heavy application. It can be understood with the help of an example, the requesting of pages from web browser. It is a heavy application. Here, if the rate at which the data is requested is slower than the rate at which it is consumed then we have I/O barrier in our concurrent system.</p>\n\n\n\n<p>The following Python script is for requesting a web page and getting the time our network took to get the requested page −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import urllib.request\n\nimport time\n\nts = time.time()\n\nreq = urllib.request.urlopen('http://www.tutorialspoint.com')\n\npageHtml = req.read()\n\nte = time.time()\n\nprint(\"Page Fetching Time : {} Seconds\".format (te-ts))</code></pre>\n\n\n\n<p>After executing the above script, we can get the page fetching time as shown below.</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Page Fetching Time: 1.0991398811340332 Seconds\n</code></pre>\n\n\n\n<p>We can see that the time to fetch the page is more than one second. Now what if we want to fetch thousands of different web pages, you can understand how much time our network would take.</p>\n\n\n\n<h2>What is Parallelism?</h2>\n\n\n\n<p>Parallelism may be defined as the art of splitting the tasks into subtasks that can be processed simultaneously. It is opposite to the concurrency, as discussed above, in which two or more events are happening at the same time. We can understand it diagrammatically; a task is broken into a number of subtasks that can be processed in parallel, as follows −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/parallelism.jpg\" alt=\"Parallelism\"/></figure>\n\n\n\n<p>To get more idea about the distinction between concurrency and parallelism, consider the following points −</p>\n\n\n\n<h3>Concurrent but not parallel</h3>\n\n\n\n<p>An application can be concurrent but not parallel means that it processes more than one task at the same time but the tasks are not broken down into subtasks.</p>\n\n\n\n<h3>Parallel but not concurrent</h3>\n\n\n\n<p>An application can be parallel but not concurrent means that it only works on one task at a time and the tasks broken down into subtasks can be processed in parallel.</p>\n\n\n\n<h3>Neither parallel nor concurrent</h3>\n\n\n\n<p>An application can be neither parallel nor concurrent. This means that it works on only one task at a time and the task is never broken into subtasks.</p>\n\n\n\n<h3>Both parallel and concurrent</h3>\n\n\n\n<p>An application can be both parallel and concurrent means that it both works on multiple tasks at a time and the task is broken into subtasks for executing them in parallel.</p>\n\n\n\n<h2>Necessity of Parallelism</h2>\n\n\n\n<p>We can achieve parallelism by distributing the subtasks among different cores of single CPU or among multiple computers connected within a network.</p>\n\n\n\n<p>Consider the following important points to understand why it is necessary to achieve parallelism −</p>\n\n\n\n<h3>Efficient code execution</h3>\n\n\n\n<p>With the help of parallelism, we can run our code efficiently. It will save our time because the same code in parts is running in parallel.</p>\n\n\n\n<h3>Faster than sequential computing</h3>\n\n\n\n<p>Sequential computing is constrained by physical and practical factors due to which it is not possible to get faster computing results. On the other hand, this issue is solved by parallel computing and gives us faster computing results than sequential computing.</p>\n\n\n\n<h3>Less execution time</h3>\n\n\n\n<p>Parallel processing reduces the execution time of program code.</p>\n\n\n\n<p>If we talk about real life example of parallelism, the graphics card of our computer is the example that highlights the true power of parallel processing because it has hundreds of individual processing cores that work independently and can do the execution at the same time. Due to this reason, we are able to run high-end applications and games as well.</p>\n\n\n\n<h2>Understanding of the processors for implementation</h2>\n\n\n\n<p>We know about concurrency, parallelism and the difference between them but what about the system on which it is to be implemented. It is very necessary to have the understanding of the system, on which we are going to implement, because it gives us the benefit to take informed decision while designing the software. We have the following two kinds of processors −</p>\n\n\n\n<h3>Single-core processors</h3>\n\n\n\n<p>Single-core processors are capable of executing one thread at any given time. These processors use&nbsp;<strong>context switching</strong>&nbsp;to store all the necessary information for a thread at a specific time and then restoring the information later. The context switching mechanism helps us make progress on a number of threads within a given second and it looks as if the system is working on multiple things.</p>\n\n\n\n<p>Single-core processors come with many advantages. These processors require less power and there is no complex communication protocol between multiple cores. On the other hand, the speed of single-core processors is limited and it is not suitable for larger applications.</p>\n\n\n\n<h3>Multi-core processors</h3>\n\n\n\n<p>Multi-core processors have multiple independent processing units also called&nbsp;<strong>cores</strong>.</p>\n\n\n\n<p>Such processors do not need context switching mechanism as each core contains everything it needs to execute a sequence of stored instructions.</p>\n\n\n\n<h2>Fetch-Decode-Execute Cycle</h2>\n\n\n\n<p>The cores of multi-core processors follow a cycle for executing. This cycle is called the&nbsp;<strong>Fetch-Decode-Execute</strong>&nbsp;cycle. It involves the following steps −</p>\n\n\n\n<h3>Fetch</h3>\n\n\n\n<p>This is the first step of cycle, which involves the fetching of instructions from the program memory.</p>\n\n\n\n<h3>Decode</h3>\n\n\n\n<p>Recently fetched instructions would be converted to a series of signals that will trigger other parts of the CPU.</p>\n\n\n\n<h3>Execute</h3>\n\n\n\n<p>It is the final step in which the fetched and the decoded instructions would be executed. The result of execution will be stored in a CPU register.</p>\n\n\n\n<p>One advantage over here is that the execution in multi-core processors are faster than that of single-core processors. It is suitable for larger applications. On the other hand, complex communication protocol between multiple cores is an issue. Multiple cores require more power than single-core processors.</p>\n","protected":false},"excerpt":{"rendered":"<p>Both concurrency and parallelism are used in relation to multithreaded programs but there is a lot of confusion about the similarity and difference between them. The big question in this regard: is concurrency parallelism or not? Although both the terms appear quite similar but the answer to the above question is NO, concurrency and parallelism [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2754"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2754"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2754/revisions"}],"predecessor-version":[{"id":2998,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2754/revisions/2998"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2754"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2754"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2754"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2755,"date":"2020-07-08T09:53:36","date_gmt":"2020-07-08T09:53:36","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1680"},"modified":"2020-12-16T16:53:11","modified_gmt":"2020-12-16T16:53:11","slug":"memory-architecture","status":"publish","type":"post","link":"https://python3.foobrdigital.com/memory-architecture/","title":{"rendered":"Memory Architecture"},"content":{"rendered":"\n<p>There are different system and memory architecture styles that need to be considered while designing the program or concurrent system. It is very necessary because one system &amp; memory style may be suitable for one task but may be error prone to other task.</p>\n\n\n\n<h2>Computer system architectures supporting concurrency</h2>\n\n\n\n<p>Michael Flynn in 1972 gave taxonomy for categorizing different styles of computer system architecture. This taxonomy defines four different styles as follows −</p>\n\n\n\n<ul><li>Single instruction stream, single data stream (SISD)</li><li>Single instruction stream, multiple data stream (SIMD)</li><li>Multiple instruction stream, single data stream (MISD)</li><li>Multiple instruction stream, multiple data stream (MIMD).</li></ul>\n\n\n\n<h2>Single instruction stream, single data stream (SISD)</h2>\n\n\n\n<p>As the name suggests, such kind of systems would have one sequential incoming data stream and one single processing unit to execute the data stream. They are just like uniprocessor systems having parallel computing architecture. Following is the architecture of SISD −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/ssid.jpg\" alt=\"SSID\"/></figure>\n\n\n\n<h3>Advantages of SISD</h3>\n\n\n\n<p>The advantages of SISD architecture are as follows −</p>\n\n\n\n<ul><li>It requires less power.</li><li>There is no issue of complex communication protocol between multiple cores.</li></ul>\n\n\n\n<h3>Disadvantages of SISD</h3>\n\n\n\n<p>The disadvantages of SISD architecture are as follows −</p>\n\n\n\n<ul><li>The speed of SISD architecture is limited just like single-core processors.</li><li>It is not suitable for larger applications.</li></ul>\n\n\n\n<h2>Single instruction stream, multiple data stream (SIMD)</h2>\n\n\n\n<p>As the name suggests, such kind of systems would have multiple incoming data streams and number of processing units that can act on a single instruction at any given time. They are just like multiprocessor systems having parallel computing architecture. Following is the architecture of SIMD −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/simd.jpg\" alt=\"simd\"/></figure>\n\n\n\n<p>The best example for SIMD is the graphics cards. These cards have hundreds of individual processing units. If we talk about computational difference between SISD and SIMD then for the adding arrays&nbsp;<strong>[5, 15, 20]</strong>&nbsp;and&nbsp;<strong>[15, 25, 10],</strong>&nbsp;SISD architecture would have to perform three different add operations. On the other hand, with the SIMD architecture, we can add then in a single add operation.</p>\n\n\n\n<h3>Advantages of SIMD</h3>\n\n\n\n<p>The advantages of SIMD architecture are as follows −</p>\n\n\n\n<ul><li>Same operation on multiple elements can be performed using one instruction only.</li><li>Throughput of the system can be increased by increasing the number of cores of the processor.</li><li>Processing speed is higher than SISD architecture.</li></ul>\n\n\n\n<h3>Disadvantages of SIMD</h3>\n\n\n\n<p>The disadvantages of SIMD architecture are as follows −</p>\n\n\n\n<ul><li>There is complex communication between numbers of cores of processor.</li><li>The cost is higher than SISD architecture.</li></ul>\n\n\n\n<h2>Multiple Instruction Single Data (MISD) stream</h2>\n\n\n\n<p>Systems with MISD stream have number of processing units performing different operations by executing different instructions on the same data set. Following is the architecture of MISD −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/misd.jpg\" alt=\"MISD\"/></figure>\n\n\n\n<p>The representatives of MISD architecture do not yet exist commercially.</p>\n\n\n\n<h2>Multiple Instruction Multiple Data (MIMD) stream</h2>\n\n\n\n<p>In the system using MIMD architecture, each processor in a multiprocessor system can execute different sets of instructions independently on the different set of data set in parallel. It is opposite to SIMD architecture in which single operation is executed on multiple data sets. Following is the architecture of MIMD −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/mimd.jpg\" alt=\"MIMD\"/></figure>\n\n\n\n<p>A normal multiprocessor uses the MIMD architecture. These architectures are basically used in a number of application areas such as computer-aided design/computer-aided manufacturing, simulation, modeling, communication switches, etc.</p>\n\n\n\n<h2>Memory architectures supporting concurrency</h2>\n\n\n\n<p>While working with the concepts like concurrency and parallelism, there is always a need to speed up the programs. One solution found by computer designers is to create shared-memory multi-computers, i.e., computers having single physical address space, which is accessed by all the cores that a processor is having. In this scenario, there can be a number of different styles of architecture but following are the three important architecture styles −</p>\n\n\n\n<h3>UMA (Uniform Memory Access)</h3>\n\n\n\n<p>In this model, all the processors share the physical memory uniformly. All the processors have equal access time to all the memory words. Each processor may have a private cache memory. The peripheral devices follow a set of rules.</p>\n\n\n\n<p>When all the processors have equal access to all the peripheral devices, the system is called a&nbsp;<strong>symmetric multiprocessor</strong>. When only one or a few processors can access the peripheral devices, the system is called an&nbsp;<strong>asymmetric multiprocessor</strong>.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/uma.jpg\" alt=\"UMA\"/></figure>\n\n\n\n<h3>Non-uniform Memory Access (NUMA)</h3>\n\n\n\n<p>In the NUMA multiprocessor model, the access time varies with the location of the memory word. Here, the shared memory is physically distributed among all the processors, called local memories. The collection of all local memories forms a global address space which can be accessed by all the processors.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/numa.jpg\" alt=\"NUMA\"/></figure>\n\n\n\n<h3>Cache Only Memory Architecture (COMA)</h3>\n\n\n\n<p>The COMA model is a specialized version of the NUMA model. Here, all the distributed main memories are converted to cache memories.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/coma.jpg\" alt=\"coma\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>There are different system and memory architecture styles that need to be considered while designing the program or concurrent system. It is very necessary because one system &amp; memory style may be suitable for one task but may be error prone to other task. Computer system architectures supporting concurrency Michael Flynn in 1972 gave taxonomy [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2755"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2755"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2755/revisions"}],"predecessor-version":[{"id":2997,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2755/revisions/2997"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2755"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2755"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2755"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2756,"date":"2020-07-08T09:54:47","date_gmt":"2020-07-08T09:54:47","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1682"},"modified":"2020-12-16T16:53:11","modified_gmt":"2020-12-16T16:53:11","slug":"threads","status":"publish","type":"post","link":"https://python3.foobrdigital.com/threads/","title":{"rendered":"Threads"},"content":{"rendered":"\n<p>In general, as we know that thread is a very thin twisted string usually of the cotton or silk fabric and used for sewing clothes and such. The same term thread is also used in the world of computer programming. Now, how do we relate the thread used for sewing clothes and the thread used for computer programming? The roles performed by the two threads is similar here. In clothes, thread hold the cloth together and on the other side, in computer programming, thread hold the computer program and allow the program to execute sequential actions or many actions at once.</p>\n\n\n\n<p><strong>Thread</strong>&nbsp;is the smallest unit of execution in an operating system. It is not in itself a program but runs within a program. In other words, threads are not independent of one other and share code section, data section, etc. with other threads. These threads are also known as lightweight processes.</p>\n\n\n\n<h2>States of Thread</h2>\n\n\n\n<p>To understand the functionality of threads in depth, we need to learn about the lifecycle of the threads or the different thread states. Typically, a thread can exist in five distinct states. The different states are shown below −</p>\n\n\n\n<h3>New Thread</h3>\n\n\n\n<p>A new thread begins its life cycle in the new state. However, at this stage, it has not yet started and it has not been allocated any resources. We can say that it is just an instance of an object.</p>\n\n\n\n<h3>Runnable</h3>\n\n\n\n<p>As the newly born thread is started, the thread becomes runnable i.e. waiting to run. In this state, it has all the resources but still task scheduler have not scheduled it to run.</p>\n\n\n\n<h3>Running</h3>\n\n\n\n<p>In this state, the thread makes progress and executes the task, which has been chosen by task scheduler to run. Now, the thread can go to either the dead state or the non-runnable/ waiting state.</p>\n\n\n\n<h3>Non-running/waiting</h3>\n\n\n\n<p>In this state, the thread is paused because it is either waiting for the response of some I/O request or waiting for the completion of the execution of other thread.</p>\n\n\n\n<h3>Dead</h3>\n\n\n\n<p>A runnable thread enters the terminated state when it completes its task or otherwise terminates.</p>\n\n\n\n<p>The following diagram shows the complete life cycle of a thread −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/dead.jpg\" alt=\"Dead\"/></figure>\n\n\n\n<h2>Types of Thread</h2>\n\n\n\n<p>In this section, we will see the different types of thread. The types are described below −</p>\n\n\n\n<h3>User Level Threads</h3>\n\n\n\n<p>These are user-managed threads.</p>\n\n\n\n<p>In this case, the thread management kernel is not aware of the existence of threads. The thread library contains code for creating and destroying threads, for passing message and data between threads, for scheduling thread execution and for saving and restoring thread contexts. The application starts with a single thread.</p>\n\n\n\n<p>The examples of user level threads are −</p>\n\n\n\n<ul><li>Java threads</li><li>POSIX threads</li></ul>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/user_level.jpg\" alt=\"Dead\"/></figure>\n\n\n\n<h3>Advantages of User level Threads</h3>\n\n\n\n<p>Following are the different advantages of user level threads −</p>\n\n\n\n<ul><li>Thread switching does not require Kernel mode privileges.</li><li>User level thread can run on any operating system.</li><li>Scheduling can be application specific in the user level thread.</li><li>User level threads are fast to create and manage.</li></ul>\n\n\n\n<h3>Disadvantages of User level Threads</h3>\n\n\n\n<p>Following are the different disadvantages of user level threads −</p>\n\n\n\n<ul><li>In a typical operating system, most system calls are blocking.</li><li>Multithreaded application cannot take advantage of multiprocessing.</li></ul>\n\n\n\n<h3>Kernel Level Threads</h3>\n\n\n\n<p>Operating System managed threads act on kernel, which is an operating system core.</p>\n\n\n\n<p>In this case, the Kernel does thread management. There is no thread management code in the application area. Kernel threads are supported directly by the operating system. Any application can be programmed to be multithreaded. All of the threads within an application are supported within a single process.</p>\n\n\n\n<p>The Kernel maintains context information for the process as a whole and for individual threads within the process. Scheduling by the Kernel is done on a thread basis. The Kernel performs thread creation, scheduling and management in Kernel space. Kernel threads are generally slower to create and manage than the user threads. The examples of kernel level threads are Windows, Solaris.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/kernal.jpg\" alt=\"Dead\"/></figure>\n\n\n\n<h3>Advantages of Kernel Level Threads</h3>\n\n\n\n<p>Following are the different advantages of kernel level threads −</p>\n\n\n\n<ul><li>Kernel can simultaneously schedule multiple threads from the same process on multiple processes.</li><li>If one thread in a process is blocked, the Kernel can schedule another thread of the same process.</li><li>Kernel routines themselves can be multithreaded.</li></ul>\n\n\n\n<h3>Disadvantages of Kernel Level Threads</h3>\n\n\n\n<ul><li>Kernel threads are generally slower to create and manage than the user threads.</li><li>Transfer of control from one thread to another within the same process requires a mode switch to the Kernel.</li></ul>\n\n\n\n<h2>Thread Control Block &#8211; TCB</h2>\n\n\n\n<p>Thread Control Block (TCB) may be defined as the data structure in the kernel of operating system that mainly contains information about thread. Thread-specific information stored in TCB would highlight some important information about each process.</p>\n\n\n\n<p>Consider the following points related to the threads contained in TCB −</p>\n\n\n\n<ul><li><strong>Thread identification</strong>&nbsp;− It is the unique thread id (tid) assigned to every new thread.</li><li><strong>Thread state</strong>&nbsp;− It contains the information related to the state (Running, Runnable, Non-Running, Dead) of the thread.</li><li><strong>Program Counter (PC)</strong>&nbsp;− It points to the current program instruction of the thread.</li><li><strong>Register set</strong>&nbsp;− It contains the thread’s register values assigned to them for computations.</li><li><strong>Stack Pointer</strong>&nbsp;− It points to the thread’s stack in the process. It contains the local variables under thread’s scope.</li><li><strong>Pointer to PCB</strong>&nbsp;− It contains the pointer to the process that created that thread.</li></ul>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/pcb.jpg\" alt=\"pcb\"/></figure>\n\n\n\n<h2>Relation between process &amp; thread</h2>\n\n\n\n<p>In multithreading, process and thread are two very closely related terms having the same goal to make computer able to do more than one thing at a time. A process can contain one or more threads but on the contrary, thread cannot contain a process. However, they both remain the two basic units of execution. A program, executing a series of instructions, initiates process and thread both.</p>\n\n\n\n<p>The following table shows the comparison between process and thread −</p>\n\n\n\n<figure class=\"wp-block-table\"><table><tbody><tr><th>Process</th><th>Thread</th></tr><tr><td>Process is heavy weight or resource intensive.</td><td>Thread is lightweight which takes fewer resources than a process.</td></tr><tr><td>Process switching needs interaction with operating system.</td><td>Thread switching does not need to interact with operating system.</td></tr><tr><td>In multiple processing environments, each process executes the same code but has its own memory and file resources.</td><td>All threads can share same set of open files, child processes.</td></tr><tr><td>If one process is blocked, then no other process can execute until the first process is unblocked.</td><td>While one thread is blocked and waiting, a second thread in the same task can run.</td></tr><tr><td>Multiple processes without using threads use more resources.</td><td>Multiple threaded processes use fewer resources.</td></tr><tr><td>In multiple processes, each process operates independently of the others.</td><td>One thread can read, write or change another thread&#8217;s data.</td></tr><tr><td>If there would be any change in the parent process then it does not affect the child processes.</td><td>If there would be any change in the main thread then it may affect the behavior of other threads of that process.</td></tr><tr><td>To communicate with sibling processes, processes must use inter-process communication.</td><td>Threads can directly communicate with other threads of that process.</td></tr></tbody></table></figure>\n\n\n\n<h2>Concept of Multithreading</h2>\n\n\n\n<p>As we have discussed earlier that Multithreading is the ability of a CPU to manage the use of operating system by executing multiple threads concurrently. The main idea of multithreading is to achieve parallelism by dividing a process into multiple threads. In a more simple way, we can say that multithreading is the way of achieving multitasking by using the concept of threads.</p>\n\n\n\n<p>The concept of multithreading can be understood with the help of the following example.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Suppose we are running a process. The process could be for opening MS word for writing something. In such process, one thread will be assigned to open MS word and another thread will be required to write. Now, suppose if we want to edit something then another thread will be required to do the editing task and so on.</p>\n\n\n\n<p>The following diagram helps us understand how multiple threads exist in memory −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/multithreading.jpg\" alt=\"Multithreading\"/></figure>\n\n\n\n<p>We can see in the above diagram that more than one thread can exist within one process where every thread contains its own register set and local variables. Other than that, all the threads in a process share global variables.</p>\n\n\n\n<h2>Pros of Multithreading</h2>\n\n\n\n<p>Let us now see a few advantages of multithreading. The advantages are as follows −</p>\n\n\n\n<ul><li><strong>Speed of communication</strong>&nbsp;− Multithreading improves the speed of computation because each core or processor handles separate threads concurrently.</li><li><strong>Program remains responsive</strong>&nbsp;− It allows a program to remain responsive because one thread waits for the input and another runs a GUI at the same time.</li><li><strong>Access to global variables</strong>&nbsp;− In multithreading, all the threads of a particular process can access the global variables and if there is any change in global variable then it is visible to other threads too.</li><li><strong>Utilization of resources</strong>&nbsp;− Running of several threads in each program makes better use of CPU and the idle time of CPU becomes less.</li><li><strong>Sharing of data</strong>&nbsp;− There is no requirement of extra space for each thread because threads within a program can share same data.</li></ul>\n\n\n\n<h2>Cons of Multithreading</h2>\n\n\n\n<p>Let us now see a few disadvantages of multithreading. The disadvantages are as follows −</p>\n\n\n\n<ul><li><strong>Not suitable for single processor system</strong>&nbsp;− Multithreading finds it difficult to achieve performance in terms of speed of computation on single processor system as compared with the performance on multi-processor system.</li><li><strong>Issue of security</strong>&nbsp;− As we know that all the threads within a program share same data, hence there is always an issue of security because any unknown thread can change the data.</li><li><strong>Increase in complexity</strong>&nbsp;− Multithreading can increase the complexity of the program and debugging becomes difficult.</li><li><strong>Lead to deadlock state</strong>&nbsp;− Multithreading can lead the program to potential risk of attaining the deadlock state.</li><li><strong>Synchronization required</strong>&nbsp;− Synchronization is required to avoid mutual exclusion. This leads to more memory and CPU utilization.</li></ul>\n","protected":false},"excerpt":{"rendered":"<p>In general, as we know that thread is a very thin twisted string usually of the cotton or silk fabric and used for sewing clothes and such. The same term thread is also used in the world of computer programming. Now, how do we relate the thread used for sewing clothes and the thread used [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2756"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2756"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2756/revisions"}],"predecessor-version":[{"id":2996,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2756/revisions/2996"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2756"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2756"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2756"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2757,"date":"2020-07-08T09:58:33","date_gmt":"2020-07-08T09:58:33","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1684"},"modified":"2020-12-16T16:53:11","modified_gmt":"2020-12-16T16:53:11","slug":"implementation-of-threads","status":"publish","type":"post","link":"https://python3.foobrdigital.com/implementation-of-threads/","title":{"rendered":"Implementation of Threads"},"content":{"rendered":"\n<p>In this chapter, we will learn how to implement threads in Python.</p>\n\n\n\n<h2>Python Module for Thread Implementation</h2>\n\n\n\n<p>Python threads are sometimes called lightweight processes because threads occupy much less memory than processes. Threads allow performing multiple tasks at once. In Python, we have the following two modules that implement threads in a program −</p>\n\n\n\n<ul><li><strong>&lt;_thread&gt;</strong>module</li><li><strong>&lt;threading&gt;</strong>module</li></ul>\n\n\n\n<p>The main difference between these two modules is that&nbsp;<strong>&lt;_thread&gt;</strong>&nbsp;module treats a thread as a function whereas, the&nbsp;<strong>&lt;threading&gt;</strong>&nbsp;module treats every thread as an object and implements it in an object oriented way. Moreover, the&nbsp;<strong>&lt;_thread&gt;</strong>module is effective in low level threading and has fewer capabilities than the&nbsp;<strong>&lt;threading&gt;</strong>&nbsp;module.</p>\n\n\n\n<h3>&lt;_thread&gt; module</h3>\n\n\n\n<p>In the earlier version of Python, we had the&nbsp;<strong>&lt;thread&gt;</strong>&nbsp;module but it has been considered as &#8220;deprecated&#8221; for quite a long time. Users have been encouraged to use the&nbsp;<strong>&lt;threading&gt;</strong>module instead. Therefore, in Python 3 the module &#8220;thread&#8221; is not available anymore. It has been renamed to &#8220;<strong>&lt;_thread&gt;</strong>&#8221; for backwards incompatibilities in Python3.</p>\n\n\n\n<p>To generate new thread with the help of the <strong>&lt;_thread></strong> module, we need to call the <strong>start_new_thread</strong> method of it. The working of this method can be understood with the help of following syntax −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>_thread.start_new_thread ( function, args&#91;, kwargs] )\n</code></pre>\n\n\n\n<p>Here −</p>\n\n\n\n<ul><li><strong>args</strong>&nbsp;is a tuple of arguments</li><li><strong>kwargs</strong>&nbsp;is an optional dictionary of keyword arguments</li></ul>\n\n\n\n<p>If we want to call function without passing an argument then we need to use an empty tuple of arguments in&nbsp;<strong>args</strong>.</p>\n\n\n\n<p>This method call returns immediately, the child thread starts, and calls function with the passed list, if any, of args. The thread terminates as and when the function returns.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is an example for generating new thread by using the <strong>&lt;_thread></strong> module. We are using the start_new_thread() method here.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import _thread\nimport time\n\ndef print_time( threadName, delay):\n   count = 0\n   while count &lt; 5:\n      time.sleep(delay)\n      count += 1\n      print (\"%s: %s\" % ( threadName, time.ctime(time.time()) ))\n\ntry:\n   _thread.start_new_thread( print_time, (\"Thread-1\", 2, ) )\n   _thread.start_new_thread( print_time, (\"Thread-2\", 4, ) )\nexcept:\n   print (\"Error: unable to start thread\")\nwhile 1:\n   pass</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<p>The following output will help us understand the generation of new threads bwith the help of the <strong>&lt;_thread></strong> module.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Thread-1: Mon Apr 23 10:03:33 2018\nThread-2: Mon Apr 23 10:03:35 2018\nThread-1: Mon Apr 23 10:03:35 2018\nThread-1: Mon Apr 23 10:03:37 2018\nThread-2: Mon Apr 23 10:03:39 2018\nThread-1: Mon Apr 23 10:03:39 2018\nThread-1: Mon Apr 23 10:03:41 2018\nThread-2: Mon Apr 23 10:03:43 2018\nThread-2: Mon Apr 23 10:03:47 2018\nThread-2: Mon Apr 23 10:03:51 2018</code></pre>\n\n\n\n<h3>&lt;threading&gt; module</h3>\n\n\n\n<p>The&nbsp;<strong>&lt;threading&gt;</strong>&nbsp;module implements in an object oriented way and treats every thread as an object. Therefore, it provides much more powerful, high-level support for threads than the &lt;_thread&gt; module. This module is included with Python 2.4.</p>\n\n\n\n<h2>Additional methods in the &lt;threading&gt; module</h2>\n\n\n\n<p>The&nbsp;<strong>&lt;threading&gt;</strong>&nbsp;module comprises all the methods of the&nbsp;<strong>&lt;_thread&gt;</strong>&nbsp;module but it provides additional methods as well. The additional methods are as follows −</p>\n\n\n\n<ul><li><strong>threading.activeCount()</strong>&nbsp;− This method returns the number of thread objects that are active</li><li><strong>threading.currentThread()</strong>&nbsp;− This method returns the number of thread objects in the caller&#8217;s thread control.</li><li><strong>threading.enumerate()</strong>&nbsp;− This method returns a list of all thread objects that are currently active.</li><li><strong>run()</strong>&nbsp;− The run() method is the entry point for a thread.</li><li><strong>start()</strong>&nbsp;− The start() method starts a thread by calling the run method.</li><li><strong>join([time])</strong>&nbsp;− The join() waits for threads to terminate.</li><li><strong>isAlive()</strong>&nbsp;− The isAlive() method checks whether a thread is still executing.</li><li><strong>getName()</strong>&nbsp;− The getName() method returns the name of a thread.</li><li><strong>setName()</strong>&nbsp;− The setName() method sets the name of a thread.</li></ul>\n\n\n\n<h2>How to create threads using the &lt;threading&gt; module?</h2>\n\n\n\n<p>In this section, we will learn how to create threads using the&nbsp;<strong>&lt;threading&gt;</strong>&nbsp;module. Follow these steps to create a new thread using the &lt;threading&gt; module −</p>\n\n\n\n<ul><li><strong>Step 1</strong>&nbsp;− In this step, we need to define a new subclass of the&nbsp;<strong>Thread</strong>&nbsp;class.</li><li><strong>Step 2</strong>&nbsp;− Then for adding additional arguments, we need to override the&nbsp;<strong>__init__(self [,args])</strong>&nbsp;method.</li><li><strong>Step 3</strong>&nbsp;− In this step, we need to override the run(self [,args]) method to implement what the thread should do when started.</li></ul>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Consider this example to learn how to generate a new thread by using the <strong>&lt;threading></strong>module.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\nimport time\nexitFlag = 0\n\nclass myThread (threading.Thread):\n   def __init__(self, threadID, name, counter):\n      threading.Thread.__init__(self)\n      self.threadID = threadID\n      self.name = name\n      self.counter = counter\n   def run(self):\n      print (\"Starting \" + self.name)\n      print_time(self.name, self.counter, 5)\n      print (\"Exiting \" + self.name)\ndef print_time(threadName, delay, counter):\n   while counter:\n      if exitFlag:\n         threadName.exit()\n      time.sleep(delay)\n      print (\"%s: %s\" % (threadName, time.ctime(time.time())))\n      counter -= 1\n\nthread1 = myThread(1, \"Thread-1\", 1)\nthread2 = myThread(2, \"Thread-2\", 2)\n\nthread1.start()\nthread2.start()\nthread1.join()\nthread2.join()\nprint (\"Exiting Main Thread\")\nStarting Thread-1\nStarting Thread-2</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<p>Now, consider the following output −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Thread-1: Mon Apr 23 10:52:09 2018\nThread-1: Mon Apr 23 10:52:10 2018\nThread-2: Mon Apr 23 10:52:10 2018\nThread-1: Mon Apr 23 10:52:11 2018\nThread-1: Mon Apr 23 10:52:12 2018\nThread-2: Mon Apr 23 10:52:12 2018\nThread-1: Mon Apr 23 10:52:13 2018\nExiting Thread-1\nThread-2: Mon Apr 23 10:52:14 2018\nThread-2: Mon Apr 23 10:52:16 2018\nThread-2: Mon Apr 23 10:52:18 2018\nExiting Thread-2\nExiting Main Thread</code></pre>\n\n\n\n<h2>Python Program for Various Thread States</h2>\n\n\n\n<p>There are five thread states &#8211; new, runnable, running, waiting and dead. Among these five Of these five, we will majorly focus on three states &#8211; running, waiting and dead. A thread gets its resources in the running state, waits for the resources in the waiting state; the final release of the resource, if executing and acquired is in the dead state.</p>\n\n\n\n<p>The following Python program with the help of start(), sleep() and join() methods will show how a thread entered in running, waiting and dead state respectively.</p>\n\n\n\n<p><strong>Step 1</strong> − Import the necessary modules, &lt;threading> and &lt;time></p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\nimport time</code></pre>\n\n\n\n<p><strong>Step 2</strong> − Define a function, which will be called while creating a thread.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def thread_states():\n   print(\"Thread entered in running state\")</code></pre>\n\n\n\n<p><strong>Step 3</strong> − We are using the sleep() method of time module to make our thread waiting for say 2 seconds.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>time.sleep(2)</code></pre>\n\n\n\n<p><strong>Step 4</strong> − Now, we are creating a thread named T1, which takes the argument of the function defined above.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>T1 = threading.Thread(target=thread_states)</code></pre>\n\n\n\n<p><strong>Step 5</strong> − Now, with the help of the start() function we can start our thread. It will produce the message, which has been set by us while defining the function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>T1.start()\nThread entered in running state</code></pre>\n\n\n\n<p><strong>Step 6</strong> − Now, at last we can kill the thread with the join() method after it finishes its execution.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>T1.join()</code></pre>\n\n\n\n<h2>Starting a thread in Python</h2>\n\n\n\n<p>In python, we can start a new thread by different ways but the easiest one among them is to define it as a single function. After defining the function, we can pass this as the target for a new <strong>threading.Thread</strong> object and so on. Execute the following Python code to understand how the function works −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\nimport time\nimport random\ndef Thread_execution(i):\n   print(\"Execution of Thread {} started\\n\".format(i))\n   sleepTime = random.randint(1,4)\n   time.sleep(sleepTime)\n   print(\"Execution of Thread {} finished\".format(i))\nfor i in range(4):\n   thread = threading.Thread(target=Thread_execution, args=(i,))\n   thread.start()\n   print(\"Active Threads:\" , threading.enumerate())</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Execution of Thread 0 started\nActive Threads:\n   &#91;&lt;_MainThread(MainThread, started 6040)>,\n      &lt;HistorySavingThread(IPythonHistorySavingThread, started 5968)>,\n      &lt;Thread(Thread-3576, started 3932)>]\n\nExecution of Thread 1 started\nActive Threads:\n   &#91;&lt;_MainThread(MainThread, started 6040)>,\n      &lt;HistorySavingThread(IPythonHistorySavingThread, started 5968)>,\n      &lt;Thread(Thread-3576, started 3932)>,\n      &lt;Thread(Thread-3577, started 3080)>]\n\nExecution of Thread 2 started\nActive Threads:\n   &#91;&lt;_MainThread(MainThread, started 6040)>,\n      &lt;HistorySavingThread(IPythonHistorySavingThread, started 5968)>,\n      &lt;Thread(Thread-3576, started 3932)>,\n      &lt;Thread(Thread-3577, started 3080)>,\n      &lt;Thread(Thread-3578, started 2268)>]\n\nExecution of Thread 3 started\nActive Threads:\n   &#91;&lt;_MainThread(MainThread, started 6040)>,\n      &lt;HistorySavingThread(IPythonHistorySavingThread, started 5968)>,\n      &lt;Thread(Thread-3576, started 3932)>,\n      &lt;Thread(Thread-3577, started 3080)>,\n      &lt;Thread(Thread-3578, started 2268)>,\n      &lt;Thread(Thread-3579, started 4520)>]\nExecution of Thread 0 finished\nExecution of Thread 1 finished\nExecution of Thread 2 finished\nExecution of Thread 3 finished</code></pre>\n\n\n\n<h2>Daemon threads in Python</h2>\n\n\n\n<p>Before implementing the daemon threads in Python, we need to know about daemon threads and their usage. In terms of computing, daemon is a background process that handles the requests for various services such as data sending, file transfers, etc. It would be dormant if it is not required any more. The same task can be done with the help of non-daemon threads also. However, in this case, the main thread has to keep track of the non-daemon threads manually. On the other hand, if we are using daemon threads then the main thread can completely forget about this and it will be killed when main thread exits. Another important point about daemon threads is that we can opt to use them only for non-essential tasks that would not affect us if it does not complete or gets killed in between. Following is the implementation of daemon threads in python −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\nimport time\n\ndef nondaemonThread():\n   print(\"starting my thread\")\n   time.sleep(8)\n   print(\"ending my thread\")\ndef daemonThread():\n   while True:\n   print(\"Hello\")\n   time.sleep(2)\nif __name__ == '__main__':\n   nondaemonThread = threading.Thread(target = nondaemonThread)\n   daemonThread = threading.Thread(target = daemonThread)\n   daemonThread.setDaemon(True)\n   daemonThread.start()\n   nondaemonThread.start()</code></pre>\n\n\n\n<p>In the above code, there are two functions namely <strong>>nondaemonThread()</strong> and <strong>>daemonThread()</strong>. The first function prints its state and sleeps after 8 seconds while the the deamonThread() function prints Hello after every 2 seconds indefinitely. We can understand the difference between nondaemon and daemon threads with the help of following output −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Hello\n\nstarting my thread\nHello\nHello\nHello\nHello\nending my thread\nHello\nHello\nHello\nHello\nHello</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, we will learn how to implement threads in Python. Python Module for Thread Implementation Python threads are sometimes called lightweight processes because threads occupy much less memory than processes. Threads allow performing multiple tasks at once. In Python, we have the following two modules that implement threads in a program − &lt;_thread&gt;module [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2757"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2757"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2757/revisions"}],"predecessor-version":[{"id":2995,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2757/revisions/2995"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2757"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2757"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2757"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2758,"date":"2020-07-08T10:03:53","date_gmt":"2020-07-08T10:03:53","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1686"},"modified":"2020-12-16T16:53:11","modified_gmt":"2020-12-16T16:53:11","slug":"synchronizing-threads","status":"publish","type":"post","link":"https://python3.foobrdigital.com/synchronizing-threads/","title":{"rendered":"Synchronizing Threads"},"content":{"rendered":"\n<p>Thread synchronization may be defined as a method with the help of which we can be assured that two or more concurrent threads are not simultaneously accessing the program segment known as critical section. On the other hand, as we know that critical section is the part of the program where the shared resource is accessed. Hence we can say that synchronization is the process of making sure that two or more threads do not interface with each other by accessing the resources at the same time. The diagram below shows that four threads trying to access the critical section of a program at the same time.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/synchronizing.jpg\" alt=\"Synchronizing\"/></figure>\n\n\n\n<p>To make it clearer, suppose two or more threads trying to add the object in the list at the same time. This act cannot lead to a successful end because either it will drop one or all the objects or it will completely corrupt the state of the list. Here the role of the synchronization is that only one thread at a time can access the list.</p>\n\n\n\n<h2>Issues in thread synchronization</h2>\n\n\n\n<p>We might encounter issues while implementing concurrent programming or applying synchronizing primitives. In this section, we will discuss two major issues. The issues are −</p>\n\n\n\n<ul><li>Deadlock</li><li>Race condition</li></ul>\n\n\n\n<h3>Race condition</h3>\n\n\n\n<p>This is one of the major issues in concurrent programming. Concurrent access to shared resources can lead to race condition. A race condition may be defined as the occurring of a condition when two or more threads can access shared data and then try to change its value at the same time. Due to this, the values of variables may be unpredictable and vary depending on the timings of context switches of the processes.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Consider this example to understand the concept of race condition −</p>\n\n\n\n<p><strong>Step 1</strong> − In this step, we need to import threading module −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading</code></pre>\n\n\n\n<p><strong>Step 2</strong> − Now, define a global variable, say x, along with its value as 0 −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x = 0</code></pre>\n\n\n\n<p><strong>Step 3</strong> − Now, we need to define the <strong>increment_global()</strong> function, which will do the increment by 1 in this global function x −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def increment_global():\n\n   global x\n   x += 1</code></pre>\n\n\n\n<p><strong>Step 4</strong> − In this step, we will define the <strong>taskofThread()</strong> function, which will call the increment_global() function for a specified number of times; for our example it is 50000 times −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def taskofThread():\n\n   for _ in range(50000):\n      increment_global()</code></pre>\n\n\n\n<p><strong>Step 5</strong> − Now, define the main() function in which threads t1 and t2 are created. Both will be started with the help of the start() function and wait until they finish their jobs with the help of join() function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def main():\n   global x\n   x = 0\n   \n   t1 = threading.Thread(target= taskofThread)\n   t2 = threading.Thread(target= taskofThread)\n\n   t1.start()\n   t2.start()\n\n   t1.join()\n   t2.join()</code></pre>\n\n\n\n<p><strong>Step 6</strong> − Now, we need to give the range as in for how many iterations we want to call the main() function. Here, we are calling it for 5 times.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>if __name__ == \"__main__\":\n   for i in range(5):\n      main()\n      print(\"x = {1} after Iteration {0}\".format(i,x))</code></pre>\n\n\n\n<p>In the output shown below, we can see the effect of race condition as the value of x after each iteration is expected 100000. However, there is lots of variation in the value. This is due to the concurrent access of threads to the shared global variable x.</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>x = 100000 after Iteration 0\nx = 54034 after Iteration 1\nx = 80230 after Iteration 2\nx = 93602 after Iteration 3\nx = 93289 after Iteration 4</code></pre>\n\n\n\n<h2>Dealing with race condition using locks</h2>\n\n\n\n<p>As we have seen the effect of race condition in the above program, we need a synchronization tool, which can deal with race condition between multiple threads. In Python, the&nbsp;<strong>&lt;threading&gt;</strong>&nbsp;module provides Lock class to deal with race condition. Further, the&nbsp;<strong>Lock</strong>&nbsp;class provides different methods with the help of which we can handle race condition between multiple threads. The methods are described below −</p>\n\n\n\n<h3>acquire() method</h3>\n\n\n\n<p>This method is used to acquire, i.e., blocking a lock. A lock can be blocking or non-blocking depending upon the following true or false value −</p>\n\n\n\n<ul><li><strong>With value set to True</strong>&nbsp;− If the acquire() method is invoked with True, which is the default argument, then the thread execution is blocked until the lock is unlocked.</li><li><strong>With value set to False</strong>&nbsp;− If the acquire() method is invoked with False, which is not the default argument, then the thread execution is not blocked until it is set to true, i.e., until it is locked.</li></ul>\n\n\n\n<h3>release() method</h3>\n\n\n\n<p>This method is used to release a lock. Following are a few important tasks related to this method −</p>\n\n\n\n<ul><li>If a lock is locked, then the&nbsp;<strong>release()</strong>&nbsp;method would unlock it. Its job is to allow exactly one thread to proceed if more than one threads are blocked and waiting for the lock to become unlocked.</li><li>It will raise a&nbsp;<strong>ThreadError</strong>&nbsp;if lock is already unlocked.</li></ul>\n\n\n\n<p>Now, we can rewrite the above program with the lock class and its methods to avoid the race condition. We need to define the taskofThread() method with lock argument and then need to use the acquire() and release() methods for blocking and non-blocking of locks to avoid race condition.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is example of python program to understand the concept of locks for dealing with race condition −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\n\nx = 0\n\ndef increment_global():\n\n   global x\n   x += 1\n\ndef taskofThread(lock):\n\n   for _ in range(50000):\n      lock.acquire()\n      increment_global()\n      lock.release()\n\ndef main():\n   global x\n   x = 0\n\n   lock = threading.Lock()\n   t1 = threading.Thread(target = taskofThread, args = (lock,))\n   t2 = threading.Thread(target = taskofThread, args = (lock,))\n\n   t1.start()\n   t2.start()\n\n   t1.join()\n   t2.join()\n\nif __name__ == \"__main__\":\n   for i in range(5):\n      main()\n      print(\"x = {1} after Iteration {0}\".format(i,x))</code></pre>\n\n\n\n<p>The following output shows that the effect of race condition is neglected; as the value of x, after each &amp; every iteration, is now 100000, which is as per the expectation of this program.</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>x = 100000 after Iteration 0\nx = 100000 after Iteration 1\nx = 100000 after Iteration 2\nx = 100000 after Iteration 3\nx = 100000 after Iteration 4</code></pre>\n\n\n\n<h2>Deadlocks − The Dining Philosophers problem</h2>\n\n\n\n<p>Deadlock is a troublesome issue one can face while designing the concurrent systems. We can illustrate this issue with the help of the dining philosopher problem as follows −</p>\n\n\n\n<p>Edsger Dijkstra originally introduced the dining philosopher problem, one of the famous illustrations of one of the biggest problem of concurrent system called deadlock.</p>\n\n\n\n<p>In this problem, there are five famous philosophers sitting at a round table eating some food from their bowls. There are five forks that can be used by the five philosophers to eat their food. However, the philosophers decide to use two forks at the same time to eat their food.</p>\n\n\n\n<p>Now, there are two main conditions for the philosophers. First, each of the philosophers can be either in eating or in thinking state and second, they must first obtain both the forks, i.e., left and right. The issue arises when each of the five philosophers manages to pick the left fork at the same time. Now they all are waiting for the right fork to be free but they will never relinquish their fork until they have eaten their food and the right fork would never be available. Hence, there would be a deadlock state at the dinner table.</p>\n\n\n\n<h3>Deadlock in concurrent system</h3>\n\n\n\n<p>Now if we see, the same issue can arise in our concurrent systems too. The forks in the above example would be the system resources and each philosopher can represent the process, which is competing to get the resources.</p>\n\n\n\n<h3>Solution with Python program</h3>\n\n\n\n<p>The solution of this problem can be found by splitting the philosophers into two types –&nbsp;<strong>greedy philosophers</strong>&nbsp;and&nbsp;<strong>generous philosophers</strong>. Mainly a greedy philosopher will try to pick up the left fork and wait until it is there. He will then wait for the right fork to be there, pick it up, eat and then put it down. On the other hand, a generous philosopher will try to pick up the left fork and if it is not there, he will wait and try again after some time. If they get the left fork then they will try to get the right one. If they will get the right fork too then they will eat and release both the forks. However, if they will not get the right fork then they will release the left fork.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following Python program will help us find a solution to the dining philosopher problem −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\nimport random\nimport time\n\nclass DiningPhilosopher(threading.Thread):\n\n   running = True\n\n   def __init__(self, xname, Leftfork, Rightfork):\n   threading.Thread.__init__(self)\n   self.name = xname\n   self.Leftfork = Leftfork\n   self.Rightfork = Rightfork\n\n   def run(self):\n   while(self.running):\n      time.sleep( random.uniform(3,13))\n      print ('%s is hungry.' % self.name)\n      self.dine()\n\n   def dine(self):\n   fork1, fork2 = self.Leftfork, self.Rightfork\n\n   while self.running:\n      fork1.acquire(True)\n      locked = fork2.acquire(False)\n\t  if locked: break\n      fork1.release()\n      print ('%s swaps forks' % self.name)\n      fork1, fork2 = fork2, fork1\n   else:\n      return\n\n   self.dining()\n   fork2.release()\n   fork1.release()\n\n   def dining(self):\n   print ('%s starts eating '% self.name)\n   time.sleep(random.uniform(1,10))\n   print ('%s finishes eating and now thinking.' % self.name)\n\ndef Dining_Philosophers():\n   forks = &#91;threading.Lock() for n in range(5)]\n   philosopherNames = ('1st','2nd','3rd','4th', '5th')\n\n   philosophers= &#91;DiningPhilosopher(philosopherNames&#91;i], forks&#91;i%5], forks&#91;(i+1)%5]) \\\n      for i in range(5)]\n\n   random.seed()\n   DiningPhilosopher.running = True\n   for p in philosophers: p.start()\n   time.sleep(30)\n   DiningPhilosopher.running = False\n   print (\" It is finishing.\")\n\nDining_Philosophers()</code></pre>\n\n\n\n<p>The above program uses the concept of greedy and generous philosophers. The program has also used the&nbsp;<strong>acquire()</strong>&nbsp;and&nbsp;<strong>release()</strong>&nbsp;methods of the&nbsp;<strong>Lock</strong>&nbsp;class of the&nbsp;<strong>&lt;threading&gt;</strong>module. We can see the solution in the following output −</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>4th is hungry.\n4th starts eating\n1st is hungry.\n1st starts eating\n2nd is hungry.\n5th is hungry.\n3rd is hungry.\n1st finishes eating and now thinking.3rd swaps forks\n2nd starts eating\n4th finishes eating and now thinking.\n3rd swaps forks5th starts eating\n5th finishes eating and now thinking.\n4th is hungry.\n4th starts eating\n2nd finishes eating and now thinking.\n3rd swaps forks\n1st is hungry.\n1st starts eating\n4th finishes eating and now thinking.\n3rd starts eating\n5th is hungry.\n5th swaps forks\n1st finishes eating and now thinking.\n5th starts eating\n2nd is hungry.\n2nd swaps forks\n4th is hungry.\n5th finishes eating and now thinking.\n3rd finishes eating and now thinking.\n2nd starts eating 4th starts eating\nIt is finishing.</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>Thread synchronization may be defined as a method with the help of which we can be assured that two or more concurrent threads are not simultaneously accessing the program segment known as critical section. On the other hand, as we know that critical section is the part of the program where the shared resource is [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2758"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2758"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2758/revisions"}],"predecessor-version":[{"id":2994,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2758/revisions/2994"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2758"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2758"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2758"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2759,"date":"2020-07-08T10:22:14","date_gmt":"2020-07-08T10:22:14","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1688"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"threads-intercommunication","status":"publish","type":"post","link":"https://python3.foobrdigital.com/threads-intercommunication/","title":{"rendered":"Threads Intercommunication"},"content":{"rendered":"\n<p>In real life, if a team of people is working on a common task then there should be communication between them for finishing the task properly. The same analogy is applicable to threads also. In programming, to reduce the ideal time of the processor we create multiple threads and assign different sub tasks to every thread. Hence, there must be a communication facility and they should interact with each other to finish the job in a synchronized manner.</p>\n\n\n\n<p>Consider the following important points related to thread intercommunication −</p>\n\n\n\n<ul><li><strong>No performance gain</strong>&nbsp;− If we cannot achieve proper communication between threads and processes then the performance gains from concurrency and parallelism is of no use.</li><li><strong>Accomplish task properly</strong>&nbsp;− Without proper intercommunication mechanism between threads, the assigned task cannot be completed properly.</li><li><strong>More efficient than inter-process communication</strong>&nbsp;− Inter-thread communication is more efficient and easy to use than inter-process communication because all threads within a process share same address space and they need not use shared memory.</li></ul>\n\n\n\n<h2>Python data structures for thread-safe communication</h2>\n\n\n\n<p>Multithreaded code comes up with a problem of passing information from one thread to another thread. The standard communication primitives do not solve this issue. Hence, we need to implement our own composite object in order to share objects between threads to make the communication thread-safe. Following are a few data structures, which provide thread-safe communication after making some changes in them −</p>\n\n\n\n<h3>Sets</h3>\n\n\n\n<p>For using set data structure in a thread-safe manner, we need to extend the set class to implement our own locking mechanism.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Here is a Python example of extending the class −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>class extend_class(set):\n   def __init__(self, *args, **kwargs):\n      self._lock = Lock()\n      super(extend_class, self).__init__(*args, **kwargs)\n\n   def add(self, elem):\n      self._lock.acquire()\n\t  try:\n      super(extend_class, self).add(elem)\n      finally:\n      self._lock.release()\n  \n   def delete(self, elem):\n      self._lock.acquire()\n      try:\n      super(extend_class, self).delete(elem)\n      finally:\n      self._lock.release()</code></pre>\n\n\n\n<p>In the above example, a class object named&nbsp;<strong>extend_class</strong>&nbsp;has been defined which is further inherited from the Python&nbsp;<strong>set class</strong>. A lock object is created within the constructor of this class. Now, there are two functions &#8211;&nbsp;<strong>add()</strong>&nbsp;and&nbsp;<strong>delete()</strong>. These functions are defined and are thread-safe. They both rely on the&nbsp;<strong>super</strong>&nbsp;class functionality with one key exception.</p>\n\n\n\n<h3>Decorator</h3>\n\n\n\n<p>This is another key method for thread-safe communication is the use of decorators.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Consider a Python example that shows how to use decorators &amp;mminus;</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def lock_decorator(method):\n\n   def new_deco_method(self, *args, **kwargs):\n      with self._lock:\n         return method(self, *args, **kwargs)\nreturn new_deco_method\n\nclass Decorator_class(set):\n   def __init__(self, *args, **kwargs):\n      self._lock = Lock()\n      super(Decorator_class, self).__init__(*args, **kwargs)\n\n   @lock_decorator\n   def add(self, *args, **kwargs):\n      return super(Decorator_class, self).add(elem)\n   @lock_decorator\n   def delete(self, *args, **kwargs):\n      return super(Decorator_class, self).delete(elem)</code></pre>\n\n\n\n<p>In the above example, a decorator method named lock_decorator has been defined which is further inherited from the Python method class. Then a lock object is created within the constructor of this class. Now, there are two functions &#8211; add() and delete(). These functions are defined and are thread-safe. They both rely on super class functionality with one key exception.</p>\n\n\n\n<h3>Lists</h3>\n\n\n\n<p>The list data structure is thread-safe, quick as well as easy structure for temporary, in-memory storage. In Cpython, the GIL protects against concurrent access to them. As we came to know that lists are thread-safe but what about the data lying in them. Actually, the list’s data is not protected. For example,&nbsp;<strong>L.append(x)</strong>&nbsp;is not guarantee to return the expected result if another thread is trying to do the same thing. This is because, although&nbsp;<strong>append()</strong>&nbsp;is an atomic operation and thread-safe but the other thread is trying to modify the list’s data in concurrent fashion hence we can see the side effects of race conditions on the output.</p>\n\n\n\n<p>To resolve this kind of issue and safely modify the data, we must implement a proper locking mechanism, which further ensures that multiple threads cannot potentially run into race conditions. To implement proper locking mechanism, we can extend the class as we did in the previous examples.</p>\n\n\n\n<p>Some other atomic operations on lists are as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>L.append(x)\nL1.extend(L2)\nx = L&#91;i]\nx = L.pop()\nL1&#91;i:j] = L2\nL.sort()\nx = y\nx.field = y\nD&#91;x] = y\nD1.update(D2)\nD.keys()</code></pre>\n\n\n\n<p>Here −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>L,L1,L2 all are lists\nD,D1,D2 are dicts\nx,y are objects\ni, j are ints</code></pre>\n\n\n\n<h3>Queues</h3>\n\n\n\n<p>If the list’s data is not protected, we might have to face the consequences. We may get or delete wrong data item, of race conditions. That is why it is recommended to use the queue data structure. A real-world example of queue can be a single-lane one-way road, where the vehicle enters first, exits first. More real-world examples can be seen of the queues at the ticket windows and bus-stops.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/queues.jpg\" alt=\"Queues\"/></figure>\n\n\n\n<p>Queues are by default, thread-safe data structure and we need not worry about implementing complex locking mechanism. Python provides us the&nbsp;module to use different types of queues in our application.</p>\n\n\n\n<h2>Types of Queues</h2>\n\n\n\n<p>In this section, we will earn about the different types of queues. Python provides three options of queues to use from the&nbsp;<strong>&lt;queue&gt;</strong>&nbsp;module −</p>\n\n\n\n<ul><li>Normal Queues (FIFO, First in First out)</li><li>LIFO, Last in First Out</li><li>Priority</li></ul>\n\n\n\n<p>We will learn about the different queues in the subsequent sections.</p>\n\n\n\n<h2>Normal Queues (FIFO, First in First out)</h2>\n\n\n\n<p>It is most commonly used queue implementations offered by Python. In this queuing mechanism whosoever will come first, will get the service first. FIFO is also called normal queues. FIFO queues can be represented as follows −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/fifo.jpg\" alt=\"FIFO\"/></figure>\n\n\n\n<h3>Python Implementation of FIFO Queue</h3>\n\n\n\n<p>In python, FIFO queue can be implemented with single thread as well as multithreads.</p>\n\n\n\n<h3>FIFO queue with single thread</h3>\n\n\n\n<p>For implementing FIFO queue with single thread, the&nbsp;<strong>Queue</strong>&nbsp;class will implement a basic first-in, first-out container. Elements will be added to one “end” of the sequence using&nbsp;<strong>put()</strong>, and removed from the other end using&nbsp;<strong>get()</strong>.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is a Python program for implementation of FIFO queue with single thread −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import queue\n\nq = queue.Queue()\n\nfor i in range(8):\n   q.put(\"item-\" + str(i))\n\nwhile not q.empty():\n   print (q.get(), end = \" \")</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>item-0 item-1 item-2 item-3 item-4 item-5 item-6 item-7\n</code></pre>\n\n\n\n<p>The output shows that above program uses a single thread to illustrate that the elements are removed from the queue in the same order they are inserted.</p>\n\n\n\n<h3>FIFO queue with multiple threads</h3>\n\n\n\n<p>For implementing FIFO with multiple threads, we need to define the myqueue() function, which is extended from the queue module. The working of get() and put() methods are same as discussed above while implementing FIFO queue with single thread. Then to make it multithreaded, we need to declare and instantiate the threads. These threads will consume the queue in FIFO manner.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is a Python program for implementation of FIFO queue with multiple threads.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\nimport queue\nimport random\nimport time\ndef myqueue(queue):\n   while not queue.empty():\n   item = queue.get()\n   if item is None:\n   break\n   print(\"{} removed {} from the queue\".format(threading.current_thread(), item))\n   queue.task_done()\n   time.sleep(2)\nq = queue.Queue()\nfor i in range(5):\n   q.put(i)\nthreads = &#91;]\nfor i in range(4):\n   thread = threading.Thread(target=myqueue, args=(q,))\n   thread.start()\n   threads.append(thread)\nfor thread in threads:\n   thread.join()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>&lt;Thread(Thread-3654, started 5044)> removed 0 from the queue\n&lt;Thread(Thread-3655, started 3144)> removed 1 from the queue\n&lt;Thread(Thread-3656, started 6996)> removed 2 from the queue\n&lt;Thread(Thread-3657, started 2672)> removed 3 from the queue\n&lt;Thread(Thread-3654, started 5044)> removed 4 from the queue</code></pre>\n\n\n\n<h2>LIFO, Last in First Out queue</h2>\n\n\n\n<p>This queue uses totally opposite analogy than FIFO(First in First Out) queues. In this queuing mechanism, the one who comes last, will get the service first. This is similar to implement stack data structure. LIFO queues prove useful while implementing Depth-first search like algorithms of artificial intelligence.</p>\n\n\n\n<h3>Python implementation of LIFO queue</h3>\n\n\n\n<p>In python, LIFO queue can be implemented with single thread as well as multithreads.</p>\n\n\n\n<h3>LIFO queue with single thread</h3>\n\n\n\n<p>For implementing LIFO queue with single thread, the&nbsp;<strong>Queue</strong>&nbsp;class will implement a basic last-in, first-out container by using the structure&nbsp;<strong>Queue</strong>.LifoQueue. Now, on calling&nbsp;<strong>put()</strong>, the elements are added in the head of the container and removed from the head also on using&nbsp;<strong>get()</strong>.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is a Python program for implementation of the LIFO queue with single thread −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import queue\n\nq = queue.LifoQueue()\n\nfor i in range(8):\n   q.put(\"item-\" + str(i))\n\nwhile not q.empty():\n   print (q.get(), end=\" \")\nOutput:\nitem-7 item-6 item-5 item-4 item-3 item-2 item-1 item-0</code></pre>\n\n\n\n<p>The output shows that the above program uses a single thread to illustrate that elements are removed from the queue in the opposite order they are inserted.</p>\n\n\n\n<h3>LIFO queue with multiple threads</h3>\n\n\n\n<p>The implementation is similar as we have done the implementation of FIFO queues with multiple threads. The only difference is that we need to use the&nbsp;<strong>Queue</strong>&nbsp;class that will implement a basic last-in, first-out container by using the structure&nbsp;<strong>Queue.LifoQueue</strong>.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is a Python program for implementation of LIFO queue with multiple threads −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\nimport queue\nimport random\nimport time\ndef myqueue(queue):\n   while not queue.empty():\n      item = queue.get()\n      if item is None:\n      break\n\t  print(\"{} removed {} from the queue\".format(threading.current_thread(), item))\n      queue.task_done()\n      time.sleep(2)\nq = queue.LifoQueue()\nfor i in range(5):\n   q.put(i)\nthreads = &#91;]\nfor i in range(4):\n   thread = threading.Thread(target=myqueue, args=(q,))\n   thread.start()\n   threads.append(thread)\nfor thread in threads:\n   thread.join() </code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>&lt;Thread(Thread-3882, started 4928)> removed 4 from the queue\n&lt;Thread(Thread-3883, started 4364)> removed 3 from the queue\n&lt;Thread(Thread-3884, started 6908)> removed 2 from the queue\n&lt;Thread(Thread-3885, started 3584)> removed 1 from the queue\n&lt;Thread(Thread-3882, started 4928)> removed 0 from the queue</code></pre>\n\n\n\n<h3>Priority queue</h3>\n\n\n\n<p>In FIFO and LIFO queues, the order of items are related to the order of insertion. However, there are many cases when the priority is more important than the order of insertion. Let us consider a real world example. Suppose the security at the airport is checking people of different categories. People of the VVIP, airline staff, custom officer, categories may be checked on priority instead of being checked on the basis of arrival like it is for the commoners.</p>\n\n\n\n<p>Another important aspect that needs to be considered for priority queue is how to develop a task scheduler. One common design is to serve the most agent task on priority basis in the queue. This data structure can be used to pick up the items from the queue based on their priority value.</p>\n\n\n\n<h3>Python Implementation of Priority Queue</h3>\n\n\n\n<p>In python, priority queue can be implemented with single thread as well as multithreads.</p>\n\n\n\n<h3>Priority queue with single thread</h3>\n\n\n\n<p>For implementing priority queue with single thread, the&nbsp;<strong>Queue</strong>&nbsp;class will implement a task on priority container by using the structure&nbsp;<strong>Queue</strong>.PriorityQueue. Now, on calling&nbsp;<strong>put()</strong>, the elements are added with a value where the lowest value will have the highest priority and hence retrieved first by using&nbsp;<strong>get()</strong>.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Consider the following Python program for implementation of Priority queue with single thread −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import queue as Q\np_queue = Q.PriorityQueue()\n\np_queue.put((2, 'Urgent'))\np_queue.put((1, 'Most Urgent'))\np_queue.put((10, 'Nothing important'))\nprio_queue.put((5, 'Important'))\n\nwhile not p_queue.empty():\n   item = p_queue.get()\n   print('%s - %s' % item)</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<p>In the above output, we can see that the queue has stored the items based on priority – less value is having high priority.</p>\n\n\n\n<h3>Priority queue with multi threads</h3>\n\n\n\n<p>The implementation is similar to the implementation of FIFO and LIFO queues with multiple threads. The only difference is that we need to use the&nbsp;<strong>Queue</strong>&nbsp;class for initializing the priority by using the structure&nbsp;<strong>Queue.PriorityQueue</strong>. Another difference is with the way the queue would be generated. In the example given below, it will be generated with two identical data sets.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following Python program helps in the implementation of priority queue with multiple threads −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import threading\nimport queue\nimport random\nimport time\ndef myqueue(queue):\n   while not queue.empty():\n      item = queue.get()\n      if item is None:\n      break\n      print(\"{} removed {} from the queue\".format(threading.current_thread(), item))\n      queue.task_done()\n      time.sleep(1)\nq = queue.PriorityQueue()\nfor i in range(5):\n   q.put(i,1)\n\nfor i in range(5):\n   q.put(i,1)\n\nthreads = &#91;]\nfor i in range(2):\n   thread = threading.Thread(target=myqueue, args=(q,))\n   thread.start()\n   threads.append(thread)\nfor thread in threads:\n   thread.join()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>&lt;Thread(Thread-4939, started 2420)> removed 0 from the queue\n&lt;Thread(Thread-4940, started 3284)> removed 0 from the queue\n&lt;Thread(Thread-4939, started 2420)> removed 1 from the queue\n&lt;Thread(Thread-4940, started 3284)> removed 1 from the queue\n&lt;Thread(Thread-4939, started 2420)> removed 2 from the queue\n&lt;Thread(Thread-4940, started 3284)> removed 2 from the queue\n&lt;Thread(Thread-4939, started 2420)> removed 3 from the queue\n&lt;Thread(Thread-4940, started 3284)> removed 3 from the queue\n&lt;Thread(Thread-4939, started 2420)> removed 4 from the queue\n&lt;Thread(Thread-4940, started 3284)> removed 4 from the queue</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>In real life, if a team of people is working on a common task then there should be communication between them for finishing the task properly. The same analogy is applicable to threads also. In programming, to reduce the ideal time of the processor we create multiple threads and assign different sub tasks to every [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2759"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2759"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2759/revisions"}],"predecessor-version":[{"id":2993,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2759/revisions/2993"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2759"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2759"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2759"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2760,"date":"2020-07-08T10:29:47","date_gmt":"2020-07-08T10:29:47","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1690"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"testing-thread-applications","status":"publish","type":"post","link":"https://python3.foobrdigital.com/testing-thread-applications/","title":{"rendered":"Testing Thread Applications"},"content":{"rendered":"\n<p>In this chapter, we will learn about testing of thread applications. We will also learn the importance of testing.</p>\n\n\n\n<h2>Why to Test?</h2>\n\n\n\n<p>Before we dive into the discussion about the importance of testing, we need to know what is testing. In general terms, testing is a technique of finding out how well something is working. On the other hand, specifically if we talk about computer programs or software then testing is the technique of accessing the functionality of a software program.</p>\n\n\n\n<p>In this section, we will discuss the importance of software testing. In software development, there must be double-checking before the releasing of software to the client. That is why it is very important to test the software by experienced testing team. Consider the following points to understand the importance of software testing −</p>\n\n\n\n<h3>Improvement of software quality</h3>\n\n\n\n<p>Certainly, no company wants to deliver low quality software and no client wants to buy low quality software. Testing improves the quality of software by finding and fixing the bugs in that.</p>\n\n\n\n<h3>Satisfaction of customers</h3>\n\n\n\n<p>The most important part of any business is the satisfaction of their customers. By providing bug free and good quality software, the companies can achieve customer satisfaction.</p>\n\n\n\n<h3>Lessen the impact of new features</h3>\n\n\n\n<p>Suppose we have made a software system of 10000 lines and we need to add a new feature then the development team would have the concern about the impact of this new feature on whole software. Here, also, testing plays a vital role because if the testing team has made a good suite of tests then it can save us from any potential catastrophic breaks.</p>\n\n\n\n<h3>User experience</h3>\n\n\n\n<p>Another most important part of any business is the experience of the users of that product. Only testing can assure that the end user finds it simple and easy to use the product.</p>\n\n\n\n<h3>Cutting down the expenses</h3>\n\n\n\n<p>Testing can cut down the total cost of software by finding and fixing the bugs in testing phase of its development rather than fixing it after delivery. If there is a major bug after the delivery of the software then it would increase its tangible cost say in terms of expenses and intangible cost say in terms of customer dissatisfaction, company’s negative reputation etc.</p>\n\n\n\n<h2>What to Test?</h2>\n\n\n\n<p>It is always recommended to have appropriate knowledge of what is to be tested. In this section, we will first understand be the prime motive of tester while testing any software. Code coverage, i.e., how many lines of code our test suite hits, while testing, should be avoided. It is because, while testing, focusing only on the number of lines of codes adds no real value to our system. There may remain some bugs, which reflect later at a later stage even after deployment.</p>\n\n\n\n<p>Consider the following important points related to what to test −</p>\n\n\n\n<ul><li>We need to focus on testing the functionality of the code rather than the code coverage.</li><li>We need to test the most important parts of the code first and then move towards the less important parts of the code. It will definitely save time.</li><li>The tester must have multitude different tests that can push the software up to its limits.</li></ul>\n\n\n\n<h2>Approaches for testing concurrent software programs</h2>\n\n\n\n<p>Due to the capability of utilizing the true capability of multi-core architecture, concurrent software systems are replacing sequential systems. In recent times, concurrent system programs are being used in everything from mobile phones to washing machines, from cars to airplanes, etc. We need to be more careful about testing the concurrent software programs because if we have added multiple threads to single thread application having already a bug, then we would end up with multiple bugs.</p>\n\n\n\n<p>Testing techniques for concurrent software programs are extensively focusing on selecting interleaving that expose potentially harmful patterns like race conditions, deadlocks and violation of atomicity. Following are two approaches for testing concurrent software programs −</p>\n\n\n\n<h3>Systematic exploration</h3>\n\n\n\n<p>This approach aims to explore the space of the interleavings as broadly as possible. Such approaches can adopt a brute-force technique and others adopt partial order reduction technique or heuristic technique to explore the space of interleavings.</p>\n\n\n\n<h3>Property-driven</h3>\n\n\n\n<p>Property-driven approaches rely on the observation that concurrency faults are more likely to occur under interleavings that expose specific properties such as suspicious memory access pattern. Different property-driven approaches target different faults like race conditions, deadlocks and violation of atomicity, which further depends on one or other specific properties.</p>\n\n\n\n<h2>Testing Strategies</h2>\n\n\n\n<p>Test Strategy is also known as test approach. The strategy defines how testing would be carried out. Test approach has two techniques −</p>\n\n\n\n<h3>Proactive</h3>\n\n\n\n<p>An approach in which the test design process is initiated as early as possible in order to find and fix the defects before the build is created.</p>\n\n\n\n<h3>Reactive</h3>\n\n\n\n<p>An approach in which the testing does not start until the completion of the development process.</p>\n\n\n\n<p>Before applying any test strategy or approach on python program, we must have a basic idea about the kind of errors a software program may have. The errors are as follows −</p>\n\n\n\n<h3>Syntactical errors</h3>\n\n\n\n<p>During program development, there can be many small errors. The errors are mostly due to typing mistakes. For example, missing colon or a wrong spelling of a keyword, etc. Such errors are due to the mistake in program syntax and not in logic. Hence, these errors are called syntactical errors.</p>\n\n\n\n<h3>Semantic errors</h3>\n\n\n\n<p>The semantic errors are also called logical errors. If there is a logical or semantic error in software program then the statement will compile and run correctly but it will not give the desired output because the logic is not correct.</p>\n\n\n\n<h2>Unit Testing</h2>\n\n\n\n<p>This is one of the most used testing strategies for testing python programs. This strategy is used for testing units or components of the code. By units or components, we mean classes or functions of the code. Unit testing simplifies the testing of large programming systems by testing “small” units. With the help of the above concept, unit testing may be defined as a method where individual units of source code are tested to determine if they return the desired output.</p>\n\n\n\n<p>In our subsequent sections, we will learn about the different Python modules for unit testing.</p>\n\n\n\n<h2>unittest module</h2>\n\n\n\n<p>The very first module for unit testing is the unittest module. It is inspired by JUnit and by default included in Python3.6. It supports test automation, sharing of setup and shutdown code for tests, aggregation of tests into collections, and independence of the tests from the reporting framework.</p>\n\n\n\n<p>Following are a few important concepts supported by the unittest module</p>\n\n\n\n<h3>Text fixture</h3>\n\n\n\n<p>It is used to set up a test so that it can be run before starting the test and tear down after the finish of test. It may involve creation of temporary database, directories, etc. needed before starting the test.</p>\n\n\n\n<h3>Test case</h3>\n\n\n\n<p>The test case checks whether a required response is coming from the specific set of inputs or not. The unittest module includes a base class named TestCase which can be used to create new test cases. It includes two by default methods −</p>\n\n\n\n<ul><li><strong>setUp()</strong>&nbsp;− a hook method for setting up the test fixture before exercising it. This is called before calling the implemented test methods.</li><li><strong>tearDown(</strong>&nbsp;− a hook method for deconstructing the class fixture after running all tests in the class.</li></ul>\n\n\n\n<h3>Test suite</h3>\n\n\n\n<p>It is a collection of test suites, test cases or both.</p>\n\n\n\n<h3>Test runner</h3>\n\n\n\n<p>It controls the running of the test cases or suits and provides the outcome to the user. It may use GUI or simple text interface for providing the outcome.</p>\n\n\n\n<p><strong>Example</strong></p>\n\n\n\n<p>The following Python program uses the unittest module to test a module named <strong>Fibonacci</strong>. The program helps in calculating the Fibonacci series of a number. In this example, we have created a class named Fibo_test, to define the test cases by using different methods. These methods are inherited from unittest.TestCase. We are using two by default methods – setUp() and tearDown(). We also define the testfibocal method. The name of the test must be started with the letter test. In the final block, unittest.main() provides a command-line interface to the test script.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import unittest\ndef fibonacci(n):\n   a, b = 0, 1\n   for i in range(n):\n   a, b = b, a + b\n   return a\nclass Fibo_Test(unittest.TestCase):\n   def setUp(self):\n   print(\"This is run before our tests would be executed\")\n   def tearDown(self):\n   print(\"This is run after the completion of execution of our tests\")\n\n   def testfibocal(self):\n   self.assertEqual(fib(0), 0)\n   self.assertEqual(fib(1), 1)\n   self.assertEqual(fib(5), 5)\n   self.assertEqual(fib(10), 55)\n   self.assertEqual(fib(20), 6765)\n\nif __name__ == \"__main__\":\n   unittest.main()</code></pre>\n\n\n\n<p>When run from the command line, the above script produces an output that looks like this −</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>This runs before our tests would be executed.\nThis runs after the completion of execution of our tests.\n.\n----------------------------------------------------------------------\nRan 1 test in 0.006s\nOK</code></pre>\n\n\n\n<p>Now, to make it clearer, we are changing our code which helped in defining the Fibonacci module.</p>\n\n\n\n<p>Consider the following code block as an example −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def fibonacci(n):\n   a, b = 0, 1\n   for i in range(n):\n   a, b = b, a + b\n   return a</code></pre>\n\n\n\n<p>A few changes to the code block are made as shown below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def fibonacci(n):\n   a, b = 1, 1\n   for i in range(n):\n   a, b = b, a + b\n   return a</code></pre>\n\n\n\n<p>Now, after running the script with the changed code, we will get the following output −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>This runs before our tests would be executed.\nThis runs after the completion of execution of our tests.\nF\n======================================================================\nFAIL: testCalculation (__main__.Fibo_Test)\n----------------------------------------------------------------------\nTraceback (most recent call last):\nFile \"unitg.py\", line 15, in testCalculation\nself.assertEqual(fib(0), 0)\nAssertionError: 1 != 0\n----------------------------------------------------------------------\nRan 1 test in 0.007s\n\nFAILED (failures = 1)</code></pre>\n\n\n\n<p>The above output shows that the module has failed to give the desired output.</p>\n\n\n\n<h2>Docktest module</h2>\n\n\n\n<p>The docktest module also helps in unit testing. It also comes prepackaged with python. It is easier to use than the unittest module. The unittest module is more suitable for complex tests. For using the doctest module, we need to import it. The docstring of the corresponding function must have interactive python session along with their outputs.</p>\n\n\n\n<p>If everything is fine in our code then there will be no output from the docktest module; otherwise, it will provide the output.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following Python example uses the docktest module to test a module named Fibonacci , which helps in calculating the Fibonacci series of a number.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import doctest\ndef fibonacci(n):\n   \"\"\"\n   Calculates the Fibonacci number\n\n   >>> fibonacci(0)\n   0\n   >>> fibonacci(1)\n   1\n   >>> fibonacci(10)\n   55\n   >>> fibonacci(20)\n   6765\n   >>>\n\n   \"\"\"\n   a, b = 1, 1\n   for i in range(n):\n   a, b = b, a + b\n   return a\n      if __name__ == \"__main__\":\n   doctest.testmod()</code></pre>\n\n\n\n<p>We can see that the docstring of the corresponding function named fib had interactive python session along with the outputs. If our code is fine then there would be no output from the doctest module. But to see how it works we can run it with the –v option.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>(base) D:\\ProgramData>python dock_test.py -v\nTrying:\n   fibonacci(0)\nExpecting:\n   0\nok\nTrying:\n   fibonacci(1)\nExpecting:\n   1\nok\nTrying:\n   fibonacci(10)\nExpecting:\n   55\nok\nTrying:\n   fibonacci(20)\nExpecting:\n   6765\nok\n1 items had no tests:\n   __main__\n1 items passed all tests:\n4 tests in __main__.fibonacci\n4 tests in 2 items.\n4 passed and 0 failed.\nTest passed.</code></pre>\n\n\n\n<p>Now, we will change the code that helped in defining the Fibonacci module</p>\n\n\n\n<p>Consider the following code block as an example −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def fibonacci(n):\n   a, b = 0, 1\n   for i in range(n):\n   a, b = b, a + b\n   return a</code></pre>\n\n\n\n<p>The following code block helps with the changes −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def fibonacci(n):\n   a, b = 1, 1\n   for i in range(n):\n   a, b = b, a + b\n   return a</code></pre>\n\n\n\n<p>After running the script even without the –v option, with the changed code, we will get the output as shown below.</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>(base) D:\\ProgramData>python dock_test.py\n**********************************************************************\nFile \"unitg.py\", line 6, in __main__.fibonacci\nFailed example:\n   fibonacci(0)\nExpected:\n   0\nGot:\n   1\n**********************************************************************\nFile \"unitg.py\", line 10, in __main__.fibonacci\nFailed example:\n   fibonacci(10)\nExpected:\n   55\nGot:\n   89\n**********************************************************************\nFile \"unitg.py\", line 12, in __main__.fibonacci\nFailed example:\n   fibonacci(20)\nExpected:\n   6765\nGot:\n   10946\n**********************************************************************\n1 items had failures:\n   3 of 4 in __main__.fibonacci\n***Test Failed*** 3 failures.</code></pre>\n\n\n\n<p>We can see in the above output that three tests have failed.</p>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, we will learn about testing of thread applications. We will also learn the importance of testing. Why to Test? Before we dive into the discussion about the importance of testing, we need to know what is testing. In general terms, testing is a technique of finding out how well something is working. [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2760"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2760"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2760/revisions"}],"predecessor-version":[{"id":2992,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2760/revisions/2992"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2760"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2760"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2760"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2761,"date":"2020-07-08T10:32:12","date_gmt":"2020-07-08T10:32:12","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1692"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"debugging-thread-applications","status":"publish","type":"post","link":"https://python3.foobrdigital.com/debugging-thread-applications/","title":{"rendered":"Debugging Thread Applications"},"content":{"rendered":"\n<p>In this chapter, we will learn how to debug thread applications. We will also learn the importance of debugging.</p>\n\n\n\n<h2>What is Debugging?</h2>\n\n\n\n<p>In computer programming, debugging is the process of finding and removing the bugs, errors and abnormalities from computer program. This process starts as soon as the code is written and continues in successive stages as code is combined with other units of programming to form a software product. Debugging is part of the software testing process and is an integral part of the entire software development life cycle.</p>\n\n\n\n<h2>Python Debugger</h2>\n\n\n\n<p>The Python debugger or the&nbsp;<strong>pdb</strong>&nbsp;is part of the Python standard library. It is a good fallback tool for tracking down hard-to-find bugs and allows us to fix faulty code quickly and reliably. Followings are the two most important tasks of the&nbsp;<strong>pdp</strong>&nbsp;debugger −</p>\n\n\n\n<ul><li>It allows us to check the values of variables at runtime.</li><li>We can step through the code and set breakpoints also.</li></ul>\n\n\n\n<p>We can work with pdb in the following two ways −</p>\n\n\n\n<ul><li>Through the command-line; this is also called postmortem debugging.</li><li>By interactively running pdb.</li></ul>\n\n\n\n<h3>Working with pdb</h3>\n\n\n\n<p>For working with the Python debugger, we need to use the following code at the location where we want to break into the debugger −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import pdb;\npdb.set_trace()</code></pre>\n\n\n\n<p>Consider the following commands to work with pdb through command-line.</p>\n\n\n\n<ul><li>h(help)</li><li>d(down)</li><li>u(up)</li><li>b(break)</li><li>cl(clear)</li><li>l(list))</li><li>n(next))</li><li>c(continue)</li><li>s(step)</li><li>r(return))</li><li>b(break)</li></ul>\n\n\n\n<p>Following is a demo of the h(help) command of the Python debugger −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import pdb\n\npdb.set_trace()\n--Call--\n>d:\\programdata\\lib\\site-packages\\ipython\\core\\displayhook.py(247)__call__()\n-> def __call__(self, result = None):\n(Pdb) h\n\nDocumented commands (type help &lt;topic>):\n========================================\nEOF   c         d       h        list     q       rv      undisplay\na     cl        debug   help     ll       quit    s       unt\nalias clear     disable ignore   longlist r       source  until\nargs  commands  display interact n        restart step    up\nb     condition down    j        next     return  tbreak  w\nbreak cont      enable  jump     p        retval  u       whatis\nbt    continue  exit    l        pp       run     unalias where\n\nMiscellaneous help topics:\n==========================\nexec pdb</code></pre>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>While working with Python debugger, we can set the breakpoint anywhere in the script by using the following lines −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import pdb;\npdb.set_trace()</code></pre>\n\n\n\n<p>After setting the breakpoint, we can run the script normally. The script will execute until a certain point; until where a line has been set. Consider the following example where we will run the script by using the above-mentioned lines at various places in the script −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import pdb;\na = \"aaa\"\npdb.set_trace()\nb = \"bbb\"\nc = \"ccc\"\nfinal = a + b + c\nprint (final)</code></pre>\n\n\n\n<p>When the above script is run, it will execute the program till a = “aaa”, we can check this in the following output.</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>--Return--\n> &lt;ipython-input-7-8a7d1b5cc854>(3)&lt;module>()->None\n-> pdb.set_trace()\n(Pdb) p a\n'aaa'\n(Pdb) p b\n*** NameError: name 'b' is not defined\n(Pdb) p c\n*** NameError: name 'c' is not defined</code></pre>\n\n\n\n<p>After using the command ‘p(print)’ in pdb, this script is only printing ‘aaa’. This is followed by an error because we have set the breakpoint till a = &#8220;aaa&#8221;.</p>\n\n\n\n<p>Similarly, we can run the script by changing the breakpoints and see the difference in the output −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import pdb\na = \"aaa\"\nb = \"bbb\"\nc = \"ccc\"\npdb.set_trace()\nfinal = a + b + c\nprint (final)</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>--Return--\n> &lt;ipython-input-9-a59ef5caf723>(5)&lt;module>()->None\n-> pdb.set_trace()\n(Pdb) p a\n'aaa'\n(Pdb) p b\n'bbb'\n(Pdb) p c\n'ccc'\n(Pdb) p final\n*** NameError: name 'final' is not defined\n(Pdb) exit</code></pre>\n\n\n\n<p>In the following script, we are setting the breakpoint in the last line of the program −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import pdb\na = \"aaa\"\nb = \"bbb\"\nc = \"ccc\"\nfinal = a + b + c\npdb.set_trace()\nprint (final)</code></pre>\n\n\n\n<p>The output is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>--Return--\n> &lt;ipython-input-11-8019b029997d>(6)&lt;module>()->None\n-> pdb.set_trace()\n(Pdb) p a\n'aaa'\n(Pdb) p b\n'bbb'\n(Pdb) p c\n'ccc'\n(Pdb) p final\n'aaabbbccc'\n(Pdb)</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, we will learn how to debug thread applications. We will also learn the importance of debugging. What is Debugging? In computer programming, debugging is the process of finding and removing the bugs, errors and abnormalities from computer program. This process starts as soon as the code is written and continues in successive [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2761"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2761"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2761/revisions"}],"predecessor-version":[{"id":2991,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2761/revisions/2991"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2761"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2761"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2761"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2762,"date":"2020-07-08T10:35:30","date_gmt":"2020-07-08T10:35:30","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1694"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"benchmarking-and-profiling","status":"publish","type":"post","link":"https://python3.foobrdigital.com/benchmarking-and-profiling/","title":{"rendered":"Benchmarking and Profiling"},"content":{"rendered":"\n<p>In this chapter, we will learn how benchmarking and profiling help in addressing performance issues.</p>\n\n\n\n<p>Suppose we had written a code and it is giving the desired result too but what if we want to run this code a bit faster because the needs have changed. In this case, we need to find out what parts of our code are slowing down the entire program. In this case, benchmarking and profiling can be useful.</p>\n\n\n\n<h2>What is Benchmarking?</h2>\n\n\n\n<p>Benchmarking aims at evaluating something by comparison with a standard. However, the question that arises here is that what would be the benchmarking and why we need it in case of software programming. Benchmarking the code means how fast the code is executing and where the bottleneck is. One major reason for benchmarking is that it optimizes the code.</p>\n\n\n\n<h3>How does benchmarking work?</h3>\n\n\n\n<p>If we talk about the working of benchmarking, we need to start by benchmarking the whole program as one current state then we can combine micro benchmarks and then decompose a program into smaller programs. In order to find the bottlenecks within our program and optimize it. In other words, we can understand it as breaking the big and hard problem into series of smaller and a bit easier problems for optimizing them.</p>\n\n\n\n<h3>Python module for benchmarking</h3>\n\n\n\n<p>In Python, we have a by default module for benchmarking which is called&nbsp;<strong>timeit</strong>. With the help of the&nbsp;<strong>timeit</strong>&nbsp;module, we can measure the performance of small bit of Python code within our main program.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>In the following Python script, we are importing the <strong>timeit</strong> module, which further measures the time taken to execute two functions – <strong>functionA</strong> and <strong>functionB</strong> −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import timeit\nimport time\ndef functionA():\n   print(\"Function A starts the execution:\")\n   print(\"Function A completes the execution:\")\ndef functionB():\n   print(\"Function B starts the execution\")\n   print(\"Function B completes the execution\")\nstart_time = timeit.default_timer()\nfunctionA()\nprint(timeit.default_timer() - start_time)\nstart_time = timeit.default_timer()\nfunctionB()\nprint(timeit.default_timer() - start_time)</code></pre>\n\n\n\n<p>After running the above script, we will get the execution time of both the functions as shown below.</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Function A starts the execution:\nFunction A completes the execution:\n0.0014599495514175942\nFunction B starts the execution\nFunction B completes the execution\n0.0017024724827479076</code></pre>\n\n\n\n<h2>Writing our own timer using the decorator function</h2>\n\n\n\n<p>In Python, we can create our own timer, which will act just like the <strong>timeit</strong> module. It can be done with the help of the <strong>decorator</strong> function. Following is an example of the custom timer −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import random\nimport time\n\ndef timer_func(func):\n\n   def function_timer(*args, **kwargs):\n   start = time.time()\n   value = func(*args, **kwargs)\n   end = time.time()\n   runtime = end - start\n   msg = \"{func} took {time} seconds to complete its execution.\"\n      print(msg.format(func = func.__name__,time = runtime))\n   return value\n   return function_timer\n\n@timer_func\ndef Myfunction():\n   for x in range(5):\n   sleep_time = random.choice(range(1,3))\n   time.sleep(sleep_time)\n\nif __name__ == '__main__':\n   Myfunction()</code></pre>\n\n\n\n<p>The above python script helps in importing random time modules. We have created the timer_func() decorator function. This has the function_timer() function inside it. Now, the nested function will grab the time before calling the passed in function. Then it waits for the function to return and grabs the end time. In this way, we can finally make python script print the execution time. The script will generate the output as shown below.</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Myfunction took 8.000457763671875 seconds to complete its execution.\n</code></pre>\n\n\n\n<h2>What is profiling?</h2>\n\n\n\n<p>Sometimes the programmer wants to measure some attributes like the use of memory, time complexity or usage of particular instructions about the programs to measure the real capability of that program. Such kind of measuring about program is called profiling. Profiling uses dynamic program analysis to do such measuring.</p>\n\n\n\n<p>In the subsequent sections, we will learn about the different Python Modules for Profiling.</p>\n\n\n\n<h2>cProfile – the inbuilt module</h2>\n\n\n\n<p><strong>cProfile</strong>&nbsp;is a Python built-in module for profiling. The module is a C-extension with reasonable overhead that makes it suitable for profiling long-running programs. After running it, it logs all the functions and execution times. It is very powerful but sometimes a bit difficult to interpret and act on. In the following example, we are using cProfile on the code below −</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>def increment_global():\n\n   global x\n   x += 1\n\ndef taskofThread(lock):\n\n   for _ in range(50000):\n   lock.acquire()\n   increment_global()\n   lock.release()\n\ndef main():\n   global x\n   x = 0\n\n   lock = threading.Lock()\n\n   t1 = threading.Thread(target=taskofThread, args=(lock,))\n   t2 = threading.Thread(target= taskofThread, args=(lock,))\n\n   t1.start()\n   t2.start()\n\n   t1.join()\n   t2.join()\n\nif __name__ == \"__main__\":\n   for i in range(5):\n      main()\n   print(\"x = {1} after Iteration {0}\".format(i,x))</code></pre>\n\n\n\n<p>The above code is saved in the <strong>thread_increment.py</strong> file. Now, execute the code with cProfile on the command line as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>(base) D:\\ProgramData>python -m cProfile thread_increment.py\nx = 100000 after Iteration 0\nx = 100000 after Iteration 1\nx = 100000 after Iteration 2\nx = 100000 after Iteration 3\nx = 100000 after Iteration 4\n      3577 function calls (3522 primitive calls) in 1.688 seconds\n\n   Ordered by: standard name\n\n   ncalls tottime percall cumtime percall filename:lineno(function)\n\n   5 0.000 0.000 0.000 0.000 &lt;frozen importlib._bootstrap>:103(release)\n   5 0.000 0.000 0.000 0.000 &lt;frozen importlib._bootstrap>:143(__init__)\n   5 0.000 0.000 0.000 0.000 &lt;frozen importlib._bootstrap>:147(__enter__)</code></pre>\n\n\n\n<p>From the above output, it is clear that cProfile prints out all the 3577 functions called, with the time spent in each and the number of times they have been called. Followings are the columns we got in output −</p>\n\n\n\n<ul><li>m<strong>ncalls</strong> − It is the number of calls made.</li><li><strong>tottime</strong> − It is the total time spent in the given function.</li><li><strong>percall</strong> − It refers to the quotient of tottime divided by ncalls.</li><li><strong>cumtime</strong> − It is the cumulative time spent in this and all subfunctions. It is even accurate for recursive functions.</li><li><strong>percall</strong> − It is the quotient of cumtime divided by primitive calls.</li><li><strong>filename:lineno(function)</strong> − It basically provides the respective data of each function.</li></ul>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, we will learn how benchmarking and profiling help in addressing performance issues. Suppose we had written a code and it is giving the desired result too but what if we want to run this code a bit faster because the needs have changed. In this case, we need to find out what [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2762"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2762"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2762/revisions"}],"predecessor-version":[{"id":2990,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2762/revisions/2990"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2762"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2762"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2762"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2763,"date":"2020-07-08T10:40:12","date_gmt":"2020-07-08T10:40:12","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1696"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"pool-of-threads","status":"publish","type":"post","link":"https://python3.foobrdigital.com/pool-of-threads/","title":{"rendered":"Pool of Threads"},"content":{"rendered":"\n<p>Suppose we had to create a large number of threads for our multithreaded tasks. It would be computationally most expensive as there can be many performance issues, due to too many threads. A major issue could be in the throughput getting limited. We can solve this problem by creating a pool of threads. A thread pool may be defined as the group of pre-instantiated and idle threads, which stand ready to be given work. Creating thread pool is preferred over instantiating new threads for every task when we need to do large number of tasks. A thread pool can manage concurrent execution of large number of threads as follows −</p>\n\n\n\n<ul><li>If a thread in a thread pool completes its execution then that thread can be reused.</li><li>If a thread is terminated, another thread will be created to replace that thread.</li></ul>\n\n\n\n<h2>Python Module – Concurrent.futures</h2>\n\n\n\n<p>Python standard library includes the&nbsp;<strong>concurrent.futures</strong>&nbsp;module. This module was added in Python 3.2 for providing the developers a high-level interface for launching asynchronous tasks. It is an abstraction layer on the top of Python’s threading and multiprocessing modules for providing the interface for running the tasks using pool of thread or processes.</p>\n\n\n\n<p>In our subsequent sections, we will learn about the different classes of the concurrent.futures module.</p>\n\n\n\n<h2>Executor Class</h2>\n\n\n\n<p><strong>Executor</strong>is an abstract class of the&nbsp;<strong>concurrent.futures</strong>&nbsp;Python module. It cannot be used directly and we need to use one of the following concrete subclasses −</p>\n\n\n\n<ul><li>ThreadPoolExecutor</li><li>ProcessPoolExecutor</li></ul>\n\n\n\n<h3>ThreadPoolExecutor – A Concrete Subclass</h3>\n\n\n\n<p>It is one of the concrete subclasses of the Executor class. The subclass uses multi-threading and we get a pool of thread for submitting the tasks. This pool assigns tasks to the available threads and schedules them to run.</p>\n\n\n\n<h3>How to create a ThreadPoolExecutor?</h3>\n\n\n\n<p>With the help of&nbsp;<strong>concurrent.futures</strong>&nbsp;module and its concrete subclass&nbsp;<strong>Executor</strong>, we can easily create a pool of threads. For this, we need to construct a&nbsp;<strong>ThreadPoolExecutor</strong>&nbsp;with the number of threads we want in the pool. By default, the number is 5. Then we can submit a task to the thread pool. When we&nbsp;<strong>submit()</strong>&nbsp;a task, we get back a&nbsp;<strong>Future</strong>. The Future object has a method called&nbsp;<strong>done()</strong>, which tells if the future has resolved. With this, a value has been set for that particular future object. When a task finishes, the thread pool executor sets the value to the future object.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>from concurrent.futures import ThreadPoolExecutor\nfrom time import sleep\ndef task(message):\n   sleep(2)\n   return message\n\ndef main():\n   executor = ThreadPoolExecutor(5)\n   future = executor.submit(task, (\"Completed\"))\n   print(future.done())\n   sleep(2)\n   print(future.done())\n   print(future.result())\nif __name__ == '__main__':\nmain()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>False\nTrue\nCompleted</code></pre>\n\n\n\n<p>In the above example, a&nbsp;<strong>ThreadPoolExecutor</strong>&nbsp;has been constructed with 5 threads. Then a task, which will wait for 2 seconds before giving the message, is submitted to the thread pool executor. As seen from the output, the task does not complete until 2 seconds, so the first call to&nbsp;<strong>done()</strong>&nbsp;will return False. After 2 seconds, the task is done and we get the result of the future by calling the&nbsp;<strong>result()</strong>&nbsp;method on it.</p>\n\n\n\n<h3>Instantiating ThreadPoolExecutor – Context Manager</h3>\n\n\n\n<p>Another way to instantiate <strong>ThreadPoolExecutor</strong> is with the help of context manager. It works similar to the method used in the above example. The main advantage of using context manager is that it looks syntactically good. The instantiation can be done with the help of the following code −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>with ThreadPoolExecutor(max_workers = 5) as executor</code></pre>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following example is borrowed from the Python docs. In this example, first of all the <strong>concurrent.futures</strong> module has to be imported. Then a function named <strong>load_url()</strong> is created which will load the requested url. The function then creates <strong>ThreadPoolExecutor</strong>with the 5 threads in the pool. The <strong>ThreadPoolExecutor</strong> has been utilized as context manager. We can get the result of the future by calling the <strong>result()</strong> method on it.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import concurrent.futures\nimport urllib.request\n\nURLS = &#91;'http://www.foxnews.com/',\n   'http://www.cnn.com/',\n   'http://europe.wsj.com/',\n   'http://www.bbc.co.uk/',\n   'http://some-made-up-domain.com/']\n\ndef load_url(url, timeout):\n   with urllib.request.urlopen(url, timeout = timeout) as conn:\n   return conn.read()\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers = 5) as executor:\n\n   future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n   for future in concurrent.futures.as_completed(future_to_url):\n   url = future_to_url&#91;future]\n   try:\n      data = future.result()\n   except Exception as exc:\n      print('%r generated an exception: %s' % (url, exc))\n   else:\n      print('%r page is %d bytes' % (url, len(data)))</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<p>Following would be the output of the above Python script −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>'http://some-made-up-domain.com/' generated an exception: &lt;urlopen error &#91;Errno 11004] getaddrinfo failed>\n'http://www.foxnews.com/' page is 229313 bytes\n'http://www.cnn.com/' page is 168933 bytes\n'http://www.bbc.co.uk/' page is 283893 bytes\n'http://europe.wsj.com/' page is 938109 bytes</code></pre>\n\n\n\n<h3>Use of Executor.map() function</h3>\n\n\n\n<p>The Python&nbsp;<strong>map()</strong>&nbsp;function is widely used in a number of tasks. One such task is to apply a certain function to every element within iterables. Similarly, we can map all the elements of an iterator to a function and submit these as independent jobs to out&nbsp;<strong>ThreadPoolExecutor</strong>. Consider the following example of Python script to understand how the function works.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>In this example below, the map function is used to apply the <strong>square()</strong> function to every value in the values array.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from concurrent.futures import ThreadPoolExecutor\nfrom concurrent.futures import as_completed\nvalues = &#91;2,3,4,5]\ndef square(n):\n   return n * n\ndef main():\n   with ThreadPoolExecutor(max_workers = 3) as executor:\n      results = executor.map(square, values)\nfor result in results:\n      print(result)\nif __name__ == '__main__':\n   main()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<p>The above Python script generates the following output −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>4\n9\n16\n25</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>Suppose we had to create a large number of threads for our multithreaded tasks. It would be computationally most expensive as there can be many performance issues, due to too many threads. A major issue could be in the throughput getting limited. We can solve this problem by creating a pool of threads. A thread [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2763"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2763"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2763/revisions"}],"predecessor-version":[{"id":2989,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2763/revisions/2989"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2763"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2763"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2763"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2764,"date":"2020-07-08T10:46:01","date_gmt":"2020-07-08T10:46:01","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1699"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"pool-of-processes","status":"publish","type":"post","link":"https://python3.foobrdigital.com/pool-of-processes/","title":{"rendered":"Pool of Processes"},"content":{"rendered":"\n<p>Pool of process can be created and used in the same way as we have created and used the pool of threads. Process pool can be defined as the group of pre-instantiated and idle processes, which stand ready to be given work. Creating process pool is preferred over instantiating new processes for every task when we need to do a large number of tasks.</p>\n\n\n\n<h2>Python Module – Concurrent.futures</h2>\n\n\n\n<p>Python standard library has a module called the&nbsp;<strong>concurrent.futures</strong>. This module was added in Python 3.2 for providing the developers a high-level interface for launching asynchronous tasks. It is an abstraction layer on the top of Python’s threading and multiprocessing modules for providing the interface for running the tasks using pool of thread or processes.</p>\n\n\n\n<p>In our subsequent sections, we will look at the different subclasses of the concurrent.futures module.</p>\n\n\n\n<h2>Executor Class</h2>\n\n\n\n<p><strong>Executor</strong>&nbsp;is an abstract class of the&nbsp;<strong>concurrent.futures</strong>&nbsp;Python module. It cannot be used directly and we need to use one of the following concrete subclasses −</p>\n\n\n\n<ul><li>ThreadPoolExecutor</li><li>ProcessPoolExecutor</li></ul>\n\n\n\n<h3>ProcessPoolExecutor – A concrete subclass</h3>\n\n\n\n<p>It is one of the concrete subclasses of the Executor class. It uses multi-processing and we get a pool of processes for submitting the tasks. This pool assigns tasks to the available processes and schedule them to run.</p>\n\n\n\n<h3>How to create a ProcessPoolExecutor?</h3>\n\n\n\n<p>With the help of the&nbsp;<strong>concurrent.futures</strong>&nbsp;module and its concrete subclass&nbsp;<strong>Executor</strong>, we can easily create a pool of process. For this, we need to construct a&nbsp;<strong>ProcessPoolExecutor</strong>with the number of processes we want in the pool. By default, the number is 5. This is followed by submitting a task to the process pool.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>We will now consider the same example that we used while creating thread pool, the only difference being that now we will use <strong>ProcessPoolExecutor</strong> instead of <strong>ThreadPoolExecutor</strong> .</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from concurrent.futures import ProcessPoolExecutor\nfrom time import sleep\ndef task(message):\n   sleep(2)\n   return message\n\ndef main():\n   executor = ProcessPoolExecutor(5)\n   future = executor.submit(task, (\"Completed\"))\n   print(future.done())\n   sleep(2)\n   print(future.done())\n   print(future.result())\nif __name__ == '__main__':\nmain()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>False\nFalse\nCompleted</code></pre>\n\n\n\n<p>In the above example, a Process<strong>PoolExecutor</strong>&nbsp;has been constructed with 5 threads. Then a task, which will wait for 2 seconds before giving the message, is submitted to the process pool executor. As seen from the output, the task does not complete until 2 seconds, so the first call to&nbsp;<strong>done()</strong>&nbsp;will return False. After 2 seconds, the task is done and we get the result of the future by calling the&nbsp;<strong>result()</strong>&nbsp;method on it.</p>\n\n\n\n<h3>Instantiating ProcessPoolExecutor – Context Manager</h3>\n\n\n\n<p>Another way to instantiate ProcessPoolExecutor is with the help of context manager. It works similar to the method used in the above example. The main advantage of using context manager is that it looks syntactically good. The instantiation can be done with the help of the following code −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>with ProcessPoolExecutor(max_workers = 5) as executor\n</code></pre>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>For better understanding, we are taking the same example as used while creating thread pool. In this example, we need to start by importing the <strong>concurrent.futures</strong> module. Then a function named <strong>load_url()</strong> is created which will load the requested url. The <strong>ProcessPoolExecutor</strong> is then created with the 5 number of threads in the pool. The Process<strong>PoolExecutor</strong> has been utilized as context manager. We can get the result of the future by calling the <strong>result()</strong> method on it.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import concurrent.futures\nfrom concurrent.futures import ProcessPoolExecutor\nimport urllib.request\n\nURLS = &#91;'http://www.foxnews.com/',\n   'http://www.cnn.com/',\n   'http://europe.wsj.com/',\n   'http://www.bbc.co.uk/',\n   'http://some-made-up-domain.com/']\n\ndef load_url(url, timeout):\n   with urllib.request.urlopen(url, timeout = timeout) as conn:\n      return conn.read()\n\ndef main():\n   with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:\n      future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n      for future in concurrent.futures.as_completed(future_to_url):\n      url = future_to_url&#91;future]\n      try:\n         data = future.result()\n      except Exception as exc:\n         print('%r generated an exception: %s' % (url, exc))\n      else:\n         print('%r page is %d bytes' % (url, len(data)))\n\nif __name__ == '__main__':\n   main()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<p>The above Python script will generate the following output −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>'http://some-made-up-domain.com/' generated an exception: &lt;urlopen error &#91;Errno 11004] getaddrinfo failed>\n'http://www.foxnews.com/' page is 229476 bytes\n'http://www.cnn.com/' page is 165323 bytes\n'http://www.bbc.co.uk/' page is 284981 bytes\n'http://europe.wsj.com/' page is 967575 bytes</code></pre>\n\n\n\n<h3>Use of the Executor.map() function</h3>\n\n\n\n<p>The Python&nbsp;<strong>map()</strong>&nbsp;function is widely used to perform a number of tasks. One such task is to apply a certain function to every element within iterables. Similarly, we can map all the elements of an iterator to a function and submit these as independent jobs to the&nbsp;<strong>ProcessPoolExecutor</strong>. Consider the following example of Python script to understand this.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>We will consider the same example that we used while creating thread pool using the <strong>Executor.map()</strong> function. In the example givenbelow, the map function is used to apply <strong>square()</strong> function to every value in the values array.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from concurrent.futures import ProcessPoolExecutor\nfrom concurrent.futures import as_completed\nvalues = &#91;2,3,4,5]\ndef square(n):\n   return n * n\ndef main():\n   with ProcessPoolExecutor(max_workers = 3) as executor:\n      results = executor.map(square, values)\n   for result in results:\n      print(result)\nif __name__ == '__main__':\n   main()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<p>The above Python script will generate the following output</p>\n\n\n\n<pre class=\"wp-block-code\"><code>4\n9\n16\n25</code></pre>\n\n\n\n<h3>When to use ProcessPoolExecutor and ThreadPoolExecutor?</h3>\n\n\n\n<p>Now that we have studied about both the Executor classes – ThreadPoolExecutor and ProcessPoolExecutor, we need to know when to use which executor. We need to choose ProcessPoolExecutor in case of CPU-bound workloads and ThreadPoolExecutor in case of I/O-bound workloads.</p>\n\n\n\n<p>If we use&nbsp;<strong>ProcessPoolExecutor</strong>, then we do not need to worry about GIL because it uses multiprocessing. Moreover, the execution time will be less when compared to&nbsp;<strong>ThreadPoolExecution</strong>. Consider the following Python script example to understand this.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import time\nimport concurrent.futures\n\nvalue = &#91;8000000, 7000000]\n\ndef counting(n):\n   start = time.time()\n   while n > 0:\n      n -= 1\n   return time.time() - start\n\ndef main():\n   start = time.time()\n   with concurrent.futures.ProcessPoolExecutor() as executor:\n      for number, time_taken in zip(value, executor.map(counting, value)):\n         print('Start: {} Time taken: {}'.format(number, time_taken))\n   print('Total time taken: {}'.format(time.time() - start))\n\nif __name__ == '__main__':\nmain()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Start: 8000000 Time taken: 1.5509998798370361\nStart: 7000000 Time taken: 1.3259999752044678\nTotal time taken: 2.0840001106262207\n\nExample- Python script with ThreadPoolExecutor:\nimport time\nimport concurrent.futures\n\nvalue = &#91;8000000, 7000000]\n\ndef counting(n):\n   start = time.time()\n   while n > 0:\n      n -= 1\n   return time.time() - start\n\ndef main():\n   start = time.time()\n   with concurrent.futures.ThreadPoolExecutor() as executor:\n      for number, time_taken in zip(value, executor.map(counting, value)):\n         print('Start: {} Time taken: {}'.format(number, time_taken))\n      print('Total time taken: {}'.format(time.time() - start))\n\nif __name__ == '__main__':\nmain()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Start: 8000000 Time taken: 3.8420000076293945\nStart: 7000000 Time taken: 3.6010000705718994\nTotal time taken: 3.8480000495910645</code></pre>\n\n\n\n<p>From the outputs of both the programs above, we can see the difference of execution time while using&nbsp;<strong>ProcessPoolExecutor</strong>&nbsp;and&nbsp;<strong>ThreadPoolExecutor</strong>.</p>\n","protected":false},"excerpt":{"rendered":"<p>Pool of process can be created and used in the same way as we have created and used the pool of threads. Process pool can be defined as the group of pre-instantiated and idle processes, which stand ready to be given work. Creating process pool is preferred over instantiating new processes for every task when [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2764"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2764"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2764/revisions"}],"predecessor-version":[{"id":2988,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2764/revisions/2988"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2764"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2764"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2764"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2768,"date":"2020-07-10T12:03:30","date_gmt":"2020-07-10T12:03:30","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1707"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"multiprocessing-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/multiprocessing-2/","title":{"rendered":"Multiprocessing"},"content":{"rendered":"\n<p>In this chapter, we will focus more on the comparison between multiprocessing and multithreading.</p>\n\n\n\n<h3>Multiprocessing</h3>\n\n\n\n<p>It is the use of two or more CPUs units within a single computer system. It is the best approach to get the full potential from our hardware by utilizing full number of CPU cores available in our computer system.</p>\n\n\n\n<h3>Multithreading</h3>\n\n\n\n<p>It is the ability of a CPU to manage the use of operating system by executing multiple threads concurrently. The main idea of multithreading is to achieve parallelism by dividing a process into multiple threads.</p>\n\n\n\n<p>The following table shows some of the important differences between them −</p>\n\n\n\n<figure class=\"wp-block-table\"><table><tbody><tr><th>Multiprocessing</th><th>Multiprogramming</th></tr><tr><td>Multiprocessing refers to processing of multiple processes at same time by multiple CPUs.</td><td>Multiprogramming keeps several programs in main memory at the same time and execute them concurrently utilizing single CPU.</td></tr><tr><td>It utilizes multiple CPUs.</td><td>It utilizes single CPU.</td></tr><tr><td>It permits parallel processing.</td><td>Context switching takes place.</td></tr><tr><td>Less time taken to process the jobs.</td><td>More Time taken to process the jobs.</td></tr><tr><td>It facilitates much efficient utilization of devices of the computer system.</td><td>Less efficient than multiprocessing.</td></tr><tr><td>Usually more expensive.</td><td>Such systems are less expensive.</td></tr></tbody></table></figure>\n\n\n\n<h2>Eliminating impact of global interpreter lock (GIL)</h2>\n\n\n\n<p>While working with concurrent applications, there is a limitation present in Python called the&nbsp;<strong>GIL (Global Interpreter Lock)</strong>. GIL never allows us to utilize multiple cores of CPU and hence we can say that there are no true threads in Python. GIL is the mutex – mutual exclusion lock, which makes things thread safe. In other words, we can say that GIL prevents multiple threads from executing Python code in parallel. The lock can be held by only one thread at a time and if we want to execute a thread then it must acquire the lock first.</p>\n\n\n\n<p>With the use of multiprocessing, we can effectively bypass the limitation caused by GIL −</p>\n\n\n\n<ul><li>By using multiprocessing, we are utilizing the capability of multiple processes and hence we are utilizing multiple instances of the GIL.</li><li>Due to this, there is no restriction of executing the bytecode of one thread within our programs at any one time.</li></ul>\n\n\n\n<h2>Starting Processes in Python</h2>\n\n\n\n<p>The following three methods can be used to start a process in Python within the multiprocessing module −</p>\n\n\n\n<ul><li>Fork</li><li>Spawn</li><li>Forkserver</li></ul>\n\n\n\n<h3>Creating a process with Fork</h3>\n\n\n\n<p>Fork command is a standard command found in UNIX. It is used to create new processes called child processes. This child process runs concurrently with the process called the parent process. These child processes are also identical to their parent processes and inherit all of the resources available to the parent. The following system calls are used while creating a process with Fork −</p>\n\n\n\n<ul><li><strong>fork()</strong>&nbsp;− It is a system call generally implemented in kernel. It is used to create a copy of the process.p&gt;</li><li><strong>getpid()</strong>&nbsp;− This system call returns the process ID(PID) of the calling process.</li></ul>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following Python script example will help you understabd how to create a new child process and get the PIDs of child and parent processes −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import os\n\ndef child():\n   n = os.fork()\n   \n   if n > 0:\n      print(\"PID of Parent process is : \", os.getpid())\n\n   else:\n      print(\"PID of Child process is : \", os.getpid())\nchild()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>PID of Parent process is : 25989\nPID of Child process is : 25990</code></pre>\n\n\n\n<h2>Creating a process with Spawn</h2>\n\n\n\n<p>Spawn means to start something new. Hence, spawning a process means the creation of a new process by a parent process. The parent process continues its execution asynchronously or waits until the child process ends its execution. Follow these steps for spawning a process −</p>\n\n\n\n<ul><li>Importing multiprocessing module.</li><li>Creating the object process.</li><li>Starting the process activity by calling&nbsp;<strong>start()</strong>&nbsp;method.</li><li>Waiting until the process has finished its work and exit by calling&nbsp;<strong>join()</strong>&nbsp;method.</li></ul>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following example of Python script helps in spawning three processes</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import multiprocessing\n\ndef spawn_process(i):\n   print ('This is process: %s' %i)\n   return\n\nif __name__ == '__main__':\n   Process_jobs = &#91;]\n   for i in range(3):\n   p = multiprocessing.Process(target = spawn_process, args = (i,))\n      Process_jobs.append(p)\n   p.start()\n   p.join()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>This is process: 0\nThis is process: 1\nThis is process: 2</code></pre>\n\n\n\n<h2>Creating a process with Forkserver</h2>\n\n\n\n<p>Forkserver mechanism is only available on those selected UNIX platforms that support passing the file descriptors over Unix Pipes. Consider the following points to understand the working of Forkserver mechanism −</p>\n\n\n\n<ul><li>A server is instantiated on using Forkserver mechanism for starting new process.</li><li>The server then receives the command and handles all the requests for creating new processes.</li><li>For creating a new process, our python program will send a request to Forkserver and it will create a process for us.</li><li>At last, we can use this new created process in our programs.</li></ul>\n\n\n\n<h2>Daemon processes in Python</h2>\n\n\n\n<p>Python&nbsp;<strong>multiprocessing</strong>&nbsp;module allows us to have daemon processes through its daemonic option. Daemon processes or the processes that are running in the background follow similar concept as the daemon threads. To execute the process in the background, we need to set the daemonic flag to true. The daemon process will continue to run as long as the main process is executing and it will terminate after finishing its execution or when the main program would be killed.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Here, we are using the same example as used in the daemon threads. The only difference is the change of module from <strong>multithreading</strong> to <strong>multiprocessing</strong> and setting the daemonic flag to true. However, there would be a change in output as shown below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import multiprocessing\nimport time\n\ndef nondaemonProcess():\n   print(\"starting my Process\")\n   time.sleep(8)\n   print(\"ending my Process\")\ndef daemonProcess():\n   while True:\n   print(\"Hello\")\n   time.sleep(2)\nif __name__ == '__main__':\n   nondaemonProcess = multiprocessing.Process(target = nondaemonProcess)\n   daemonProcess = multiprocessing.Process(target = daemonProcess)\n   daemonProcess.daemon = True\n   nondaemonProcess.daemon = False\n   daemonProcess.start()\n   nondaemonProcess.start()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>starting my Process\nending my Process</code></pre>\n\n\n\n<p>The output is different when compared to the one generated by daemon threads, because the process in no daemon mode have an output. Hence, the daemonic process ends automatically after the main programs end to avoid the persistence of running processes.</p>\n\n\n\n<h2>Terminating processes in Python</h2>\n\n\n\n<p>We can kill or terminate a process immediately by using the&nbsp;<strong>terminate()</strong>&nbsp;method. We will use this method to terminate the child process, which has been created with the help of function, immediately before completing its execution.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import multiprocessing\nimport time\ndef Child_process():\n   print ('Starting function')\n   time.sleep(5)\n   print ('Finished function')\nP = multiprocessing.Process(target = Child_process)\nP.start()\nprint(\"My Process has terminated, terminating main thread\")\nprint(\"Terminating Child Process\")\nP.terminate()\nprint(\"Child Process successfully terminated\")</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>My Process has terminated, terminating main thread\nTerminating Child Process\nChild Process successfully terminated</code></pre>\n\n\n\n<p>The output shows that the program terminates before the execution of child process that has been created with the help of the Child_process() function. This implies that the child process has been terminated successfully.</p>\n\n\n\n<h2>Identifying the current process in Python</h2>\n\n\n\n<p>Every process in the operating system is having process identity known as PID. In Python, we can find out the PID of current process with the help of the following command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import multiprocessing\nprint(multiprocessing.current_process().pid)</code></pre>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following example of Python script helps find out the PID of main process as well as PID of child process −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import multiprocessing\nimport time\ndef Child_process():\n   print(\"PID of Child Process is: {}\".format(multiprocessing.current_process().pid))\nprint(\"PID of Main process is: {}\".format(multiprocessing.current_process().pid))\nP = multiprocessing.Process(target=Child_process)\nP.start()\nP.join()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>PID of Main process is: 9401\nPID of Child Process is: 9402\n﻿</code></pre>\n\n\n\n<h2>Using a process in subclass</h2>\n\n\n\n<p>We can create threads by sub-classing the&nbsp;<strong>threading.Thread</strong>&nbsp;class. In addition, we can also create processes by sub-classing the&nbsp;<strong>multiprocessing.Process</strong>&nbsp;class. For using a process in subclass, we need to consider the following points −</p>\n\n\n\n<ul><li>We need to define a new subclass of the&nbsp;<strong>Process</strong>&nbsp;class.</li><li>We need to override the&nbsp;<strong>_init_(self [,args] )</strong>&nbsp;class.</li><li>We need to override the of the&nbsp;<strong>run(self [,args] )</strong>&nbsp;method to implement what&nbsp;<strong>Process</strong></li><li>We need to start the process by invoking the<strong>start()</strong>&nbsp;method.</li></ul>\n\n\n\n<h3>Example</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>import multiprocessing\nclass MyProcess(multiprocessing.Process):\n   def run(self):\n   print ('called run method in process: %s' %self.name)\n   return\nif __name__ == '__main__':\n   jobs = &#91;]\n   for i in range(5):\n   P = MyProcess()\n   jobs.append(P)\n   P.start()\n   P.join()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>called run method in process: MyProcess-1\ncalled run method in process: MyProcess-2\ncalled run method in process: MyProcess-3\ncalled run method in process: MyProcess-4\ncalled run method in process: MyProcess-5</code></pre>\n\n\n\n<h2>Python Multiprocessing Module – Pool Class</h2>\n\n\n\n<p>If we talk about simple parallel&nbsp;<strong>processing</strong>&nbsp;tasks in our Python applications, then multiprocessing module provide us the Pool class. The following methods of&nbsp;<strong>Pool</strong>&nbsp;class can be used to spin up number of child processes within our main program</p>\n\n\n\n<h3>apply() method</h3>\n\n\n\n<p>This method is similar to the<strong>.submit()</strong>method of&nbsp;<strong>.ThreadPoolExecutor.</strong>It blocks until the result is ready.</p>\n\n\n\n<h3>apply_async() method</h3>\n\n\n\n<p>When we need parallel execution of our tasks then we need to use the<strong>apply_async()</strong>method to submit tasks to the pool. It is an asynchronous operation that will not lock the main thread until all the child processes are executed.</p>\n\n\n\n<h3>map() method</h3>\n\n\n\n<p>Just like the&nbsp;<strong>apply()</strong>&nbsp;method, it also blocks until the result is ready. It is equivalent to the built-in&nbsp;<strong>map()</strong>&nbsp;function that splits the iterable data in a number of chunks and submits to the process pool as separate tasks.</p>\n\n\n\n<h3>map_async() method</h3>\n\n\n\n<p>It is a variant of the&nbsp;<strong>map()</strong>&nbsp;method as&nbsp;<strong>apply_async()</strong>&nbsp;is to the&nbsp;<strong>apply()</strong>&nbsp;method. It returns a result object. When the result becomes ready, a callable is applied to it. The callable must be completed immediately; otherwise, the thread that handles the results will get blocked.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following example will help you implement a process pool for performing parallel execution. A simple calculation of square of number has been performed by applying the <strong>square()</strong> function through the <strong>multiprocessing.Pool</strong> method. Then <strong>pool.map()</strong> has been used to submit the 5, because input is a list of integers from 0 to 4. The result would be stored in <strong>p_outputs</strong> and it is printed.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def square(n):\n   result = n*n\n   return result\nif __name__ == '__main__':\n   inputs = list(range(5))\n   p = multiprocessing.Pool(processes = 4)\n   p_outputs = pool.map(function_square, inputs)\n   p.close()\n   p.join()\n   print ('Pool :', p_outputs)</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Pool : &#91;0, 1, 4, 9, 16]</code></pre>\n\n\n\n<p></p>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, we will focus more on the comparison between multiprocessing and multithreading. Multiprocessing It is the use of two or more CPUs units within a single computer system. It is the best approach to get the full potential from our hardware by utilizing full number of CPU cores available in our computer system. [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2768"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2768"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2768/revisions"}],"predecessor-version":[{"id":2987,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2768/revisions/2987"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2768"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2768"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2768"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2767,"date":"2020-07-10T12:07:17","date_gmt":"2020-07-10T12:07:17","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1706"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"intercommunication","status":"publish","type":"post","link":"https://python3.foobrdigital.com/intercommunication/","title":{"rendered":"Intercommunication"},"content":{"rendered":"\n<p>Process intercommunication means the exchange of data between processes. It is necessary to exchange the data between processes for the development of parallel application. Following diagram shows the various communication mechanisms for synchronization between multiple sub processes −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/intercommunication.jpg\" alt=\"Intercommunication\"/></figure>\n\n\n\n<h2>Various Communication Mechanisms</h2>\n\n\n\n<p>In this section, we will learn about the various communication mechanisms. The mechanisms are described below −</p>\n\n\n\n<h3>Queues</h3>\n\n\n\n<p>Queues can be used with multi-process programs. The Queue class of&nbsp;<strong>multiprocessing</strong>module is similar to the&nbsp;<strong>Queue.Queue</strong>&nbsp;class. Hence, the same API can be used.&nbsp;<strong>Multiprocessing</strong>.Queue provides us a thread and process safe FIFO (first-in first-out) mechanism of communication between processes.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is a simple example taken from python official docs on multiprocessing to understand the concept of Queue class of multiprocessing.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from multiprocessing import Process, Queue\nimport queue\nimport random\ndef f(q):\n   q.put(&#91;42, None, 'hello'])\ndef main():\n   q = Queue()\n   p = Process(target = f, args = (q,))\n   p.start()\n   print (q.get())\nif __name__ == '__main__':\n   main()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91;42, None, 'hello']\n</code></pre>\n\n\n\n<h3>Pipes</h3>\n\n\n\n<p>It is a data structure, which is used to communicate between processes in multi-process programs. The Pipe() function returns a pair of connection objects connected by a pipe which by default is duplex(two way). It works in the following manner −</p>\n\n\n\n<ul><li>It returns a pair of connection objects that represent the two ends of pipe.</li><li>Every object has two methods –&nbsp;<strong>send()</strong>&nbsp;and&nbsp;<strong>recv()</strong>, to communicate between processes.</li></ul>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is a simple example taken from python official docs on multiprocessing to understand the concept of <strong>Pipe()</strong> function of multiprocessing.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from multiprocessing import Process, Pipe\n\ndef f(conn):\n   conn.send(&#91;42, None, 'hello'])\n   conn.close()\n\nif __name__ == '__main__':\n   parent_conn, child_conn = Pipe()\n   p = Process(target = f, args = (child_conn,))\n   p.start()\n   print (parent_conn.recv())\n   p.join()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91;42, None, 'hello']\n</code></pre>\n\n\n\n<h3>Manager</h3>\n\n\n\n<p>Manager is a class of multiprocessing module that provides a way to coordinate shared information between all its users. A manager object controls a server process, which manages shared objects and allows other processes to manipulate them. In other words, managers provide a way to create data that can be shared between different processes. Following are the different properties of manager object −</p>\n\n\n\n<ul><li>The main property of manager is to control a server process, which manages the shared objects.</li><li>Another important property is to update all the shared objects when any process modifies it.</li></ul>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is an example which uses the manager object for creating a list record in server process and then adding a new record in that list.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import multiprocessing\n\ndef print_records(records):\n   for record in records:\n      print(\"Name: {0}\\nScore: {1}\\n\".format(record&#91;0], record&#91;1]))\n\ndef insert_record(record, records):\n   records.append(record)\n      print(\"A New record is added\\n\")\n\nif __name__ == '__main__':\n   with multiprocessing.Manager() as manager:\n\n      records = manager.list(&#91;('Computers', 1), ('Histoty', 5), ('Hindi',9)])\n      new_record = ('English', 3)\n\n      p1 = multiprocessing.Process(target = insert_record, args = (new_record, records))\n      p2 = multiprocessing.Process(target = print_records, args = (records,))\n\t  p1.start()\n      p1.join()\n      p2.start()\n      p2.join()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>A New record is added\n\nName: Computers\nScore: 1\n\nName: Histoty\nScore: 5\n\nName: Hindi\nScore: 9\n\nName: English\nScore: 3</code></pre>\n\n\n\n<h3>Concept of Namespaces in Manager</h3>\n\n\n\n<p>Manager Class comes with the concept of namespaces, which is a quick way method for sharing several attributes across multiple processes. Namespaces do not feature any public method, which can be called, but they have writable attributes.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following Python script example helps us utilize namespaces for sharing data across main process and child process −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import multiprocessing\n\ndef Mng_NaSp(using_ns):\n\n   using_ns.x +=5\n   using_ns.y *= 10\n\nif __name__ == '__main__':\n   manager = multiprocessing.Manager()\n   using_ns = manager.Namespace()\n   using_ns.x = 1\n   using_ns.y = 1\n\n   print ('before', using_ns)\n   p = multiprocessing.Process(target = Mng_NaSp, args = (using_ns,))\n   p.start()\n   p.join()\n   print ('after', using_ns)</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>before Namespace(x = 1, y = 1)\nafter Namespace(x = 6, y = 10)</code></pre>\n\n\n\n<h2>Ctypes-Array and Value</h2>\n\n\n\n<p>Multiprocessing module provides Array and Value objects for storing the data in a shared memory map.&nbsp;<strong>Array</strong>&nbsp;is a ctypes array allocated from shared memory and&nbsp;<strong>Value</strong>&nbsp;is a ctypes object allocated from shared memory.</p>\n\n\n\n<p>To being with, import Process, Value, Array from multiprocessing.</p>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following Python script is an example taken from python docs to utilize Ctypes Array and Value for sharing some data between processes.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def f(n, a):\n   n.value = 3.1415927\n   for i in range(len(a)):\n   a&#91;i] = -a&#91;i]\n\nif __name__ == '__main__':\n   num = Value('d', 0.0)\n   arr = Array('i', range(10))\n\n   p = Process(target = f, args = (num, arr))\n   p.start()\n   p.join()\n   print (num.value)\n   print (arr&#91;:])</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>3.1415927\n&#91;0, -1, -2, -3, -4, -5, -6, -7, -8, -9]</code></pre>\n\n\n\n<h2>Communicating Sequential Processes (CSP)</h2>\n\n\n\n<p>CSP is used to illustrate the interaction of systems with other systems featuring concurrent models. CSP is a framework for writing concurrent or program via message passing and hence it is effective for describing concurrency.</p>\n\n\n\n<h2>Python library – PyCSP</h2>\n\n\n\n<p>For implementing core primitives found in CSP, Python has a library called PyCSP. It keeps the implementation very short and readable so that it can be understood very easily. Following is the basic process network of PyCSP −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/pycsp.jpg\" alt=\"PyCSP\"/></figure>\n\n\n\n<p>In the above PyCSP process network, there are two processes – Process1 and Process 2. These processes communicate by passing messages through two channels – channel 1 and channel 2.</p>\n\n\n\n<h3>Installing PyCSP</h3>\n\n\n\n<p>With the help of following command, we can install Python library PyCSP −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install PyCSP</code></pre>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following Python script is a simple example for running two processes in parallel to each other. It is done with the help of the PyCSP python libabary −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from pycsp.parallel import *\nimport time\n@process\ndef P1():\n   time.sleep(1)\n   print('P1 exiting')\n@process\ndef P2():\n   time.sleep(1)\n   print('P2 exiting')\ndef main():\n   Parallel(P1(), P2())\n   print('Terminating')\nif __name__ == '__main__':\n   main()</code></pre>\n\n\n\n<p>In the above script, two functions namely&nbsp;<strong>P1</strong>&nbsp;and&nbsp;<strong>P2</strong>&nbsp;have been created and then decorated with&nbsp;<strong>@process</strong>&nbsp;for converting them into processes.</p>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>P2 exiting\nP1 exiting\nTerminating</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>Process intercommunication means the exchange of data between processes. It is necessary to exchange the data between processes for the development of parallel application. Following diagram shows the various communication mechanisms for synchronization between multiple sub processes − Various Communication Mechanisms In this section, we will learn about the various communication mechanisms. The mechanisms are [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2767"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2767"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2767/revisions"}],"predecessor-version":[{"id":2986,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2767/revisions/2986"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2767"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2767"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2767"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2766,"date":"2020-07-10T12:17:56","date_gmt":"2020-07-10T12:17:56","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1705"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"event-driven","status":"publish","type":"post","link":"https://python3.foobrdigital.com/event-driven/","title":{"rendered":"Event-Driven"},"content":{"rendered":"\n<p>Event-driven programming focuses on events. Eventually, the flow of program depends upon events. Until now, we were dealing with either sequential or parallel execution model but the model having the concept of event-driven programming is called asynchronous model. Event-driven programming depends upon an event loop that is always listening for the new incoming events. The working of event-driven programming is dependent upon events. Once an event loops, then events decide what to execute and in what order. Following flowchart will help you understand how this works −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/concurrency_in_python/images/driven.jpg\" alt=\"Driven\"/></figure>\n\n\n\n<h2>Python Module – Asyncio</h2>\n\n\n\n<p>Asyncio module was added in Python 3.4 and it provides infrastructure for writing single-threaded concurrent code using co-routines. Following are the different concepts used by the Asyncio module −</p>\n\n\n\n<h3>The event loop</h3>\n\n\n\n<p>Event-loop is a functionality to handle all the events in a computational code. It acts round the way during the execution of whole program and keeps track of the incoming and execution of events. The Asyncio module allows a single event loop per process. Followings are some methods provided by Asyncio module to manage an event loop −</p>\n\n\n\n<ul><li><strong>loop = get_event_loop()</strong>&nbsp;− This method will provide the event loop for the current context.</li><li><strong>loop.call_later(time_delay,callback,argument)</strong>&nbsp;− This method arranges for the callback that is to be called after the given time_delay seconds.</li><li><strong>loop.call_soon(callback,argument)</strong>&nbsp;− This method arranges for a callback that is to be called as soon as possible. The callback is called after call_soon() returns and when the control returns to the event loop.</li><li><strong>loop.time()</strong>&nbsp;− This method is used to return the current time according to the event loop’s internal clock.</li><li><strong>asyncio.set_event_loop()</strong>&nbsp;− This method will set the event loop for the current context to the loop.</li><li><strong>asyncio.new_event_loop()</strong>&nbsp;− This method will create and return a new event loop object.</li><li><strong>loop.run_forever()</strong>&nbsp;− This method will run until stop() method is called.</li></ul>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following example of event loop helps in printing <strong>hello world</strong> by using the get_event_loop() method. This example is taken from the Python official docs.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import asyncio\n\ndef hello_world(loop):\n   print('Hello World')\n   loop.stop()\n\nloop = asyncio.get_event_loop()\n\nloop.call_soon(hello_world, loop)\n\nloop.run_forever()\nloop.close()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Hello World\n</code></pre>\n\n\n\n<h3>Futures</h3>\n\n\n\n<p>This is compatible with the concurrent.futures.Future class that represents a computation that has not been accomplished. There are following differences between asyncio.futures.Future and concurrent.futures.Future −</p>\n\n\n\n<ul><li>result() and exception() methods do not take a timeout argument and raise an exception when the future isn’t done yet.</li><li>Callbacks registered with add_done_callback() are always called via the event loop’s call_soon().</li><li>asyncio.futures.Future class is not compatible with the wait() and as_completed() functions in the concurrent.futures package.</li></ul>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>The following is an example that will help you understand how to use asyncio.futures.future class.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import asyncio\n\nasync def Myoperation(future):\n   await asyncio.sleep(2)\n   future.set_result('Future Completed')\n\nloop = asyncio.get_event_loop()\nfuture = asyncio.Future()\nasyncio.ensure_future(Myoperation(future))\ntry:\n   loop.run_until_complete(future)\n   print(future.result())\nfinally:\n   loop.close()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Future Completed\n</code></pre>\n\n\n\n<h3>Coroutines</h3>\n\n\n\n<p>The concept of coroutines in Asyncio is similar to the concept of standard Thread object under threading module. This is the generalization of the subroutine concept. A coroutine can be suspended during the execution so that it waits for the external processing and returns from the point at which it had stopped when the external processing was done. The following two ways help us in implementing coroutines −</p>\n\n\n\n<h3>async def function()</h3>\n\n\n\n<p>This is a method for implementation of coroutines under Asyncio module. Following is a Python script for the same −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import asyncio\n\nasync def Myoperation():\n   print(\"First Coroutine\")\n\nloop = asyncio.get_event_loop()\ntry:\n   loop.run_until_complete(Myoperation())\n\nfinally:\n   loop.close()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>First Coroutine\n</code></pre>\n\n\n\n<h3>@asyncio.coroutine decorator</h3>\n\n\n\n<p>Another method for implementation of coroutines is to utilize generators with the @asyncio.coroutine decorator. Following is a Python script for the same −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import asyncio\n\n@asyncio.coroutine\ndef Myoperation():\n   print(\"First Coroutine\")\n\nloop = asyncio.get_event_loop()\ntry:\n   loop.run_until_complete(Myoperation())\n\nfinally:\n   loop.close()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>First Coroutine\n</code></pre>\n\n\n\n<h3>Tasks</h3>\n\n\n\n<p>This subclass of Asyncio module is responsible for execution of coroutines within an event loop in parallel manner. Following Python script is an example of processing some tasks in parallel.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import asyncio\nimport time\nasync def Task_ex(n):\n   time.sleep(1)\n   print(\"Processing {}\".format(n))\nasync def Generator_task():\n   for i in range(10):\n      asyncio.ensure_future(Task_ex(i))\n   int(\"Tasks Completed\")\n   asyncio.sleep(2)\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(Generator_task())\nloop.close()</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Tasks Completed\nProcessing 0\nProcessing 1\nProcessing 2\nProcessing 3\nProcessing 4\nProcessing 5\nProcessing 6\nProcessing 7\nProcessing 8\nProcessing 9</code></pre>\n\n\n\n<h3>Transports</h3>\n\n\n\n<p>Asyncio module provides transport classes for implementing various types of communication. These classes are not thread safe and always paired with a protocol instance after establishment of communication channel.</p>\n\n\n\n<p>Following are distinct types of transports inherited from the BaseTransport −</p>\n\n\n\n<ul><li><strong>ReadTransport</strong>&nbsp;− This is an interface for read-only transports.</li><li><strong>WriteTransport</strong>&nbsp;− This is an interface for write-only transports.</li><li><strong>DatagramTransport</strong>&nbsp;− This is an interface for sending the data.</li><li><strong>BaseSubprocessTransport</strong>&nbsp;− Similar to BaseTransport class.</li></ul>\n\n\n\n<p>Followings are five distinct methods of BaseTransport class that are subsequently transient across the four transport types −</p>\n\n\n\n<ul><li><strong>close()</strong>&nbsp;− It closes the transport.</li><li><strong>is_closing()</strong>&nbsp;− This method will return true if the transport is closing or is already closed.transports.</li><li><strong>get_extra_info(name, default = none)</strong>&nbsp;− This will give us some extra information about transport.</li><li><strong>get_protocol()</strong>&nbsp;− This method will return the current protocol.</li></ul>\n\n\n\n<h3>Protocols</h3>\n\n\n\n<p>Asyncio module provides base classes that you can subclass to implement your network protocols. Those classes are used in conjunction with transports; the protocol parses incoming data and asks for the writing of outgoing data, while the transport is responsible for the actual I/O and buffering. Following are three classes of Protocol −</p>\n\n\n\n<ul><li><strong>Protocol</strong>&nbsp;− This is the base class for implementing streaming protocols for use with TCP and SSL transports.</li><li><strong>DatagramProtocol</strong>&nbsp;− This is the base class for implementing datagram protocols for use with UDP transports..</li><li><strong>SubprocessProtocol</strong>&nbsp;− This is the base class for implementing protocols communicating with child processes through a set of unidirectional pipes.</li></ul>\n","protected":false},"excerpt":{"rendered":"<p>Event-driven programming focuses on events. Eventually, the flow of program depends upon events. Until now, we were dealing with either sequential or parallel execution model but the model having the concept of event-driven programming is called asynchronous model. Event-driven programming depends upon an event loop that is always listening for the new incoming events. The [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2766"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2766"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2766/revisions"}],"predecessor-version":[{"id":2985,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2766/revisions/2985"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2766"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2766"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2766"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":2765,"date":"2020-07-10T12:19:30","date_gmt":"2020-07-10T12:19:30","guid":{"rendered":"http://learnpython.foobrdigital.com/?p=1704"},"modified":"2020-12-16T16:53:10","modified_gmt":"2020-12-16T16:53:10","slug":"reactive-programming","status":"publish","type":"post","link":"https://python3.foobrdigital.com/reactive-programming/","title":{"rendered":"Reactive Programming"},"content":{"rendered":"\n<p>Reactive programming is a programming paradigm that deals with data flows and the propagation of change. It means that when a data flow is emitted by one component, the change will be propagated to other components by reactive programming library. The propagation of change will continue until it reaches the final receiver. The difference between event-driven and reactive programming is that event-driven programming revolves around events and reactive programming revolves around data.</p>\n\n\n\n<h2>ReactiveX or RX for reactive programming</h2>\n\n\n\n<p>ReactiveX or Raective Extension is the most famous implementation of reactive programming. The working of ReactiveX depends upon the following two classes −</p>\n\n\n\n<h3>Observable class</h3>\n\n\n\n<p>This class is the source of data stream or events and it packs the incoming data so that the data can be passed from one thread to another. It will not give data until some observer subscribe to it.</p>\n\n\n\n<h3>Observer class</h3>\n\n\n\n<p>This class consumes the data stream emitted by&nbsp;<strong>observable</strong>. There can be multiple observers with observable and each observer will receive each data item that is emitted. The observer can receive three type of events by subscribing to observable −</p>\n\n\n\n<ul><li><strong>on_next() event</strong>&nbsp;− It implies there is an element in the data stream.</li><li><strong>on_completed() event</strong>&nbsp;− It implies end of emission and no more items are coming.</li><li><strong>on_error() event</strong>&nbsp;− It also implies end of emission but in case when an error is thrown by&nbsp;<strong>observable</strong>.</li></ul>\n\n\n\n<h2>RxPY – Python Module for Reactive Programming</h2>\n\n\n\n<p>RxPY is a Python module which can be used for reactive programming. We need to ensure that the module is installed. The following command can be used to install the RxPY module −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install RxPY\n</code></pre>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following is a Python script, which uses&nbsp;<strong>RxPY</strong>&nbsp;module and its classes&nbsp;<strong>Observable</strong>&nbsp;and&nbsp;<strong>Observe for</strong>&nbsp;reactive programming. There are basically two classes −</p>\n\n\n\n<ul><li><strong>get_strings()</strong> − for getting the strings from observer.</li><li><strong>PrintObserver()</strong> − for printing the strings from observer. It uses all three events of observer class. It also uses subscribe() class.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>from rx import Observable, Observer\ndef get_strings(observer):\n   observer.on_next(\"Ram\")\n   observer.on_next(\"Mohan\")\n   observer.on_next(\"Shyam\")\n      observer.on_completed()\nclass PrintObserver(Observer):\n   def on_next(self, value):\n      print(\"Received {0}\".format(value))\n   def on_completed(self):\n   print(\"Finished\")\n   def on_error(self, error):\n      print(\"Error: {0}\".format(error))\nsource = Observable.create(get_strings)\nsource.subscribe(PrintObserver())</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Received Ram\nReceived Mohan\nReceived Shyam\nFinished</code></pre>\n\n\n\n<h2>PyFunctional library for reactive programming</h2>\n\n\n\n<p><strong>PyFunctional</strong>is another Python library that can be used for reactive programming. It enables us to create functional programs using the Python programming language. It is useful because it allows us to create data pipelines by using chained functional operators.</p>\n\n\n\n<h3>Difference between RxPY and PyFunctional</h3>\n\n\n\n<p>Both the libraries are used for reactive programming and handle the stream in similar fashion but the main difference between both of them depends upon the handling of data.&nbsp;<strong>RxPY</strong>&nbsp;handles data and events in the system while&nbsp;<strong>PyFunctional</strong>&nbsp;is focused on transformation of data using functional programming paradigms.</p>\n\n\n\n<h3>Installing PyFunctional Module</h3>\n\n\n\n<p>We need to install this module before using it. It can be installed with the help of pip command as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install pyfunctional</code></pre>\n\n\n\n<h3>Example</h3>\n\n\n\n<p>Following example uses <strong>the PyFunctional</strong> module and its <strong>seq</strong> class which act as the stream object with which we can iterate and manipulate. In this program, it maps the sequence by using the lamda function that doubles every value, then filters the value where x is greater than 4 and finally it reduces the sequence into a sum of all the remaining values.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from functional import seq\n\nresult = seq(1,2,3).map(lambda x: x*2).filter(lambda x: x > 4).reduce(lambda x, y: x + y)\n\nprint (\"Result: {}\".format(result))</code></pre>\n\n\n\n<h3>Output</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>Result: 6</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>Reactive programming is a programming paradigm that deals with data flows and the propagation of change. It means that when a data flow is emitted by one component, the change will be propagated to other components by reactive programming library. The propagation of change will continue until it reaches the final receiver. The difference between [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[35,59,141],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2765"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=2765"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2765/revisions"}],"predecessor-version":[{"id":2984,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/2765/revisions/2984"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=2765"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=2765"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=2765"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}}]