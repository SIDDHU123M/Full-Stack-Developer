[{"id":3373,"date":"2020-10-01T10:59:59","date_gmt":"2020-10-01T10:59:59","guid":{"rendered":"http://ai.foobrdigital.com/?p=3373"},"modified":"2020-12-16T17:04:17","modified_gmt":"2020-12-16T17:04:17","slug":"introduction-2-2","status":"publish","type":"post","link":"https://python3.foobrdigital.com/introduction-2-2/","title":{"rendered":"Introduction"},"content":{"rendered":"\n<p>Deep learning is one of the major subfield of machine learning framework. Machine learning is the study of design of algorithms, inspired from the model of human brain. Deep learning is becoming more popular in data science fields like robotics, artificial intelligence(AI), audio &amp; video recognition and image recognition. Artificial neural network is the core of deep learning methodologies. Deep learning is supported by various libraries such as Theano, TensorFlow, Caffe, Mxnet etc., Keras is one of the most powerful and easy to use python library, which is built on top of popular deep learning libraries like TensorFlow, Theano, etc., for creating deep learning models.</p>\n\n\n\n<h2>Overview of Keras</h2>\n\n\n\n<p>Keras runs on top of open source machine libraries like TensorFlow, Theano or Cognitive Toolkit (CNTK). Theano is a python library used for fast numerical computation tasks. TensorFlow is the most famous symbolic math library used for creating neural networks and deep learning models. TensorFlow is very flexible and the primary benefit is distributed computing. CNTK is deep learning framework developed by Microsoft. It uses libraries such as Python, C#, C++ or standalone machine learning toolkits. Theano and TensorFlow are very powerful libraries but difficult to understand for creating neural networks.</p>\n\n\n\n<p>Keras is based on minimal structure that provides a clean and easy way to create deep learning models based on TensorFlow or Theano. Keras is designed to quickly define deep learning models. Well, Keras is an optimal choice for deep learning applications.</p>\n\n\n\n<h2>Features</h2>\n\n\n\n<p>Keras leverages various optimization techniques to make high level neural network API easier and more performant. It supports the following features −</p>\n\n\n\n<ul><li>Consistent, simple and extensible API.</li><li>Minimal structure &#8211; easy to achieve the result without any frills.</li><li>It supports multiple platforms and backends.</li><li>It is user friendly framework which runs on both CPU and GPU.</li><li>Highly scalability of computation.</li></ul>\n\n\n\n<h2>Benefits</h2>\n\n\n\n<p>Keras is highly powerful and dynamic framework and comes up with the following advantages −</p>\n\n\n\n<ul><li>Larger community support.</li><li>Easy to test.</li><li>Keras neural networks are written in Python which makes things simpler.</li><li>Keras supports both convolution and recurrent networks.</li><li>Deep learning models are discrete components, so that, you can combine into many ways.</li></ul>\n","protected":false},"excerpt":{"rendered":"<p>Deep learning is one of the major subfield of machine learning framework. Machine learning is the study of design of algorithms, inspired from the model of human brain. Deep learning is becoming more popular in data science fields like robotics, artificial intelligence(AI), audio &amp; video recognition and image recognition. Artificial neural network is the core [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3373"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3373"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3373/revisions"}],"predecessor-version":[{"id":4246,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3373/revisions/4246"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3373"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3373"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3373"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3375,"date":"2020-10-01T11:05:02","date_gmt":"2020-10-01T11:05:02","guid":{"rendered":"http://ai.foobrdigital.com/?p=3375"},"modified":"2020-12-16T17:04:16","modified_gmt":"2020-12-16T17:04:16","slug":"keras-installation","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-installation/","title":{"rendered":"Installation"},"content":{"rendered":"\n<p>This chapter explains about how to install Keras on your machine. Before moving to installation, let us go through the basic requirements of Keras.</p>\n\n\n\n<h2>Prerequisites</h2>\n\n\n\n<p>You must satisfy the following requirements −</p>\n\n\n\n<ul><li>Any kind of OS (Windows, Linux or Mac)</li><li>Python version 3.5 or higher.</li></ul>\n\n\n\n<h3>Python</h3>\n\n\n\n<p>Keras is python based neural network library so python must be installed on your machine. If python is properly installed on your machine, then open your terminal and type python, you could see the response similar as specified below,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) \n&#91;MSC v.1900 64 bit (AMD64)] on win32 \nType \"help\", \"copyright\", \"credits\" or \"license\" for more information. \n>>>\n</code></pre>\n\n\n\n<p>As of now the latest version is ‘3.7.2’. If Python is not installed, then visit the official python link &#8211; www.python.org and download the latest version based on your OS and install it immediately on your system.</p>\n\n\n\n<h2>Keras Installation Steps</h2>\n\n\n\n<p>Keras installation is quite easy. Follow below steps to properly install Keras on your system.</p>\n\n\n\n<h3>Step 1: Create virtual environment</h3>\n\n\n\n<p><strong>Virtualenv</strong>&nbsp;is used to manage Python packages for different projects. This will be helpful to avoid breaking the packages installed in the other environments. So, it is always recommended to use a virtual environment while developing Python applications.</p>\n\n\n\n<p><strong>Linux/Mac OS</strong></p>\n\n\n\n<p>Linux or mac OS users, go to your project root directory and type the below command to create virtual environment,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python3 -m venv kerasenv\n</code></pre>\n\n\n\n<p>After executing the above command, “kerasenv” directory is created with&nbsp;<strong>bin,lib and include folders</strong>&nbsp;in your installation location.</p>\n\n\n\n<p><strong>Windows</strong></p>\n\n\n\n<p>Windows user can use the below command,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>py -m venv keras\n</code></pre>\n\n\n\n<h3>Step 2: Activate the environment</h3>\n\n\n\n<p>This step will configure python and pip executables in your shell path.</p>\n\n\n\n<p><strong>Linux/Mac OS</strong></p>\n\n\n\n<p>Now we have created a virtual environment named “kerasvenv”. Move to the folder and type the below command,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>$ cd kerasvenv kerasvenv $ source bin/activate\n</code></pre>\n\n\n\n<p><strong>Windows</strong></p>\n\n\n\n<p>Windows users move inside the “kerasenv” folder and type the below command,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>.\\env\\Scripts\\activate\n</code></pre>\n\n\n\n<h3>Step 3: Python libraries</h3>\n\n\n\n<p>Keras depends on the following python libraries.</p>\n\n\n\n<ul><li>Numpy</li><li>Pandas</li><li>Scikit-learn</li><li>Matplotlib</li><li>Scipy</li><li>Seaborn</li></ul>\n\n\n\n<p>Hopefully, you have installed all the above libraries on your system. If these libraries are not installed, then use the below command to install one by one.</p>\n\n\n\n<p><strong>numpy</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install numpy\n</code></pre>\n\n\n\n<p>you could see the following response,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Collecting numpy \n   Downloading \nhttps:&#47;&#47;files.pythonhosted.org/packages/cf/a4/d5387a74204542a60ad1baa84cd2d3353c330e59be8cf2d47c0b11d3cde8/ \n   numpy-3.1.1-cp36-cp36m-macosx_10_6_intel.\nmacosx_10_9_intel.macosx_10_9_x86_64. \n   macosx_10_10_intel.macosx_10_10_x86_64.whl (14.4MB) \n      |████████████████████████████████| 14.4MB 2.8MB/s\n</code></pre>\n\n\n\n<p><strong>pandas</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install pandas\n</code></pre>\n\n\n\n<p>We could see the following response,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Collecting pandas \n   Downloading \nhttps:&#47;&#47;files.pythonhosted.org/packages/cf/a4/d5387a74204542a60ad1baa84cd2d3353c330e59be8cf2d47c0b11d3cde8/ \npandas-3.1.1-cp36-cp36m-macosx_10_6_intel.\nmacosx_10_9_intel.macosx_10_9_x86_64. \n   macosx_10_10_intel.macosx_10_10_x86_64.whl (14.4MB) \n      |████████████████████████████████| 14.4MB 2.8MB/s\n</code></pre>\n\n\n\n<p><strong>matplotlib</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install matplotlib</code></pre>\n\n\n\n<p>We could see the following response,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Collecting matplotlib \n   Downloading \nhttps:&#47;&#47;files.pythonhosted.org/packages/cf/a4/d5387a74204542a60ad1baa84cd2d3353c330e59be8cf2d47c0b11d3cde8/ \nmatplotlib-3.1.1-cp36-cp36m-macosx_10_6_intel.\nmacosx_10_9_intel.macosx_10_9_x86_64. \n   macosx_10_10_intel.macosx_10_10_x86_64.whl (14.4MB) \n      |████████████████████████████████| 14.4MB 2.8MB/s\n</code></pre>\n\n\n\n<p><strong>scipy</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install scipy\n</code></pre>\n\n\n\n<p>We could see the following response,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Collecting scipy \n   Downloading \nhttps:&#47;&#47;files.pythonhosted.org/packages/cf/a4/d5387a74204542a60ad1baa84cd2d3353c330e59be8cf2d47c0b11d3cde8 \n/scipy-3.1.1-cp36-cp36m-macosx_10_6_intel.\nmacosx_10_9_intel.macosx_10_9_x86_64. \n   macosx_10_10_intel.macosx_10_10_x86_64.whl (14.4MB) \n      |████████████████████████████████| 14.4MB 2.8MB/s\n</code></pre>\n\n\n\n<p><strong>scikit-learn</strong></p>\n\n\n\n<p>It is an open source machine learning library. It is used for classification, regression and clustering algorithms. Before moving to the installation, it requires the following −</p>\n\n\n\n<ul><li>Python version 3.5 or higher</li><li>NumPy version 1.11.0 or higher</li><li>SciPy version 0.17.0 or higher</li><li>joblib 0.11 or higher.</li></ul>\n\n\n\n<p>Now, we install scikit-learn using the below command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install -U scikit-learn\n</code></pre>\n\n\n\n<p><strong>Seaborn</strong></p>\n\n\n\n<p>Seaborn is an amazing library that allows you to easily visualize your data. Use the below command to install −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip pip install seaborninstall -U scikit-learn\n</code></pre>\n\n\n\n<p>You could see the message similar as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Collecting seaborn \n   Downloading \nhttps:&#47;&#47;files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc \n/seaborn-0.9.0-py3-none-any.whl (208kB) 100% \n   |████████████████████████████████| 215kB 4.0MB/s \nRequirement already satisfied: numpy> = 1.9.3 in \n./lib/python3.7/site-packages (from seaborn) (1.17.0) \nCollecting pandas> = 0.15.2 (from seaborn) \n   Downloading \nhttps://files.pythonhosted.org/packages/39/b7/441375a152f3f9929ff8bc2915218ff1a063a59d7137ae0546db616749f9/ \npandas-0.25.0-cp37-cp37m-macosx_10_9_x86_64.\nmacosx_10_10_x86_64.whl (10.1MB) 100% \n   |████████████████████████████████| 10.1MB 1.8MB/s \nRequirement already satisfied: scipy>=0.14.0 in \n./lib/python3.7/site-packages (from seaborn) (1.3.0) \nCollecting matplotlib> = 1.4.3 (from seaborn) \n   Downloading \nhttps://files.pythonhosted.org/packages/c3/8b/af9e0984f\n5c0df06d3fab0bf396eb09cbf05f8452de4e9502b182f59c33b/ \nmatplotlib-3.1.1-cp37-cp37m-macosx_10_6_intel.\nmacosx_10_9_intel.macosx_10_9_x86_64 \n.macosx_10_10_intel.macosx_10_10_x86_64.whl (14.4MB) 100% \n   |████████████████████████████████| 14.4MB 1.4MB/s \n...................................... \n...................................... \nSuccessfully installed cycler-0.10.0 kiwisolver-1.1.0 \nmatplotlib-3.1.1 pandas-0.25.0 pyparsing-2.4.2 \npython-dateutil-2.8.0 pytz-2019.2 seaborn-0.9.0\n</code></pre>\n\n\n\n<h2>Keras Installation Using Python</h2>\n\n\n\n<p>As of now, we have completed basic requirements for the installtion of Kera. Now, install the Keras using same procedure as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install keras\n</code></pre>\n\n\n\n<h3>Quit virtual environment</h3>\n\n\n\n<p>After finishing all your changes in your project, then simply run the below command to quit the environment −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>deactivate\n</code></pre>\n\n\n\n<h2>Anaconda Cloud</h2>\n\n\n\n<p>We believe that you have installed anaconda cloud on your machine. If anaconda is not installed, then visit the official link, www.anaconda.com/distribution and choose download based on your OS.</p>\n\n\n\n<h3>Create a new conda environment</h3>\n\n\n\n<p>Launch anaconda prompt, this will open base Anaconda environment. Let us create a new conda environment. This process is similar to virtualenv. Type the below command in your conda terminal −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>conda create --name PythonCPU\n</code></pre>\n\n\n\n<p>If you want, you can create and install modules using GPU also. In this tutorial, we follow CPU instructions.</p>\n\n\n\n<h3>Activate conda environment</h3>\n\n\n\n<p>To activate the environment, use the below command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>activate PythonCPU\n</code></pre>\n\n\n\n<h3>Install spyder</h3>\n\n\n\n<p>Spyder is an IDE for executing python applications. Let us install this IDE in our conda environment using the below command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>conda install spyder\n</code></pre>\n\n\n\n<h3>Install python libraries</h3>\n\n\n\n<p>We have already known the python libraries numpy, pandas, etc., needed for keras. You can install all the modules by using the below syntax −</p>\n\n\n\n<p><strong>Syntax</strong></p>\n\n\n\n<pre class=\"wp-block-code\"><code>conda install -c anaconda &lt;module-name>\n</code></pre>\n\n\n\n<p>For example, you want to install pandas −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>conda install -c anaconda pandas\n</code></pre>\n\n\n\n<p>Like the same method, try it yourself to install the remaining modules.</p>\n\n\n\n<h3>Install Keras</h3>\n\n\n\n<p>Now, everything looks good so you can start keras installation using the below command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>conda install -c anaconda keras\n</code></pre>\n\n\n\n<h3>Launch spyder</h3>\n\n\n\n<p>Finally, launch spyder in your conda terminal using the below command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>spyder\n</code></pre>\n\n\n\n<p>To ensure everything was installed correctly, import all the modules, it will add everything and if anything went wrong, you will get&nbsp;<strong>module not found</strong>&nbsp;error message.</p>\n","protected":false},"excerpt":{"rendered":"<p>This chapter explains about how to install Keras on your machine. Before moving to installation, let us go through the basic requirements of Keras. Prerequisites You must satisfy the following requirements − Any kind of OS (Windows, Linux or Mac) Python version 3.5 or higher. Python Keras is python based neural network library so python [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3375"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3375"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3375/revisions"}],"predecessor-version":[{"id":4245,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3375/revisions/4245"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3375"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3375"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3375"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3377,"date":"2020-10-01T11:07:01","date_gmt":"2020-10-01T11:07:01","guid":{"rendered":"http://ai.foobrdigital.com/?p=3377"},"modified":"2020-12-16T17:04:16","modified_gmt":"2020-12-16T17:04:16","slug":"keras-backend-configuration","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-backend-configuration/","title":{"rendered":"Backend Configuration"},"content":{"rendered":"\n<p>This chapter explains Keras backend implementations TensorFlow and Theano in detail. Let us go through each implementation one by one.</p>\n\n\n\n<h2>TensorFlow</h2>\n\n\n\n<p>TensorFlow is an open source machine learning library used for numerical computational tasks developed by Google. Keras is a high level API built on top of TensorFlow or Theano. We know already how to install TensorFlow using pip.</p>\n\n\n\n<p>If it is not installed, you can install using the below command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install TensorFlow\n</code></pre>\n\n\n\n<p>Once we execute keras, we could see the configuration file is located at your home directory inside and go to .keras/keras.json.</p>\n\n\n\n<h3>keras.json</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>{ \n   \"image_data_format\": \"channels_last\", \n   \"epsilon\": 1e-07, \"floatx\": \"float32\", \"backend\": \"tensorflow\" \n}\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>image_data_format</strong>&nbsp;represent the data format.</li><li><strong>epsilon</strong>&nbsp;represents numeric constant. It is used to avoid&nbsp;<strong>DivideByZero</strong>&nbsp;error.</li><li><strong>float</strong>x represent the default data type&nbsp;<strong>float32</strong>. You can also change it to&nbsp;<strong>float16</strong>&nbsp;or&nbsp;<strong>float64</strong>&nbsp;using&nbsp;<strong>set_floatx()</strong>&nbsp;method.</li><li><strong>image_data_format</strong>&nbsp;represent the data format.</li></ul>\n\n\n\n<p>Suppose, if the file is not created then move to the location and create using the below steps −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>> cd home \n> mkdir .keras \n> vi keras.json\n</code></pre>\n\n\n\n<p>Remember, you should specify .keras as its folder name and add the above configuration inside keras.json file. We can perform some pre-defined operations to know backend functions.</p>\n\n\n\n<h2>Theano</h2>\n\n\n\n<p>Theano is an open source deep learning library that allows you to evaluate multi-dimensional arrays effectively. We can easily install using the below command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install theano\n</code></pre>\n\n\n\n<p>By default, keras uses TensorFlow backend. If you want to change backend configuration from TensorFlow to Theano, just change the backend = theano in keras.json file. It is described below −</p>\n\n\n\n<h3>keras.json</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>{ \n   \"image_data_format\": \"channels_last\", \n   \"epsilon\": 1e-07, \n   \"floatx\": \"float32\", \n   \"backend\": \"theano\" \n}\n</code></pre>\n\n\n\n<p>Now save your file, restart your terminal and start keras, your backend will be changed.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> import keras as k \nusing theano backend.</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>This chapter explains Keras backend implementations TensorFlow and Theano in detail. Let us go through each implementation one by one. TensorFlow TensorFlow is an open source machine learning library used for numerical computational tasks developed by Google. Keras is a high level API built on top of TensorFlow or Theano. We know already how to [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3377"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3377"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3377/revisions"}],"predecessor-version":[{"id":4244,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3377/revisions/4244"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3377"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3377"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3377"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3379,"date":"2020-10-01T11:07:51","date_gmt":"2020-10-01T11:07:51","guid":{"rendered":"http://ai.foobrdigital.com/?p=3379"},"modified":"2020-12-16T17:04:16","modified_gmt":"2020-12-16T17:04:16","slug":"keras-overview-of-deep-learning","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-overview-of-deep-learning/","title":{"rendered":"Overview of Deep learning"},"content":{"rendered":"\n<p>Deep learning is an evolving subfield of machine learning. Deep learning involves analyzing the input in layer by layer manner, where each layer progressively extracts higher level information about the input.</p>\n\n\n\n<p>Let us take a simple scenario of analyzing an image. Let us assume that your input image is divided up into a rectangular grid of pixels. Now, the first layer abstracts the pixels. The second layer understands the edges in the image. The Next layer constructs nodes from the edges. Then, the next would find branches from the nodes. Finally, the output layer will detect the full object. Here, the feature extraction process goes from the output of one layer into the input of the next subsequent layer.</p>\n\n\n\n<p>By using this approach, we can process huge amount of features, which makes deep learning a very powerful tool. Deep learning algorithms are also useful for the analysis of unstructured data. Let us go through the basics of deep learning in this chapter.</p>\n\n\n\n<h2>Artificial Neural Networks</h2>\n\n\n\n<p>The most popular and primary approach of deep learning is using “Artificial neural network” (ANN). They are inspired from the model of human brain, which is the most complex organ of our body. The human brain is made up of more than 90 billion tiny cells called “Neurons”. Neurons are inter-connected through nerve fiber called “axons” and “Dendrites”. The main role of axon is to transmit information from one neuron to another to which it is connected.</p>\n\n\n\n<p>Similarly, the main role of dendrites is to receive the information being transmitted by the axons of another neuron to which it is connected. Each neuron processes a small information and then passes the result to another neuron and this process continues. This is the basic method used by our human brain to process huge about of information like speech, visual, etc., and extract useful information from it.</p>\n\n\n\n<p>Based on this model, the first Artificial Neural Network (ANN) was invented by psychologist&nbsp;<strong>Frank Rosenblatt</strong>, in the year of 1958. ANNs are made up of multiple nodes which is similar to neurons. Nodes are tightly interconnected and organized into different hidden layers. The input layer receives the input data and the data goes through one or more hidden layers sequentially and finally the output layer predict something useful about the input data. For example, the input may be an image and the output may be the thing identified in the image, say a “Cat”.</p>\n\n\n\n<p>A single neuron (called as perceptron in ANN) can be represented as below −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/artificial_neural_networks.jpg\" alt=\"Artificial Neural Networks\"/></figure>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li>Multiple input along with weight represents dendrites.</li><li>Sum of input along with activation function represents neurons.&nbsp;<strong>Sum</strong>&nbsp;actually means computed value of all inputs and activation function represent a function, which modify the&nbsp;<strong>Sum</strong>&nbsp;value into 0, 1 or 0 to 1.</li><li>Actual output represent axon and the output will be received by neuron in next layer.</li></ul>\n\n\n\n<p>Let us understand different types of artificial neural networks in this section.</p>\n\n\n\n<h2>Multi-Layer Perceptron</h2>\n\n\n\n<p>Multi-Layer perceptron is the simplest form of ANN. It consists of a single input layer, one or more hidden layer and finally an output layer. A layer consists of a collection of perceptron. Input layer is basically one or more features of the input data. Every hidden layer consists of one or more neurons and process certain aspect of the feature and send the processed information into the next hidden layer. The output layer process receives the data from last hidden layer and finally output the result.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/multi_layer_perceptron.jpg\" alt=\"Multi-Layer Perceptron\"/></figure>\n\n\n\n<h2>Convolutional Neural Network (CNN)</h2>\n\n\n\n<p>Convolutional neural network is one of the most popular ANN. It is widely used in the fields of image and video recognition. It is based on the concept of convolution, a mathematical concept. It is almost similar to multi-layer perceptron except it contains series of convolution layer and pooling layer before the fully connected hidden neuron layer. It has three important layers −</p>\n\n\n\n<ul><li><strong>Convolution layer</strong>&nbsp;− It is the primary building block and perform computational tasks based on convolution function.</li><li><strong>Pooling layer</strong>&nbsp;− It is arranged next to convolution layer and is used to reduce the size of inputs by removing unnecessary information so computation can be performed faster.</li><li><strong>Fully connected layer</strong>&nbsp;− It is arranged to next to series of convolution and pooling layer and classify input into various categories.</li></ul>\n\n\n\n<p>A simple CNN can be represented as below −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/cnn.jpg\" alt=\"CNN\"/></figure>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li>2 series of Convolution and pooling layer is used and it receives and process the input (e.g. image).</li><li>A single fully connected layer is used and it is used to output the data (e.g. classification of image)</li></ul>\n\n\n\n<h2>Recurrent Neural Network (RNN)</h2>\n\n\n\n<p>Recurrent Neural Networks (RNN) are useful to address the flaw in other ANN models. Well, Most of the ANN doesn’t remember the steps from previous situations and learned to make decisions based on context in training. Meanwhile, RNN stores the past information and all its decisions are taken from what it has learnt from the past.</p>\n\n\n\n<p>This approach is mainly useful in image classification. Sometimes, we may need to look into the future to fix the past. In this case bidirectional RNN is helpful to learn from the past and predict the future. For example, we have handwritten samples in multiple inputs. Suppose, we have confusion in one input then we need to check again other inputs to recognize the correct context which takes the decision from the past.</p>\n\n\n\n<h2>Workflow of ANN</h2>\n\n\n\n<p>Let us first understand the different phases of deep learning and then, learn how Keras helps in the process of deep learning.</p>\n\n\n\n<h3>Collect required data</h3>\n\n\n\n<p>Deep learning requires lot of input data to successfully learn and predict the result. So, first collect as much data as possible.</p>\n\n\n\n<h3>Analyze data</h3>\n\n\n\n<p>Analyze the data and acquire a good understanding of the data. The better understanding of the data is required to select the correct ANN algorithm.</p>\n\n\n\n<h3>Choose an algorithm (model)</h3>\n\n\n\n<p>Choose an algorithm, which will best fit for the type of learning process (e.g image classification, text processing, etc.,) and the available input data. Algorithm is represented by&nbsp;<strong>Model</strong>&nbsp;in Keras. Algorithm includes one or more layers. Each layers in ANN can be represented by&nbsp;<strong>Keras Layer</strong>&nbsp;in Keras.</p>\n\n\n\n<ul><li><strong>Prepare data</strong>&nbsp;− Process, filter and select only the required information from the data.</li><li><strong>Split data</strong>&nbsp;− Split the data into training and test data set. Test data will be used to evaluate the prediction of the algorithm / Model (once the machine learn) and to cross check the efficiency of the learning process.</li><li><strong>Compile the model</strong>&nbsp;− Compile the algorithm / model, so that, it can be used further to learn by training and finally do to prediction. This step requires us to choose loss function and Optimizer. loss function and Optimizer are used in learning phase to find the error (deviation from actual output) and do optimization so that the error will be minimized.</li><li><strong>Fit the model</strong>&nbsp;− The actual learning process will be done in this phase using the training data set.</li><li><strong>Predict result for unknown value</strong>&nbsp;− Predict the output for the unknown input data (other than existing training and test data)</li><li><strong>Evaluate model</strong>&nbsp;− Evaluate the model by predicting the output for test data and cross-comparing the prediction with actual result of the test data.</li><li><strong>Freeze, Modify or choose new algorithm</strong>&nbsp;− Check whether the evaluation of the model is successful. If yes, save the algorithm for future prediction purpose. If not, then modify or choose new algorithm / model and finally, again train, predict and evaluate the model. Repeat the process until the best algorithm (model) is found.</li></ul>\n\n\n\n<p>The above steps can be represented using below flow chart −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/ann.jpg\" alt=\"ANN\"/></figure>\n","protected":false},"excerpt":{"rendered":"<p>Deep learning is an evolving subfield of machine learning. Deep learning involves analyzing the input in layer by layer manner, where each layer progressively extracts higher level information about the input. Let us take a simple scenario of analyzing an image. Let us assume that your input image is divided up into a rectangular grid [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3379"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3379"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3379/revisions"}],"predecessor-version":[{"id":4243,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3379/revisions/4243"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3379"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3379"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3379"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3381,"date":"2020-10-01T11:09:05","date_gmt":"2020-10-01T11:09:05","guid":{"rendered":"http://ai.foobrdigital.com/?p=3381"},"modified":"2020-12-16T17:04:16","modified_gmt":"2020-12-16T17:04:16","slug":"keras-deep-learning","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-deep-learning/","title":{"rendered":"Deep learning"},"content":{"rendered":"\n<p>Keras provides a complete framework to create any type of neural networks. Keras is innovative as well as very easy to learn. It supports simple neural network to very large and complex neural network model. Let us understand the architecture of Keras framework and how Keras helps in deep learning in this chapter.</p>\n\n\n\n<h2>Architecture of Keras</h2>\n\n\n\n<p>Keras API can be divided into three main categories −</p>\n\n\n\n<ul><li>Model</li><li>Layer</li><li>Core Modules</li></ul>\n\n\n\n<p>In Keras, every ANN is represented by&nbsp;<strong>Keras Models</strong>. In turn, every Keras Model is composition of&nbsp;<strong>Keras Layers</strong>&nbsp;and represents ANN layers like input, hidden layer, output layers, convolution layer, pooling layer, etc., Keras model and layer access&nbsp;<strong>Keras modules</strong>&nbsp;for activation function, loss function, regularization function, etc., Using Keras model, Keras Layer, and Keras modules, any ANN algorithm (CNN, RNN, etc.,) can be represented in a simple and efficient manner.</p>\n\n\n\n<p>The following diagram depicts the relationship between model, layer and core modules −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/architecture_of_keras.jpg\" alt=\"Architecture of Keras\"/></figure>\n\n\n\n<p>Let us see the overview of Keras models, Keras layers and Keras modules.</p>\n\n\n\n<h2>Model</h2>\n\n\n\n<p>Keras Models are of two types as mentioned below −</p>\n\n\n\n<p><strong>Sequential Model</strong>&nbsp;− Sequential model is basically a linear composition of Keras Layers. Sequential model is easy, minimal as well as has the ability to represent nearly all available neural networks.</p>\n\n\n\n<p>A simple sequential model is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Dense, Activation \n\nmodel = Sequential()  \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,)))\n</code></pre>\n\n\n\n<p>Where,</p>\n\n\n\n<ul><li><strong>Line 1</strong>&nbsp;imports&nbsp;<strong>Sequential</strong>&nbsp;model from Keras models</li><li><strong>Line 2</strong>&nbsp;imports&nbsp;<strong>Dense</strong>&nbsp;layer and&nbsp;<strong>Activation</strong>&nbsp;module</li><li><strong>Line 4</strong>&nbsp;create a new sequential model using&nbsp;<strong>Sequential</strong>&nbsp;API</li><li><strong>Line 5</strong>&nbsp;adds a dense layer (Dense API) with&nbsp;<strong>relu</strong>&nbsp;activation (using Activation module) function.</li></ul>\n\n\n\n<p><strong>Sequential</strong>&nbsp;model exposes&nbsp;<strong>Model</strong>&nbsp;class to create customized models as well. We can use sub-classing concept to create our own complex model.</p>\n\n\n\n<p><strong>Functional API</strong>&nbsp;− Functional API is basically used to create complex models.</p>\n\n\n\n<h2>Layer</h2>\n\n\n\n<p>Each Keras layer in the Keras model represent the corresponding layer (input layer, hidden layer and output layer) in the actual proposed neural network model. Keras provides a lot of pre-build layers so that any complex neural network can be easily created. Some of the important Keras layers are specified below,</p>\n\n\n\n<ul><li>Core Layers</li><li>Convolution Layers</li><li>Pooling Layers</li><li>Recurrent Layers</li></ul>\n\n\n\n<p>A simple python code to represent a neural network model using&nbsp;<strong>sequential</strong>&nbsp;model is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Dense, Activation, Dropout model = Sequential() \n\nmodel.add(Dense(512, activation = 'relu', input_shape = (784,))) \nmodel.add(Dropout(0.2)) \nmodel.add(Dense(512, activation = 'relu')) model.add(Dropout(0.2)) \nmodel.add(Dense(num_classes, activation = 'softmax'))\n</code></pre>\n\n\n\n<p>Where,</p>\n\n\n\n<ul><li><strong>Line 1</strong>&nbsp;imports&nbsp;<strong>Sequential</strong>&nbsp;model from Keras models</li><li><strong>Line 2</strong>&nbsp;imports&nbsp;<strong>Dense</strong>&nbsp;layer and&nbsp;<strong>Activation</strong>&nbsp;module</li><li><strong>Line 4</strong>&nbsp;create a new sequential model using&nbsp;<strong>Sequential</strong>&nbsp;API</li><li><strong>Line 5</strong>&nbsp;adds a dense layer (Dense API) with&nbsp;<strong>relu</strong>&nbsp;activation (using Activation module) function.</li><li><strong>Line 6</strong>&nbsp;adds a dropout layer (Dropout API) to handle over-fitting.</li><li><strong>Line 7</strong>&nbsp;adds another dense layer (Dense API) with&nbsp;<strong>relu</strong>&nbsp;activation (using Activation module) function.</li><li><strong>Line 8</strong>&nbsp;adds another dropout layer (Dropout API) to handle over-fitting.</li><li><strong>Line 9</strong>&nbsp;adds final dense layer (Dense API) with&nbsp;<strong>softmax</strong>&nbsp;activation (using Activation module) function.</li></ul>\n\n\n\n<p>Keras also provides options to create our own customized layers. Customized layer can be created by sub-classing the&nbsp;<strong>Keras.Layer</strong>&nbsp;class and it is similar to sub-classing Keras models.</p>\n\n\n\n<h2>Core Modules</h2>\n\n\n\n<p>Keras also provides a lot of built-in neural network related functions to properly create the Keras model and Keras layers. Some of the function are as follows −</p>\n\n\n\n<ul><li><strong>Activations module</strong>&nbsp;− Activation function is an important concept in ANN and activation modules provides many activation function like softmax, relu, etc.,</li><li><strong>Loss module</strong>&nbsp;− Loss module provides loss functions like mean_squared_error, mean_absolute_error, poisson, etc.,</li><li><strong>Optimizer module</strong>&nbsp;− Optimizer module provides optimizer function like adam, sgd, etc.,</li><li><strong>Regularizers</strong>&nbsp;− Regularizer module provides functions like L1 regularizer, L2 regularizer, etc.,</li></ul>\n\n\n\n<p>Let us learn Keras modules in detail in the upcoming chapter.</p>\n","protected":false},"excerpt":{"rendered":"<p>Keras provides a complete framework to create any type of neural networks. Keras is innovative as well as very easy to learn. It supports simple neural network to very large and complex neural network model. Let us understand the architecture of Keras framework and how Keras helps in deep learning in this chapter. Architecture of [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3381"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3381"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3381/revisions"}],"predecessor-version":[{"id":4242,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3381/revisions/4242"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3381"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3381"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3381"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3383,"date":"2020-10-01T11:11:52","date_gmt":"2020-10-01T11:11:52","guid":{"rendered":"http://ai.foobrdigital.com/?p=3383"},"modified":"2020-12-16T17:04:16","modified_gmt":"2020-12-16T17:04:16","slug":"keras-modules","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-modules/","title":{"rendered":"Modules"},"content":{"rendered":"\n<p>As we learned earlier, Keras modules contains pre-defined classes, functions and variables which are useful for deep learning algorithm. Let us learn the modules provided by Keras in this chapter.</p>\n\n\n\n<h2>Available modules</h2>\n\n\n\n<p>Let us first see the list of modules available in the Keras.</p>\n\n\n\n<ul><li><strong>Initializers</strong>&nbsp;− Provides a list of initializers function. We can learn it in details in Keras&nbsp;<em>layer chapter</em>. during model creation phase of machine learning.</li><li><strong>Regularizers</strong>&nbsp;− Provides a list of regularizers function. We can learn it in details in&nbsp;<em>Keras Layers</em>&nbsp;chapter.</li><li><strong>Constraints</strong>&nbsp;− Provides a list of constraints function. We can learn it in details in&nbsp;<em>Keras Layers</em>&nbsp;chapter.</li><li><strong>Activations</strong>&nbsp;− Provides a list of activator function. We can learn it in details in&nbsp;<em>Keras Layers</em>&nbsp;chapter.</li><li><strong>Losses</strong>&nbsp;− Provides a list of loss function. We can learn it in details in&nbsp;<em>Model Training</em>&nbsp;chapter.</li><li><strong>Metrics</strong>&nbsp;− Provides a list of metrics function. We can learn it in details in&nbsp;<em>Model Training</em>&nbsp;chapter.</li><li><strong>Optimizers</strong>&nbsp;− Provides a list of optimizer function. We can learn it in details in&nbsp;<em>Model Training</em>&nbsp;chapter.</li><li><strong>Callback</strong>&nbsp;− Provides a list of callback function. We can use it during the training process to print the intermediate data as well as to stop the training itself (<strong>EarlyStopping</strong>&nbsp;method) based on some condition.</li><li><strong>Text processing</strong>&nbsp;− Provides functions to convert text into NumPy array suitable for machine learning. We can use it in data preparation phase of machine learning.</li><li><strong>Image processing</strong>&nbsp;− Provides functions to convert images into NumPy array suitable for machine learning. We can use it in data preparation phase of machine learning.</li><li><strong>Sequence processing</strong>&nbsp;− Provides functions to generate time based data from the given input data. We can use it in data preparation phase of machine learning.</li><li><strong>Backend</strong>&nbsp;− Provides function of the backend library like&nbsp;<em>TensorFlow</em>&nbsp;and&nbsp;<em>Theano</em>.</li><li><strong>Utilities</strong>&nbsp;− Provides lot of utility function useful in deep learning.</li></ul>\n\n\n\n<p>Let us see&nbsp;<strong>backend</strong>&nbsp;module and&nbsp;<strong>utils</strong>&nbsp;model in this chapter.</p>\n\n\n\n<h2><em>backend</em>&nbsp;module</h2>\n\n\n\n<p><strong><em>backend</em>&nbsp;module</strong>&nbsp;is used for keras backend operations. By default, keras runs on top of TensorFlow backend. If you want, you can switch to other backends like Theano or CNTK. Defualt backend configuration is defined inside your root directory under .keras/keras.json file.</p>\n\n\n\n<p>Keras&nbsp;<em>backend</em>&nbsp;module can be imported using below code</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> from keras import backend as k\n</code></pre>\n\n\n\n<p>If we are using default backend&nbsp;<em>TensorFlow</em>, then the below function returns&nbsp;<em>TensorFlow</em>&nbsp;based information as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> k.backend() \n'tensorflow'\n>>> k.epsilon() \n1e-07\n>>> k.image_data_format() \n'channels_last'\n>>> k.floatx() \n'float32'</code></pre>\n\n\n\n<p>Let us understand some of the significant backend functions used for data analysis in brief −</p>\n\n\n\n<h3>get_uid()</h3>\n\n\n\n<p>It is the identifier for the default graph. It is defined below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> k.get_uid(prefix='') \n1 \n>>> k.get_uid(prefix='') 2\n</code></pre>\n\n\n\n<h3>reset_uids</h3>\n\n\n\n<p>It is used resets the uid value.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> k.reset_uids()\n</code></pre>\n\n\n\n<p>Now, again execute the&nbsp;<em>get_uid()</em>. This will be reset and change again to 1.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> k.get_uid(prefix='') \n1\n</code></pre>\n\n\n\n<h3>placeholder</h3>\n\n\n\n<p>It is used instantiates a placeholder tensor. Simple placeholder to hold 3-D shape is shown below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> data = k.placeholder(shape = (1,3,3)) \n>>> data \n&lt;tf.Tensor 'Placeholder_9:0' shape = (1, 3, 3) dtype = float32> \n\nIf you use int_shape(), it will show the shape. \n\n>>> k.int_shape(data) (1, 3, 3)</code></pre>\n\n\n\n<h3>dot</h3>\n\n\n\n<p>It is used to multiply two tensors. Consider a and b are two tensors and c will be the outcome of multiply of ab. Assume a shape is (4,2) and b shape is (2,3). It is defined below,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> a = k.placeholder(shape = (4,2)) \n>>> b = k.placeholder(shape = (2,3)) \n>>> c = k.dot(a,b) \n>>> c \n&lt;tf.Tensor 'MatMul_3:0' shape = (4, 3) dtype = float32> \n>>></code></pre>\n\n\n\n<h3>ones</h3>\n\n\n\n<p>It is used to initialize all as&nbsp;<strong>one</strong>&nbsp;value.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> res = k.ones(shape = (2,2)) \n\n#print the value \n\n>>> k.eval(res) \narray(&#91;&#91;1., 1.], &#91;1., 1.]], dtype = float32)</code></pre>\n\n\n\n<h3>batch_dot</h3>\n\n\n\n<p>It is used to perform the product of two data in batches. Input dimension must be 2 or higher. It is shown below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> a_batch = k.ones(shape = (2,3)) \n>>> b_batch = k.ones(shape = (3,2)) \n>>> c_batch = k.batch_dot(a_batch,b_batch) \n>>> c_batch \n&lt;tf.Tensor 'ExpandDims:0' shape = (2, 1) dtype = float32></code></pre>\n\n\n\n<h3>variable</h3>\n\n\n\n<p>It is used to initializes a variable. Let us perform simple transpose operation in this variable.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> data = k.variable(&#91;&#91;10,20,30,40],&#91;50,60,70,80]]) \n#variable initialized here \n>>> result = k.transpose(data) \n>>> print(result) \nTensor(\"transpose_6:0\", shape = (4, 2), dtype = float32) \n>>> print(k.eval(result)) \n   &#91;&#91;10. 50.] \n   &#91;20. 60.] \n   &#91;30. 70.] \n   &#91;40. 80.]]</code></pre>\n\n\n\n<p>If you want to access from numpy −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> data = np.array(&#91;&#91;10,20,30,40],&#91;50,60,70,80]]) \n\n>>> print(np.transpose(data)) \n   &#91;&#91;10 50] \n   &#91;20 60] \n   &#91;30 70] \n   &#91;40 80]] \n\n>>> res = k.variable(value = data) \n>>> print(res) \n&lt;tf.Variable 'Variable_7:0' shape = (2, 4) dtype = float32_ref></code></pre>\n\n\n\n<h3>is_sparse(tensor)</h3>\n\n\n\n<p>It is used to check whether the tensor is sparse or not.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> a = k.placeholder((2, 2), sparse=True) \n\n>>> print(a) SparseTensor(indices =       \n   Tensor(\"Placeholder_8:0\", \n   shape = (?, 2), dtype = int64), \nvalues = Tensor(\"Placeholder_7:0\", shape = (?,), \ndtype = float32), dense_shape = Tensor(\"Const:0\", shape = (2,), dtype = int64)) \n\n>>> print(k.is_sparse(a)) True</code></pre>\n\n\n\n<h3>to_dense()</h3>\n\n\n\n<p>It is used to converts sparse into dense.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> b = k.to_dense(a) \n>>> print(b) Tensor(\"SparseToDense:0\", shape = (2, 2), dtype = float32) \n>>> print(k.is_sparse(b)) False</code></pre>\n\n\n\n<h3>random_uniform_variable</h3>\n\n\n\n<p>It is used to initialize using&nbsp;<strong><em>uniform distribution</em></strong>&nbsp;concept.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>k.random_uniform_variable(shape, mean, scale)\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>shape</strong>&nbsp;− denotes the rows and columns in the format of tuples.</li><li><strong>mean</strong>&nbsp;− mean of uniform distribution.</li><li><strong>scale</strong>&nbsp;− standard deviation of uniform distribution.</li></ul>\n\n\n\n<p>Let us have a look at the below example usage −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> a = k.random_uniform_variable(shape = (2, 3), low=0, high = 1) \n>>> b = k. random_uniform_variable(shape = (3,2), low = 0, high = 1) \n>>> c = k.dot(a, b) \n>>> k.int_shape(c) \n(2, 2)\n</code></pre>\n\n\n\n<h2>utils module</h2>\n\n\n\n<p><strong><em>utils</em></strong>&nbsp;provides useful utilities function for deep learning. Some of the methods provided by the&nbsp;<strong><em>utils</em></strong>&nbsp;module is as follows −</p>\n\n\n\n<h3>HDF5Matrix</h3>\n\n\n\n<p>It is used to represent the input data in HDF5 format.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.utils import HDF5Matrix data = HDF5Matrix('data.hdf5', 'data')\n</code></pre>\n\n\n\n<h3>to_categorical</h3>\n\n\n\n<p>It is used to convert class vector into binary class matrix.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> from keras.utils import to_categorical \n>>> labels = &#91;0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \n>>> to_categorical(labels) \narray(&#91;&#91;1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], \n   &#91;0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], \n   &#91;0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], \n   &#91;0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], \n   &#91;0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], \n   &#91;0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], \n   &#91;0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], \n   &#91;0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], \n   &#91;0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], \n   &#91;0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype = float32)\n>>> from keras.utils import normalize \n>>> normalize(&#91;1, 2, 3, 4, 5]) \narray(&#91;&#91;0.13483997, 0.26967994, 0.40451992, 0.53935989, 0.67419986]])\n</code></pre>\n\n\n\n<h3>print_summary</h3>\n\n\n\n<p>It is used to print the summary of the model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.utils import print_summary print_summary(model)\n</code></pre>\n\n\n\n<h3>plot_model</h3>\n\n\n\n<p>It is used to create the model representation in dot format and save it to file.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.utils import plot_model \nplot_model(model,to_file = 'image.png')\n</code></pre>\n\n\n\n<p>This&nbsp;<strong><em>plot_model</em></strong>&nbsp;will generate an image to understand the performance of model.</p>\n","protected":false},"excerpt":{"rendered":"<p>As we learned earlier, Keras modules contains pre-defined classes, functions and variables which are useful for deep learning algorithm. Let us learn the modules provided by Keras in this chapter. Available modules Let us first see the list of modules available in the Keras. Initializers&nbsp;− Provides a list of initializers function. We can learn it [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3383"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3383"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3383/revisions"}],"predecessor-version":[{"id":4241,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3383/revisions/4241"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3383"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3383"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3383"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3385,"date":"2020-10-01T11:19:02","date_gmt":"2020-10-01T11:19:02","guid":{"rendered":"http://ai.foobrdigital.com/?p=3385"},"modified":"2020-12-16T17:04:16","modified_gmt":"2020-12-16T17:04:16","slug":"keras-layers","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-layers/","title":{"rendered":"Layers"},"content":{"rendered":"\n<p>As learned earlier, Keras layers are the primary building block of Keras models. Each layer receives input information, do some computation and finally output the transformed information. The output of one layer will flow into the next layer as its input. Let us learn complete details about layers in this chapter.</p>\n\n\n\n<h2>Introduction</h2>\n\n\n\n<p>A Keras layer requires&nbsp;<strong><em>shape of the input (input_shape)</em></strong>&nbsp;to understand the structure of the input data,&nbsp;<strong><em>initializer</em></strong>&nbsp;to set the weight for each input and finally activators to transform the output to make it non-linear. In between, constraints restricts and specify the range in which the weight of input data to be generated and regularizer will try to optimize the layer (and the model) by dynamically applying the penalties on the weights during optimization process.</p>\n\n\n\n<p>To summarise, Keras layer requires below minimum details to create a complete layer.</p>\n\n\n\n<ul><li>Shape of the input data</li><li>Number of neurons / units in the layer</li><li>Initializers</li><li>Regularizers</li><li>Constraints</li><li>Activations</li></ul>\n\n\n\n<p>Let us understand the basic concept in the next chapter. Before understanding the basic concept, let us create a simple Keras layer using Sequential model API to get the idea of how Keras model and layer works.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \nfrom keras import regularizers \nfrom keras import constraints \n\nmodel = Sequential() \n\nmodel.add(Dense(32, input_shape=(16,), kernel_initializer = 'he_uniform', \n   kernel_regularizer = None, kernel_constraint = 'MaxNorm', activation = 'relu')) \nmodel.add(Dense(16, activation = 'relu')) \nmodel.add(Dense(8))</code></pre>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li><strong>Line 1-5</strong>&nbsp;imports the necessary modules.</li><li><strong>Line 7</strong>&nbsp;creates a new model using Sequential API.</li><li><strong>Line 9</strong>&nbsp;creates a new&nbsp;<strong><em>Dense</em></strong>&nbsp;layer and add it into the model.&nbsp;<strong><em>Dense</em></strong>&nbsp;is an entry level layer provided by Keras, which accepts the number of neurons or units (32) as its required parameter. If the layer is first layer, then we need to provide&nbsp;<strong>Input Shape, (16,)</strong>&nbsp;as well. Otherwise, the output of the previous layer will be used as input of the next layer. All other parameters are optional.<ul><li>First parameter represents the number of units (neurons).</li><li><strong><em>input_shape</em></strong>&nbsp;represent the shape of input data.</li><li><strong><em>kernel_initializer</em></strong>&nbsp;represent initializer to be used.&nbsp;<strong><em>he_uniform</em></strong>&nbsp;function is set as value.</li><li><strong><em>kernel_regularizer</em></strong>&nbsp;represent&nbsp;<strong>regularizer</strong>&nbsp;to be used. None is set as value.</li><li><strong><em>kernel_constraint</em></strong>&nbsp;represent constraint to be used.&nbsp;<strong><em>MaxNorm</em></strong>&nbsp;function is set as value.</li><li><strong><em>activation</em></strong>&nbsp;represent activation to be used. relu function is set as value.</li></ul></li><li><strong>Line 10</strong>&nbsp;creates second&nbsp;<strong><em>Dense</em></strong>&nbsp;layer with 16 units and set&nbsp;<strong><em>relu</em></strong>&nbsp;as the activation function.</li><li><strong>Line 11</strong>&nbsp;creates final Dense layer with 8 units.</li></ul>\n\n\n\n<h2>Basic Concept of Layers</h2>\n\n\n\n<p>Let us understand the basic concept of layer as well as how Keras supports each concept.</p>\n\n\n\n<h3>Input shape</h3>\n\n\n\n<p>In machine learning, all type of input data like text, images or videos will be first converted into array of numbers and then feed into the algorithm. Input numbers may be single dimensional array, two dimensional array (matrix) or multi-dimensional array. We can specify the dimensional information using&nbsp;<strong>shape</strong>, a tuple of integers. For example,&nbsp;<strong>(4,2)</strong>&nbsp;represent matrix with four rows and two columns.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> import numpy as np \n>>> shape = (4, 2) \n>>> input = np.zeros(shape) \n>>> print(input) \n&#91;\n   &#91;0. 0.] \n   &#91;0. 0.] \n   &#91;0. 0.] \n   &#91;0. 0.]\n] \n>>></code></pre>\n\n\n\n<p>Similarly,&nbsp;<strong>(3,4,2)</strong>&nbsp;three dimensional matrix having three collections of 4&#215;2 matrix (two rows and four columns).</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> import numpy as np \n>>> shape = (3, 4, 2) \n>>> input = np.zeros(shape) \n>>> print(input)\n&#91;\n   &#91;&#91;0. 0.] &#91;0. 0.] &#91;0. 0.] &#91;0. 0.]] \n   &#91;&#91;0. 0.] &#91;0. 0.] &#91;0. 0.] &#91;0. 0.]] \n   &#91;&#91;0. 0.] &#91;0. 0.] &#91;0. 0.] &#91;0. 0.]]\n]\n>>></code></pre>\n\n\n\n<p>To create the first layer of the model (or input layer of the model), shape of the input data should be specified.</p>\n\n\n\n<h2>Initializers</h2>\n\n\n\n<p>In Machine Learning, weight will be assigned to all input data.&nbsp;<em><strong>Initializers</strong></em>&nbsp;module provides different functions to set these initial weight. Some of the&nbsp;<em><strong>Keras Initializer</strong></em>&nbsp;function are as follows −</p>\n\n\n\n<h3>Zeros</h3>\n\n\n\n<p>Generates&nbsp;<strong>0</strong>&nbsp;for all input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.Zeros() \nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>Where,&nbsp;<strong><em>kernel_initializer</em></strong>&nbsp;represent the initializer for kernel of the model.</p>\n\n\n\n<h3>Ones</h3>\n\n\n\n<p>Generates&nbsp;<strong>1</strong>&nbsp;for all input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.Ones() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<h3>Constant</h3>\n\n\n\n<p>Generates a constant value (say,&nbsp;<strong>5</strong>) specified by the user for all input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.Constant(value = 0) model.add(\n   Dense(512, activation = 'relu', input_shape = (784,), kernel_initializer = my_init)\n)</code></pre>\n\n\n\n<p>where,&nbsp;<strong>value</strong>&nbsp;represent the constant value</p>\n\n\n\n<h3>RandomNormal</h3>\n\n\n\n<p>Generates value using normal distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.RandomNormal(mean=0.0, \nstddev = 0.05, seed = None) \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li><strong><em>mean</em></strong>&nbsp;represent the mean of the random values to generate</li><li><strong><em>stddev</em></strong>&nbsp;represent the standard deviation of the random values to generate</li><li><strong><em>seed</em></strong>&nbsp;represent the values to generate random number</li></ul>\n\n\n\n<h3>RandomUniform</h3>\n\n\n\n<p>Generates value using uniform distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras import initializers \n\nmy_init = initializers.RandomUniform(minval = -0.05, maxval = 0.05, seed = None) \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li><strong><em>minval</em></strong>&nbsp;represent the lower bound of the random values to generate</li><li><strong><em>maxval</em></strong>&nbsp;represent the upper bound of the random values to generate</li></ul>\n\n\n\n<h3>TruncatedNormal</h3>\n\n\n\n<p>Generates value using truncated normal distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.TruncatedNormal(mean = 0.0, stddev = 0.05, seed = None\nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<h3>VarianceScaling</h3>\n\n\n\n<p>Generates value based on the input shape and output shape of the layer along with the specified scale.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.VarianceScaling(\n   scale = 1.0, mode = 'fan_in', distribution = 'normal', seed = None) \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   skernel_initializer = my_init))</code></pre>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li><strong>scale</strong>&nbsp;represent the scaling factor</li><li><strong>mode</strong>&nbsp;represent any one of&nbsp;<strong>fan_in, fan_out</strong>&nbsp;and&nbsp;<strong>fan_avg</strong>&nbsp;values</li><li><strong>distribution</strong>&nbsp;represent either of&nbsp;<strong>normal</strong>&nbsp;or&nbsp;<strong>uniform</strong></li></ul>\n\n\n\n<h3>VarianceScaling</h3>\n\n\n\n<p>It finds the&nbsp;<strong><em>stddev</em></strong>&nbsp;value for normal distribution using below formula and then find the weights using normal distribution,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>stddev = sqrt(scale / n)\n</code></pre>\n\n\n\n<p>where&nbsp;<strong>n</strong>&nbsp;represent,</p>\n\n\n\n<ul><li>number of input units for mode = fan_in</li><li>number of out units for mode = fan_out</li><li>average number of input and output units for mode = fan_avg</li></ul>\n\n\n\n<p>Similarly, it finds the&nbsp;<em>limit</em>&nbsp;for uniform distribution using below formula and then find the weights using uniform distribution,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>\nlimit = sqrt(3 * scale / n)\n</code></pre>\n\n\n\n<h3>lecun_normal</h3>\n\n\n\n<p>Generates value using lecun normal distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.RandomUniform(minval = -0.05, maxval = 0.05, seed = None)\nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>It finds the&nbsp;<strong><em>stddev</em></strong>&nbsp;using the below formula and then apply normal distribution</p>\n\n\n\n<pre class=\"wp-block-code\"><code>stddev = sqrt(1 / fan_in)\n</code></pre>\n\n\n\n<p>where,&nbsp;<strong><em>fan_in</em></strong>&nbsp;represent the number of input units.</p>\n\n\n\n<h3>lecun_uniform</h3>\n\n\n\n<p>Generates value using lecun uniform distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>limit = sqrt(3 / fan_in)from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.lecun_uniform(seed = None) \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>It finds the&nbsp;<strong><em>limit</em></strong>&nbsp;using the below formula and then apply uniform distribution</p>\n\n\n\n<pre class=\"wp-block-code\"><code>limit = sqrt(3 / fan_in)\n</code></pre>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li><strong><em>fan_in</em></strong>&nbsp;represents the number of input units</li><li><strong><em>fan_out</em></strong>&nbsp;represents the number of output units</li></ul>\n\n\n\n<h3>glorot_normal</h3>\n\n\n\n<p>Generates value using glorot normal distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.glorot_normal(seed=None) model.add(\n   Dense(512, activation = 'relu', input_shape = (784,), kernel_initializer = my_init)\n)</code></pre>\n\n\n\n<p>It finds the&nbsp;<strong><em>stddev</em></strong>&nbsp;using the below formula and then apply normal distribution</p>\n\n\n\n<pre class=\"wp-block-code\"><code>stddev = sqrt(2 / (fan_in + fan_out))\n</code></pre>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li><strong><em>fan_in</em></strong>&nbsp;represents the number of input units</li><li><strong><em>fan_out</em></strong>&nbsp;represents the number of output units</li></ul>\n\n\n\n<h3>glorot_uniform</h3>\n\n\n\n<p>Generates value using glorot uniform distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.glorot_uniform(seed = None) \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>It finds the&nbsp;<strong><em>limit</em></strong>&nbsp;using the below formula and then apply uniform distribution</p>\n\n\n\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<pre class=\"wp-block-code\"><code>limit = sqrt(6 / (fan_in + fan_out))</code></pre>\n</div></div>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li><strong><em>fan_in</em></strong>&nbsp;represent the number of input units.</li><li><strong><em>fan_out</em></strong>&nbsp;represents the number of output units</li></ul>\n\n\n\n<h3>he_normal</h3>\n\n\n\n<p>Generates value using he normal distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.RandomUniform(minval = -0.05, maxval = 0.05, seed = None) \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>It finds the&nbsp;<em>stddev</em>&nbsp;using the below formula and then apply normal distribution.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>stddev = sqrt(2 / fan_in)\n</code></pre>\n\n\n\n<p>where,&nbsp;<strong><em>fan_in</em></strong>&nbsp;represent the number of input units.</p>\n\n\n\n<h3>he_uniform</h3>\n\n\n\n<p>Generates value using he uniform distribution of input data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.he_normal(seed = None) \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>It finds the&nbsp;<strong><em>limit</em></strong>&nbsp;using the below formula and then apply uniform distribution.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>limit = sqrt(6 / fan_in)\n</code></pre>\n\n\n\n<p>where,&nbsp;<strong><em>fan_in</em></strong>&nbsp;represent the number of input units.</p>\n\n\n\n<h3>Orthogonal</h3>\n\n\n\n<p>Generates a random orthogonal matrix.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.Orthogonal(gain = 1.0, seed = None) \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init))</code></pre>\n\n\n\n<p>where,&nbsp;<strong><em>gain</em></strong>&nbsp;represent the multiplication factor of the matrix.</p>\n\n\n\n<h3>Identity</h3>\n\n\n\n<p>Generates identity matrix.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.Identity(gain = 1.0) model.add(\n   Dense(512, activation = 'relu', input_shape = (784,), kernel_initializer = my_init)\n)</code></pre>\n\n\n\n<h2>Constraints</h2>\n\n\n\n<p>In machine learning, a constraint will be set on the parameter (weight) during optimization phase. &lt;&gt;Constraints module provides different functions to set the constraint on the layer. Some of the constraint functions are as follows.</p>\n\n\n\n<h3>NonNeg</h3>\n\n\n\n<p>Constrains weights to be non-negative.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import initializers \n\nmy_init = initializers.Identity(gain = 1.0) model.add(\n   Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_initializer = my_init)\n)</code></pre>\n\n\n\n<p>where,&nbsp;<strong><em>kernel_constraint</em></strong>&nbsp;represent the constraint to be used in the layer.</p>\n\n\n\n<h3>UnitNorm</h3>\n\n\n\n<p>Constrains weights to be unit norm.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import constraints \n\nmy_constrain = constraints.UnitNorm(axis = 0) \nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_constraint = my_constrain))</code></pre>\n\n\n\n<h3>MaxNorm</h3>\n\n\n\n<p>Constrains weight to norm less than or equals to the given value.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import constraints \n\nmy_constrain = constraints.MaxNorm(max_value = 2, axis = 0) \nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_constraint = my_constrain))</code></pre>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li><strong><em>max_value</em></strong>&nbsp;represent the upper bound</li><li><em>axis</em>&nbsp;represent the dimension in which the constraint to be applied. e.g. in Shape (2,3,4) axis 0 denotes first dimension, 1 denotes second dimension and 2 denotes third dimension</li></ul>\n\n\n\n<h3>MinMaxNorm</h3>\n\n\n\n<p>Constrains weights to be norm between specified minimum and maximum values.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import constraints \n\nmy_constrain = constraints.MinMaxNorm(min_value = 0.0, max_value = 1.0, rate = 1.0, axis = 0) \nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_constraint = my_constrain))</code></pre>\n\n\n\n<p>where,&nbsp;<strong><em>rate</em></strong>&nbsp;represent the rate at which the weight constrain is applied.</p>\n\n\n\n<h2>Regularizers</h2>\n\n\n\n<p>In machine learning, regularizers are used in the optimization phase. It applies some penalties on the layer parameter during optimization. Keras regularization module provides below functions to set penalties on the layer. Regularization applies per-layer basis only.</p>\n\n\n\n<h3>L1 Regularizer</h3>\n\n\n\n<p>It provides L1 based regularization.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import regularizers \n\nmy_regularizer = regularizers.l1(0.) \nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_regularizer = my_regularizer))\n</code></pre>\n\n\n\n<p>where,&nbsp;<strong><em>kernel_regularizer</em></strong>&nbsp;represent the rate at which the weight constrain is applied.</p>\n\n\n\n<h3>L2 Regularizer</h3>\n\n\n\n<p>It provides L2 based regularization.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import regularizers \n\nmy_regularizer = regularizers.l2(0.) \nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,), \n   kernel_regularizer = my_regularizer))</code></pre>\n\n\n\n<h3>L1 and L2 Regularizer</h3>\n\n\n\n<p>It provides both L1 and L2 based regularization.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nfrom keras import regularizers \n\nmy_regularizer = regularizers.l2(0.) \nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,),\n   kernel_regularizer = my_regularizer))</code></pre>\n\n\n\n<h2>Activations</h2>\n\n\n\n<p>In machine learning, activation function is a special function used to find whether a specific neuron is activated or not. Basically, the activation function does a nonlinear transformation of the input data and thus enable the neurons to learn better. Output of a neuron depends on the activation function.</p>\n\n\n\n<p>As you recall the concept of single perception, the output of a perceptron (neuron) is simply the result of the activation function, which accepts the summation of all input multiplied with its corresponding weight plus overall bias, if any available.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>result = Activation(SUMOF(input * weight) + bias)\n</code></pre>\n\n\n\n<p>So, activation function plays an important role in the successful learning of the model. Keras provides a lot of activation function in the activations module. Let us learn all the activations available in the module.</p>\n\n\n\n<h3>linear</h3>\n\n\n\n<p>Applies Linear function. Does nothing.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'linear', input_shape = (784,)))\n</code></pre>\n\n\n\n<p>Where,&nbsp;<strong><em>activation</em></strong>&nbsp;refers the activation function of the layer. It can be specified simply by the name of the function and the layer will use corresponding activators.</p>\n\n\n\n<h3>elu</h3>\n\n\n\n<p>Applies Exponential linear unit.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'elu', input_shape = (784,)))</code></pre>\n\n\n\n<h3>selu</h3>\n\n\n\n<p>Applies Scaled exponential linear unit.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'selu', input_shape = (784,)))</code></pre>\n\n\n\n<h3>relu</h3>\n\n\n\n<p>Applies Rectified Linear Unit.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,)))</code></pre>\n\n\n\n<h3>softmax</h3>\n\n\n\n<p>Applies Softmax function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'softmax', input_shape = (784,)))</code></pre>\n\n\n\n<h3>softplus</h3>\n\n\n\n<p>Applies Softplus function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'softplus', input_shape = (784,)))</code></pre>\n\n\n\n<h3>softsign</h3>\n\n\n\n<p>Applies Softsign function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'softsign', input_shape = (784,)))</code></pre>\n\n\n\n<h3>tanh</h3>\n\n\n\n<p>Applies Hyperbolic tangent function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \nmodel = Sequential() \nmodel.add(Dense(512, activation = 'tanh', input_shape = (784,)))</code></pre>\n\n\n\n<h3>sigmoid</h3>\n\n\n\n<p>Applies Sigmoid function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'sigmoid', input_shape = (784,)))</code></pre>\n\n\n\n<h3>hard_sigmoid</h3>\n\n\n\n<p>Applies Hard Sigmoid function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'hard_sigmoid', input_shape = (784,)))</code></pre>\n\n\n\n<h3>exponential</h3>\n\n\n\n<p>Applies exponential function.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Activation, Dense \n\nmodel = Sequential() \nmodel.add(Dense(512, activation = 'exponential', input_shape = (784,)))</code></pre>\n\n\n\n<figure class=\"wp-block-table\"><table><tbody><tr><th>Sr.No</th><th>Layers &amp; Description</th></tr><tr><td>1</td><td>Dense Layer<strong>Dense layer</strong> is the regular deeply connected neural network layer.</td></tr><tr><td>2</td><td>Dropout Layers<strong><em>Dropout</em></strong> is one of the important concept in the machine learning.</td></tr><tr><td>3</td><td>Flatten Layers<strong>Flatten</strong> is used to flatten the input.</td></tr><tr><td>4</td><td>Reshape Layers<strong><em>Reshape</em></strong> is used to change the shape of the input.</td></tr><tr><td>5</td><td>Permute Layers<strong>Permute</strong> is also used to change the shape of the input using pattern.</td></tr><tr><td>6</td><td>RepeatVector Layers<strong><em>RepeatVector</em></strong> is used to repeat the input for set number, n of times.</td></tr><tr><td>7</td><td>Lambda Layers<strong><em>Lambda</em></strong> is used to transform the input data using an expression or function.</td></tr><tr><td>8</td><td>Convolution LayersKeras contains a lot of layers for creating Convolution based ANN, popularly called as <em>Convolution Neural Network (CNN)</em>.</td></tr><tr><td>9</td><td>Pooling LayerIt is used to perform max pooling operations on temporal data.</td></tr><tr><td>10</td><td>Locally connected layerLocally connected layers are similar to Conv1D layer but the difference is Conv1D layer weights are shared but here weights are unshared.</td></tr><tr><td>11</td><td>Merge LayerIt is used to merge a list of inputs.</td></tr><tr><td>12</td><td>Embedding LayerIt performs embedding operations in input layer.</td></tr></tbody></table></figure>\n","protected":false},"excerpt":{"rendered":"<p>As learned earlier, Keras layers are the primary building block of Keras models. Each layer receives input information, do some computation and finally output the transformed information. The output of one layer will flow into the next layer as its input. Let us learn complete details about layers in this chapter. Introduction A Keras layer [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3385"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3385"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3385/revisions"}],"predecessor-version":[{"id":4240,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3385/revisions/4240"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3385"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3385"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3385"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3387,"date":"2020-10-01T11:20:43","date_gmt":"2020-10-01T11:20:43","guid":{"rendered":"http://ai.foobrdigital.com/?p=3387"},"modified":"2020-12-16T17:04:15","modified_gmt":"2020-12-16T17:04:15","slug":"keras-customized-layer","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-customized-layer/","title":{"rendered":"Customized Layer"},"content":{"rendered":"\n<p>Keras allows to create our own customized layer. Once a new layer is created, it can be used in any model without any restriction. Let us learn how to create new layer in this chapter.</p>\n\n\n\n<p>Keras provides a base&nbsp;<strong>layer</strong>&nbsp;class, Layer which can sub-classed to create our own customized layer. Let us create a simple layer which will find weight based on normal distribution and then do the basic computation of finding the summation of the product of input and its weight during training.</p>\n\n\n\n<h3>Step 1: Import the necessary module</h3>\n\n\n\n<p>First, let us import the necessary modules −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras import backend as K \nfrom keras.layers import Layer</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>backend</strong>&nbsp;is used to access the&nbsp;<strong>dot</strong>&nbsp;function.</li><li><strong>Layer</strong>&nbsp;is the base class and we will be sub-classing it to create our layer</li></ul>\n\n\n\n<h3>Step 2: Define a layer class</h3>\n\n\n\n<p>Let us create a new class,&nbsp;<strong>MyCustomLayer</strong>&nbsp;by sub-classing&nbsp;<strong>Layer class</strong>&nbsp;−</p>\n\n\n\n<pre class=\"wp-block-code\"><code>class MyCustomLayer(Layer): \n   ...\n</code></pre>\n\n\n\n<h3>Step 3: Initialize the layer class</h3>\n\n\n\n<p>Let us initialize our new class as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def __init__(self, output_dim, **kwargs):    \n   self.output_dim = output_dim \n   super(MyCustomLayer, self).__init__(**kwargs)\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>Line 2</strong>&nbsp;sets the output dimension.</li><li><strong>Line 3</strong>&nbsp;calls the base or super layer’s&nbsp;<strong>init</strong>&nbsp;function.</li></ul>\n\n\n\n<h3>Step 4: Implement build method</h3>\n\n\n\n<p><strong>build</strong>&nbsp;is the main method and its only purpose is to build the layer properly. It can do anything related to the inner working of the layer. Once the custom functionality is done, we can call the base class&nbsp;<strong>build</strong>&nbsp;function. Our custom&nbsp;<strong>build</strong>&nbsp;function is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def build(self, input_shape): \n   self.kernel = self.add_weight(name = 'kernel', \n      shape = (input_shape&#91;1], self.output_dim), \n      initializer = 'normal', trainable = True) \n   super(MyCustomLayer, self).build(input_shape)</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>Line 1</strong>&nbsp;defines the&nbsp;<strong>build</strong>&nbsp;method with one argument,&nbsp;<strong>input_shape</strong>. Shape of the input data is referred by input_shape.</li><li><strong>Line 2</strong>&nbsp;creates the weight corresponding to input shape and set it in the kernel. It is our custom functionality of the layer. It creates the weight using ‘normal’ initializer.</li><li><strong>Line 6</strong>&nbsp;calls the base class,&nbsp;<strong>build</strong>&nbsp;method.</li></ul>\n\n\n\n<h3>Step 5: Implement call method</h3>\n\n\n\n<p><strong>call</strong>&nbsp;method does the exact working of the layer during training process.</p>\n\n\n\n<p>Our custom&nbsp;<strong>call</strong>&nbsp;method is as follows</p>\n\n\n\n<pre class=\"wp-block-code\"><code>def call(self, input_data): \n   return K.dot(input_data, self.kernel)\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>Line 1</strong>&nbsp;defines the&nbsp;<strong>call</strong>&nbsp;method with one argument,&nbsp;<strong>input_data</strong>. input_data is the input data for our layer.</li><li><strong>Line 2</strong>&nbsp;return the dot product of the input data,&nbsp;<strong>input_data</strong>&nbsp;and our layer’s kernel,&nbsp;<strong>self.kernel</strong></li></ul>\n\n\n\n<h3>Step 6: Implement compute_output_shape method</h3>\n\n\n\n<pre class=\"wp-block-code\"><code>def compute_output_shape(self, input_shape): return (input_shape&#91;0], self.output_dim)\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>Line 1</strong>&nbsp;defines&nbsp;<strong>compute_output_shape</strong>&nbsp;method with one argument&nbsp;<strong>input_shape</strong></li><li><strong>Line 2</strong>&nbsp;computes the output shape using shape of input data and output dimension set while initializing the layer.</li></ul>\n\n\n\n<p>Implementing the&nbsp;<strong>build, call</strong>&nbsp;and&nbsp;<strong>compute_output_shape</strong>&nbsp;completes the creating a customized layer. The final and complete code is as follows</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras import backend as K from keras.layers import Layer\nclass MyCustomLayer(Layer): \n   def __init__(self, output_dim, **kwargs): \n      self.output_dim = output_dim \n      super(MyCustomLayer, self).__init__(**kwargs) \n   def build(self, input_shape): self.kernel = \n      self.add_weight(name = 'kernel', \n      shape = (input_shape&#91;1], self.output_dim), \n      initializer = 'normal', trainable = True) \n      super(MyCustomLayer, self).build(input_shape) # \n      Be sure to call this at the end \n   def call(self, input_data): return K.dot(input_data, self.kernel) \n   def compute_output_shape(self, input_shape): return (input_shape&#91;0], self.output_dim)</code></pre>\n\n\n\n<h3>Using our customized layer</h3>\n\n\n\n<p>Let us create a simple model using our customized layer as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nfrom keras.layers import Dense \n\nmodel = Sequential() \nmodel.add(MyCustomLayer(32, input_shape = (16,))) \nmodel.add(Dense(8, activation = 'softmax')) model.summary()</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li>Our&nbsp;<strong>MyCustomLayer</strong>&nbsp;is added to the model using 32 units and&nbsp;<strong>(16,)</strong>&nbsp;as input shape</li></ul>\n\n\n\n<p>Running the application will print the model summary as below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Model: \"sequential_1\" \n_________________________________________________________________ \nLayer (type) Output Shape Param \n#================================================================ \nmy_custom_layer_1 (MyCustomL (None, 32) 512 \n_________________________________________________________________\ndense_1 (Dense) (None, 8) 264 \n================================================================= \nTotal params: 776 \nTrainable params: 776 \nNon-trainable params: 0 \n_________________________________________________________________</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>Keras allows to create our own customized layer. Once a new layer is created, it can be used in any model without any restriction. Let us learn how to create new layer in this chapter. Keras provides a base&nbsp;layer&nbsp;class, Layer which can sub-classed to create our own customized layer. Let us create a simple layer [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3387"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3387"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3387/revisions"}],"predecessor-version":[{"id":4239,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3387/revisions/4239"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3387"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3387"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3387"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3389,"date":"2020-10-01T11:23:42","date_gmt":"2020-10-01T11:23:42","guid":{"rendered":"http://ai.foobrdigital.com/?p=3389"},"modified":"2020-12-16T17:04:15","modified_gmt":"2020-12-16T17:04:15","slug":"keras-models","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-models/","title":{"rendered":"Models"},"content":{"rendered":"\n<p>As learned earlier, Keras model represents the actual neural network model. Keras provides a two mode to create the model, simple and easy to use&nbsp;<em>Sequential API</em>&nbsp;as well as more flexible and advanced&nbsp;<em>Functional API</em>. Let us learn now to create model using both&nbsp;<em>Sequential</em>&nbsp;and&nbsp;<em>Functional</em>&nbsp;API in this chapter.</p>\n\n\n\n<h2>Sequential</h2>\n\n\n\n<p>The core idea of&nbsp;<strong><em>Sequential API</em></strong>&nbsp;is simply arranging the Keras layers in a sequential order and so, it is called&nbsp;<em>Sequential API</em>. Most of the ANN also has layers in sequential order and the data flows from one layer to another layer in the given order until the data finally reaches the output layer.</p>\n\n\n\n<p>A ANN model can be created by simply calling&nbsp;<strong>Sequential()</strong>&nbsp;API as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \nmodel = Sequential()\n</code></pre>\n\n\n\n<h3>Add layers</h3>\n\n\n\n<p>To add a layer, simply create a layer using Keras layer API and then pass the layer through add() function as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential \n\nmodel = Sequential() \ninput_layer = Dense(32, input_shape=(8,)) model.add(input_layer) \nhidden_layer = Dense(64, activation='relu'); model.add(hidden_layer) \noutput_layer = Dense(8) \nmodel.add(output_layer)</code></pre>\n\n\n\n<p>Here, we have created one input layer, one hidden layer and one output layer.</p>\n\n\n\n<h3>Access the model</h3>\n\n\n\n<p>Keras provides few methods to get the model information like layers, input data and output data. They are as follows −</p>\n\n\n\n<ul><li><strong><em>model.layers</em></strong>&nbsp;− Returns all the layers of the model as list.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> layers = model.layers \n>>> layers \n&#91;\n   &lt;keras.layers.core.Dense object at 0x000002C8C888B8D0>, \n   &lt;keras.layers.core.Dense object at 0x000002C8C888B7B8>\n   &lt;keras.layers.core.Dense object at 0x 000002C8C888B898>\n]</code></pre>\n\n\n\n<ul><li><strong><em>model.inputs</em></strong>&nbsp;− Returns all the input tensors of the model as list.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> inputs = model.inputs \n>>> inputs \n&#91;&lt;tf.Tensor 'dense_13_input:0' shape=(?, 8) dtype=float32>]</code></pre>\n\n\n\n<ul><li><strong><em>model.outputs</em></strong>&nbsp;− Returns all the output tensors of the model as list.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> outputs = model.outputs \n>>> outputs \n&lt;tf.Tensor 'dense_15/BiasAdd:0' shape=(?, 8) dtype=float32>]</code></pre>\n\n\n\n<ul><li><strong><em>model.get_weights</em></strong>&nbsp;− Returns all the weights as NumPy arrays.</li><li><strong><em>model.set_weights(weight_numpy_array)</em></strong>&nbsp;− Set the weights of the model.</li></ul>\n\n\n\n<h3>Serialize the model</h3>\n\n\n\n<p>Keras provides methods to serialize the model into object as well as json and load it again later. They are as follows −</p>\n\n\n\n<ul><li><strong><em>get_config()</em></strong>&nbsp;− IReturns the model as an object.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>config = model.get_config()\n</code></pre>\n\n\n\n<ul><li><strong><em>from_config()</em></strong>&nbsp;− It accept the model configuration object as argument and create the model accordingly.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>new_model = Sequential.from_config(config)\n</code></pre>\n\n\n\n<ul><li><strong><em>to_json()</em></strong>&nbsp;− Returns the model as an json object.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> json_string = model.to_json() \n>>> json_string '{\"class_name\": \"Sequential\", \"config\": \n{\"name\": \"sequential_10\", \"layers\": \n&#91;{\"class_name\": \"Dense\", \"config\": \n{\"name\": \"dense_13\", \"trainable\": true, \"batch_input_shape\": \n&#91;null, 8], \"dtype\": \"float32\", \"units\": 32, \"activation\": \"linear\", \n\"use_bias\": true, \"kernel_initializer\": \n{\"class_name\": \"Vari anceScaling\", \"config\": \n{\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}},\n\"bias_initializer\": {\"class_name\": \"Zeros\", \"conf \nig\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \n\"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, \n{\" class_name\": \"Dense\", \"config\": {\"name\": \"dense_14\", \"trainable\": true, \n\"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \n\"kern el_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": \n{\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \n\"bias_initia lizer\": {\"class_name\": \"Zeros\", \n\"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \n\"activity_regularizer\": null, \"kernel_constraint\" : null, \"bias_constraint\": null}}, \n{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_15\", \"trainable\": true, \n\"dtype\": \"float32\", \"units\": 8, \"activation\": \"linear\", \"use_bias\": true, \n\"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": \n{\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \" uniform\", \"seed\": null}}, \n\"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \n\"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_r egularizer\": \nnull, \"kernel_constraint\": null, \"bias_constraint\": \nnull}}]}, \"keras_version\": \"2.2.5\", \"backend\": \"tensorflow\"}' \n>>></code></pre>\n\n\n\n<ul><li><strong><em>model_from_json()</em></strong>&nbsp;− Accepts json representation of the model and create a new model.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import model_from_json \nnew_model = model_from_json(json_string)\n</code></pre>\n\n\n\n<ul><li><strong><em>to_yaml()</em></strong>&nbsp;− Returns the model as a yaml string.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> yaml_string = model.to_yaml() \n>>> yaml_string 'backend: tensorflow\\nclass_name: \nSequential\\nconfig:\\n layers:\\n - class_name: Dense\\n config:\\n \nactivation: linear\\n activity_regular izer: null\\n batch_input_shape: \n!!python/tuple\\n - null\\n - 8\\n bias_constraint: null\\n bias_initializer:\\n \nclass_name : Zeros\\n config: {}\\n bias_regularizer: null\\n dtype: \nfloat32\\n kernel_constraint: null\\n \nkernel_initializer:\\n cla ss_name: VarianceScaling\\n config:\\n \ndistribution: uniform\\n mode: fan_avg\\n \nscale: 1.0\\n seed: null\\n kernel_regularizer: null\\n name: dense_13\\n \ntrainable: true\\n units: 32\\n \nuse_bias: true\\n - class_name: Dense\\n config:\\n activation: relu\\n activity_regularizer: null\\n \nbias_constraint: null\\n bias_initializer:\\n class_name: Zeros\\n \nconfig : {}\\n bias_regularizer: null\\n dtype: float32\\n \nkernel_constraint: null\\n kernel_initializer:\\n class_name: VarianceScalin g\\n \nconfig:\\n distribution: uniform\\n mode: fan_avg\\n scale: 1.0\\n \nseed: null\\n kernel_regularizer: nu ll\\n name: dense_14\\n trainable: true\\n \nunits: 64\\n use_bias: true\\n - class_name: Dense\\n config:\\n \nactivation: linear\\n activity_regularizer: null\\n \nbias_constraint: null\\n bias_initializer:\\n \nclass_name: Zeros\\n config: {}\\n bias_regu larizer: null\\n \ndtype: float32\\n kernel_constraint: null\\n \nkernel_initializer:\\n class_name: VarianceScaling\\n config:\\n \ndistribution: uniform\\n mode: fan_avg\\n \nscale: 1.0\\n seed: null\\n kernel_regularizer: null\\n name: dense _15\\n \ntrainable: true\\n units: 8\\n \nuse_bias: true\\n name: sequential_10\\nkeras_version: 2.2.5\\n' \n>>></code></pre>\n\n\n\n<ul><li><strong><em>model_from_yaml()</em></strong>&nbsp;− Accepts yaml representation of the model and create a new model.</li></ul>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import model_from_yaml \nnew_model = model_from_yaml(yaml_string)</code></pre>\n\n\n\n<h3>Summarise the model</h3>\n\n\n\n<p>Understanding the model is very important phase to properly use it for training and prediction purposes. Keras provides a simple method, summary to get the full information about the model and its layers.</p>\n\n\n\n<p>A summary of the model created in the previous section is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&amp;gt;&amp;gt;&amp;gt; model.summary() Model: \"sequential_10\" \n_________________________________________________________________ \nLayer (type) Output Shape Param \n#================================================================ \ndense_13 (Dense) (None, 32) 288 \n_________________________________________________________________ \ndense_14 (Dense) (None, 64) 2112 \n_________________________________________________________________ \ndense_15 (Dense) (None, 8) 520 \n================================================================= \nTotal params: 2,920 \nTrainable params: 2,920 \nNon-trainable params: 0 \n_________________________________________________________________ \n&amp;gt;&amp;gt;&amp;gt;</code></pre>\n\n\n\n<h3>Train and Predict the model</h3>\n\n\n\n<p>Model provides function for training, evaluation and prediction process. They are as follows −</p>\n\n\n\n<ul><li><strong><em>compile</em></strong>&nbsp;− Configure the learning process of the model</li><li><strong><em>fit</em></strong>&nbsp;− Train the model using the training data</li><li><strong><em>evaluate</em></strong>&nbsp;− Evaluate the model using the test data</li><li><strong><em>predict</em></strong>&nbsp;− Predict the results for new input.</li></ul>\n\n\n\n<h2>Functional API</h2>\n\n\n\n<p>Sequential API is used to create models layer-by-layer. Functional API is an alternative approach of creating more complex models. Functional model, you can define multiple input or output that share layers. First, we create an instance for model and connecting to the layers to access input and output to the model. This section explains about functional model in brief.</p>\n\n\n\n<h3>Create a model</h3>\n\n\n\n<p>Import an input layer using the below module −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&amp;gt;&amp;gt;&amp;gt; from keras.layers import Input\n</code></pre>\n\n\n\n<p>Now, create an input layer specifying input dimension shape for the model using the below code −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&amp;gt;&amp;gt;&amp;gt; data = Input(shape=(2,3))\n</code></pre>\n\n\n\n<p>Define layer for the input using the below module −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&amp;gt;&amp;gt;&amp;gt; from keras.layers import Dense\n</code></pre>\n\n\n\n<p>Add Dense layer for the input using the below line of code −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&amp;gt;&amp;gt;&amp;gt; layer = Dense(2)(data) \n&amp;gt;&amp;gt;&amp;gt; print(layer) \nTensor(\"dense_1/add:0\", shape =(?, 2, 2), dtype = float32)</code></pre>\n\n\n\n<p>Define model using the below module −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Model\n</code></pre>\n\n\n\n<p>Create a model in functional way by specifying both input and output layer −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model = Model(inputs = data, outputs = layer)\n</code></pre>\n\n\n\n<p>The complete code to create a simple model is shown below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.layers import Input \nfrom keras.models import Model \nfrom keras.layers import Dense \n\ndata = Input(shape=(2,3)) \nlayer = Dense(2)(data) model = \nModel(inputs=data,outputs=layer) model.summary() \n_________________________________________________________________ \nLayer (type)               Output Shape               Param # \n================================================================= \ninput_2 (InputLayer)       (None, 2, 3)               0 \n_________________________________________________________________ \ndense_2 (Dense)            (None, 2, 2)               8 \n================================================================= \nTotal params: 8 \nTrainable params: 8 \nNon-trainable params: 0 \n_________________________________________________________________</code></pre>\n","protected":false},"excerpt":{"rendered":"<p>As learned earlier, Keras model represents the actual neural network model. Keras provides a two mode to create the model, simple and easy to use&nbsp;Sequential API&nbsp;as well as more flexible and advanced&nbsp;Functional API. Let us learn now to create model using both&nbsp;Sequential&nbsp;and&nbsp;Functional&nbsp;API in this chapter. Sequential The core idea of&nbsp;Sequential API&nbsp;is simply arranging the Keras [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3389"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3389"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3389/revisions"}],"predecessor-version":[{"id":4238,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3389/revisions/4238"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3389"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3389"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3389"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3391,"date":"2020-10-01T11:26:58","date_gmt":"2020-10-01T11:26:58","guid":{"rendered":"http://ai.foobrdigital.com/?p=3391"},"modified":"2020-12-16T17:04:14","modified_gmt":"2020-12-16T17:04:14","slug":"keras-model-compilation","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-model-compilation/","title":{"rendered":"Model Compilation"},"content":{"rendered":"\n<p>Previously, we studied the basics of how to create model using Sequential and Functional API. This chapter explains about how to compile the model. The compilation is the final step in creating a model. Once the compilation is done, we can move on to training phase.</p>\n\n\n\n<p>Let us learn few concepts required to better understand the compilation process.</p>\n\n\n\n<h2>Loss</h2>\n\n\n\n<p>In machine learning,&nbsp;<strong>Loss</strong>&nbsp;function is used to find error or deviation in the learning process. Keras requires loss function during model compilation process.</p>\n\n\n\n<p>Keras provides quite a few loss function in the&nbsp;<strong>losses</strong>&nbsp;module and they are as follows −</p>\n\n\n\n<ul><li>mean_squared_error</li><li>mean_absolute_error</li><li>mean_absolute_percentage_error</li><li>mean_squared_logarithmic_error</li><li>squared_hinge</li><li>hinge</li><li>categorical_hinge</li><li>logcosh</li><li>huber_loss</li><li>categorical_crossentropy</li><li>sparse_categorical_crossentropy</li><li>binary_crossentropy</li><li>kullback_leibler_divergence</li><li>poisson</li><li>cosine_proximity</li><li>is_categorical_crossentropy</li></ul>\n\n\n\n<p>All above loss function accepts two arguments −</p>\n\n\n\n<ul><li><strong>y_true</strong>&nbsp;− true labels as tensors</li><li><strong>y_pred</strong>&nbsp;− prediction with same shape as&nbsp;<strong>y_true</strong></li></ul>\n\n\n\n<p>Import the losses module before using loss function as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras import losses\n</code></pre>\n\n\n\n<h2>Optimizer</h2>\n\n\n\n<p>In machine learning,&nbsp;<strong>Optimization</strong>&nbsp;is an important process which optimize the input weights by comparing the prediction and the loss function. Keras provides quite a few optimizer as a module,&nbsp;<em>optimizers</em>&nbsp;and they are as follows:</p>\n\n\n\n<p><strong>SGD</strong>&nbsp;− Stochastic gradient descent optimizer.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.0, nesterov = False)\n</code></pre>\n\n\n\n<p><strong>RMSprop</strong>&nbsp;− RMSProp optimizer.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.optimizers.RMSprop(learning_rate = 0.001, rho = 0.9)\n</code></pre>\n\n\n\n<p><strong>Adagrad</strong>&nbsp;− Adagrad optimizer.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.optimizers.Adagrad(learning_rate = 0.01)\n</code></pre>\n\n\n\n<p><strong>Adadelta</strong>&nbsp;− Adadelta optimizer.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.optimizers.Adadelta(learning_rate = 1.0, rho = 0.95)\n</code></pre>\n\n\n\n<p><strong>Adam</strong>&nbsp;− Adam optimizer.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.optimizers.Adam(\n   learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False\n)</code></pre>\n\n\n\n<p><strong>Adamax</strong>&nbsp;− Adamax optimizer from Adam.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.optimizers.Adamax(learning_rate = 0.002, beta_1 = 0.9, beta_2 = 0.999)\n</code></pre>\n\n\n\n<p><strong>Nadam</strong>&nbsp;− Nesterov Adam optimizer.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.optimizers.Nadam(learning_rate = 0.002, beta_1 = 0.9, beta_2 = 0.999)\n</code></pre>\n\n\n\n<p>Import the optimizers module before using optimizers as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras import optimizers\n</code></pre>\n\n\n\n<h2>Metrics</h2>\n\n\n\n<p>In machine learning,&nbsp;<strong>Metrics</strong>&nbsp;is used to evaluate the performance of your model. It is similar to loss function, but not used in training process. Keras provides quite a few metrics as a module,&nbsp;<strong>metrics</strong>&nbsp;and they are as follows</p>\n\n\n\n<ul><li>accuracy</li><li>binary_accuracy</li><li>categorical_accuracy</li><li>sparse_categorical_accuracy</li><li>top_k_categorical_accuracy</li><li>sparse_top_k_categorical_accuracy</li><li>cosine_proximity</li><li>clone_metric</li></ul>\n\n\n\n<p>Similar to loss function, metrics also accepts below two arguments −</p>\n\n\n\n<ul><li><strong>y_true</strong>&nbsp;− true labels as tensors</li><li><strong>y_pred</strong>&nbsp;− prediction with same shape as&nbsp;<strong>y_true</strong></li></ul>\n\n\n\n<p>Import the metrics module before using metrics as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras import metrics\n</code></pre>\n\n\n\n<h2>Compile the model</h2>\n\n\n\n<p>Keras model provides a method,&nbsp;<strong>compile()</strong>&nbsp;to compile the model. The argument and default value of the&nbsp;<strong>compile()</strong>&nbsp;method is as follows</p>\n\n\n\n<pre class=\"wp-block-code\"><code>compile(\n   optimizer, \n   loss = None, \n   metrics = None, \n   loss_weights = None, \n   sample_weight_mode = None, \n   weighted_metrics = None, \n   target_tensors = None\n)\n</code></pre>\n\n\n\n<p>The important arguments are as follows −</p>\n\n\n\n<ul><li>loss function</li><li>Optimizer</li><li>metrics</li></ul>\n\n\n\n<p>A sample code to compile the mode is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras import losses \nfrom keras import optimizers \nfrom keras import metrics \n\nmodel.compile(loss = 'mean_squared_error',  \n   optimizer = 'sgd', metrics = &#91;metrics.categorical_accuracy])</code></pre>\n\n\n\n<p>where,</p>\n\n\n\n<ul><li>loss function is set as&nbsp;<strong>mean_squared_error</strong></li><li>optimizer is set as&nbsp;<strong>sgd</strong></li><li>metrics is set as&nbsp;<strong>metrics.categorical_accuracy</strong></li></ul>\n\n\n\n<h2>Model Training</h2>\n\n\n\n<p>Models are trained by NumPy arrays using&nbsp;<strong><em>fit()</em></strong>. The main purpose of this fit function is used to evaluate your model on training. This can be also used for graphing model performance. It has the following syntax −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.fit(X, y, epochs = , batch_size = )\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>X, y</strong>&nbsp;− It is a tuple to evaluate your data.</li><li><strong>epochs</strong>&nbsp;− no of times the model is needed to be evaluated during training.</li><li><strong>batch_size</strong>&nbsp;− training instances.</li></ul>\n\n\n\n<p>Let us take a simple example of numpy random data to use this concept.</p>\n\n\n\n<h3>Create data</h3>\n\n\n\n<p>Let us create a random data using numpy for x and y with the help of below mentioned command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import numpy as np \n\nx_train = np.random.random((100,4,8)) \ny_train = np.random.random((100,10))</code></pre>\n\n\n\n<p>Now, create random validation data,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x_val = np.random.random((100,4,8)) \ny_val = np.random.random((100,10))\n</code></pre>\n\n\n\n<h3>Create model</h3>\n\n\n\n<p>Let us create simple sequential model −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.models import Sequential model = Sequential()\n</code></pre>\n\n\n\n<h3>Add layers</h3>\n\n\n\n<p>Create layers to add model −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.layers import LSTM, Dense \n\n# add a sequence of vectors of dimension 16 \nmodel.add(LSTM(16, return_sequences = True)) \nmodel.add(Dense(10, activation = 'softmax'))\n</code></pre>\n\n\n\n<h3>compile model</h3>\n\n\n\n<p>Now model is defined. You can compile using the below command −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.compile(\n   loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = &#91;'accuracy']\n)\n</code></pre>\n\n\n\n<h3>Apply fit()</h3>\n\n\n\n<p>Now we apply&nbsp;<em>fit()</em>&nbsp;function to train our data −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.fit(x_train, y_train, batch_size = 32, epochs = 5, validation_data = (x_val, y_val))\n</code></pre>\n\n\n\n<h2>Create a Multi-Layer Perceptron ANN</h2>\n\n\n\n<p>We have learned to create, compile and train the Keras models.</p>\n\n\n\n<p>Let us apply our learning and create a simple MPL based ANN.</p>\n\n\n\n<h3>Dataset module</h3>\n\n\n\n<p>Before creating a model, we need to choose a problem, need to collect the required data and convert the data to NumPy array. Once data is collected, we can prepare the model and train it by using the collected data. Data collection is one of the most difficult phase of machine learning. Keras provides a special module, datasets to download the online machine learning data for training purposes. It fetches the data from online server, process the data and return the data as training and test set. Let us check the data provided by Keras dataset module. The data available in the module are as follows,</p>\n\n\n\n<ul><li>CIFAR10 small image classification</li><li>CIFAR100 small image classification</li><li>IMDB Movie reviews sentiment classification</li><li>Reuters newswire topics classification</li><li>MNIST database of handwritten digits</li><li>Fashion-MNIST database of fashion articles</li><li>Boston housing price regression dataset</li></ul>\n\n\n\n<p>Let us use the&nbsp;<strong><em>MNIST database of handwritten digits</em></strong>&nbsp;(or minst) as our input. minst is a collection of 60,000, 28&#215;28 grayscale images. It contains 10 digits. It also contains 10,000 test images.</p>\n\n\n\n<p>Below code can be used to load the dataset −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.datasets import mnist \n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()</code></pre>\n\n\n\n<p>where</p>\n\n\n\n<ul><li><strong>Line 1</strong>&nbsp;imports&nbsp;<strong>minst</strong>&nbsp;from the keras dataset module.</li><li><strong>Line 3</strong>&nbsp;calls the&nbsp;<strong>load_data</strong>&nbsp;function, which will fetch the data from online server and return the data as 2 tuples, First tuple,&nbsp;<strong>(x_train, y_train)</strong>&nbsp;represent the training data with shape,&nbsp;<strong>(number_sample, 28, 28)</strong>&nbsp;and its digit label with shape,&nbsp;<strong>(number_samples, )</strong>. Second tuple,&nbsp;<strong>(x_test, y_test)</strong>&nbsp;represent test data with same shape.</li></ul>\n\n\n\n<p>Other dataset can also be fetched using similar API and every API returns similar data as well except the shape of the data. The shape of the data depends on the type of data.</p>\n\n\n\n<h3>Create a model</h3>\n\n\n\n<p>Let us choose a simple multi-layer perceptron (MLP) as represented below and try to create the model using Keras.</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/create_model.jpg\" alt=\"Create Model\"/></figure>\n\n\n\n<p>The core features of the model are as follows −</p>\n\n\n\n<ul><li>Input layer consists of 784 values (28 x 28 = 784).</li><li>First hidden layer,&nbsp;<strong>Dense</strong>&nbsp;consists of 512 neurons and ‘relu’ activation function.</li><li>Second hidden layer,&nbsp;<strong>Dropout</strong>&nbsp;has 0.2 as its value.</li><li>Third hidden layer, again Dense consists of 512 neurons and ‘relu’ activation function.</li><li>Fourth hidden layer,&nbsp;<strong>Dropout</strong>&nbsp;has 0.2 as its value.</li><li>Fifth and final layer consists of 10 neurons and ‘softmax’ activation function.</li><li>Use&nbsp;<strong>categorical_crossentropy</strong>&nbsp;as loss function.</li><li>Use&nbsp;<strong>RMSprop()</strong>&nbsp;as Optimizer.</li><li>Use&nbsp;<strong>accuracy</strong>&nbsp;as metrics.</li><li>Use 128 as batch size.</li><li>Use 20 as epochs.</li></ul>\n\n\n\n<p><strong>Step 1 − Import the modules</strong></p>\n\n\n\n<p>Let us import the necessary modules.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import keras \nfrom keras.datasets import mnist \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout \nfrom keras.optimizers import RMSprop \nimport numpy as np</code></pre>\n\n\n\n<p><strong>Step 2 − Load data</strong></p>\n\n\n\n<p>Let us import the mnist dataset.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>(x_train, y_train), (x_test, y_test) = mnist.load_data()\n</code></pre>\n\n\n\n<p><strong>Step 3 − Process the data</strong></p>\n\n\n\n<p>Let us change the dataset according to our model, so that it can be feed into our model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x_train = x_train.reshape(60000, 784) \nx_test = x_test.reshape(10000, 784) \nx_train = x_train.astype('float32') \nx_test = x_test.astype('float32') \nx_train /= 255 \nx_test /= 255 \n\ny_train = keras.utils.to_categorical(y_train, 10) \ny_test = keras.utils.to_categorical(y_test, 10)</code></pre>\n\n\n\n<p>Where</p>\n\n\n\n<ul><li><strong>reshape</strong>&nbsp;is used to reshape the input from (28, 28) tuple to (784, )</li><li><strong>to_categorical</strong>&nbsp;is used to convert vector to binary matrix</li></ul>\n\n\n\n<p><strong>Step 4 − Create the model</strong></p>\n\n\n\n<p>Let us create the actual model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model = Sequential() \nmodel.add(Dense(512, activation = 'relu', input_shape = (784,))) \nmodel.add(Dropout(0.2)) \nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(0.2)) \nmodel.add(Dense(10, activation = 'softmax'))</code></pre>\n\n\n\n<p><strong>Step 5 − Compile the model</strong></p>\n\n\n\n<p>Let us compile the model using selected loss function, optimizer and metrics.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.compile(loss = 'categorical_crossentropy',     \n   optimizer = RMSprop(), \n   metrics = &#91;'accuracy'])</code></pre>\n\n\n\n<p><strong>Step 6 − Train the model</strong></p>\n\n\n\n<p>Let us train the model using&nbsp;<strong><em>fit()</em></strong>&nbsp;method.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>history = model.fit(\n   x_train, y_train, \n   batch_size = 128, \n   epochs = 20, \n   verbose = 1, \n   validation_data = (x_test, y_test)\n)</code></pre>\n\n\n\n<h2>Final thoughts</h2>\n\n\n\n<p>We have created the model, loaded the data and also trained the data to the model. We still need to evaluate the model and predict output for unknown input, which we learn in upcoming chapter.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import keras \nfrom keras.datasets import mnist \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout \nfrom keras.optimizers import RMSprop \nimport numpy as np \n\n(x_train, y_train), (x_test, y_test) = mnist.load_data() \n\nx_train = x_train.reshape(60000, 784) \nx_test = x_test.reshape(10000, 784) \nx_train = x_train.astype('float32') \nx_test = x_test.astype('float32') \nx_train /= 255 \nx_test /= 255 \n\ny_train = keras.utils.to_categorical(y_train, 10) \ny_test = keras.utils.to_categorical(y_test, 10) \n\nmodel = Sequential() \nmodel.add(Dense(512, activation='relu', input_shape = (784,))) \nmodel.add(Dropout(0.2)) \nmodel.add(Dense(512, activation = 'relu')) model.add(Dropout(0.2)) \nmodel.add(Dense(10, activation = 'softmax'))\nmodel.compile(loss = 'categorical_crossentropy', \n   optimizer = RMSprop(), \n   metrics = &#91;'accuracy']) \n\nhistory = model.fit(x_train, y_train, \n   batch_size = 128, epochs = 20, verbose = 1, validation_data = (x_test, y_test))</code></pre>\n\n\n\n<p>Executing the application will give the below content as output −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Train on 60000 samples, validate on 10000 samples Epoch 1/20 \n60000/60000 &#91;==============================] - 7s 118us/step - loss: 0.2453 \n- acc: 0.9236 - val_loss: 0.1004 - val_acc: 0.9675 Epoch 2/20 \n60000/60000 &#91;==============================] - 7s 110us/step - loss: 0.1023 \n- acc: 0.9693 - val_loss: 0.0797 - val_acc: 0.9761 Epoch 3/20 \n60000/60000 &#91;==============================] - 7s 110us/step - loss: 0.0744 \n- acc: 0.9770 - val_loss: 0.0727 - val_acc: 0.9791 Epoch 4/20 \n60000/60000 &#91;==============================] - 7s 110us/step - loss: 0.0599 \n- acc: 0.9823 - val_loss: 0.0704 - val_acc: 0.9801 Epoch 5/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0504 \n- acc: 0.9853 - val_loss: 0.0714 - val_acc: 0.9817 Epoch 6/20 \n60000/60000 &#91;==============================] - 7s 111us/step - loss: 0.0438 \n- acc: 0.9868 - val_loss: 0.0845 - val_acc: 0.9809 Epoch 7/20 \n60000/60000 &#91;==============================] - 7s 114us/step - loss: 0.0391 \n- acc: 0.9887 - val_loss: 0.0823 - val_acc: 0.9802 Epoch 8/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0364 \n- acc: 0.9892 - val_loss: 0.0818 - val_acc: 0.9830 Epoch 9/20 \n60000/60000 &#91;==============================] - 7s 113us/step - loss: 0.0308 \n- acc: 0.9905 - val_loss: 0.0833 - val_acc: 0.9829 Epoch 10/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0289 \n- acc: 0.9917 - val_loss: 0.0947 - val_acc: 0.9815 Epoch 11/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0279 \n- acc: 0.9921 - val_loss: 0.0818 - val_acc: 0.9831 Epoch 12/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0260 \n- acc: 0.9927 - val_loss: 0.0945 - val_acc: 0.9819 Epoch 13/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0257 \n- acc: 0.9931 - val_loss: 0.0952 - val_acc: 0.9836 Epoch 14/20\n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0229 \n- acc: 0.9937 - val_loss: 0.0924 - val_acc: 0.9832 Epoch 15/20 \n60000/60000 &#91;==============================] - 7s 115us/step - loss: 0.0235 \n- acc: 0.9937 - val_loss: 0.1004 - val_acc: 0.9823 Epoch 16/20 \n60000/60000 &#91;==============================] - 7s 113us/step - loss: 0.0214 \n- acc: 0.9941 - val_loss: 0.0991 - val_acc: 0.9847 Epoch 17/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0219 \n- acc: 0.9943 - val_loss: 0.1044 - val_acc: 0.9837 Epoch 18/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0190 \n- acc: 0.9952 - val_loss: 0.1129 - val_acc: 0.9836 Epoch 19/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0197 \n- acc: 0.9953 - val_loss: 0.0981 - val_acc: 0.9841 Epoch 20/20 \n60000/60000 &#91;==============================] - 7s 112us/step - loss: 0.0198 \n- acc: 0.9950 - val_loss: 0.1215 - val_acc: 0.9828</code></pre>\n\n\n\n<p></p>\n","protected":false},"excerpt":{"rendered":"<p>Previously, we studied the basics of how to create model using Sequential and Functional API. This chapter explains about how to compile the model. The compilation is the final step in creating a model. Once the compilation is done, we can move on to training phase. Let us learn few concepts required to better understand [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3391"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3391"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3391/revisions"}],"predecessor-version":[{"id":4237,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3391/revisions/4237"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3391"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3391"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3391"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3393,"date":"2020-10-01T11:28:12","date_gmt":"2020-10-01T11:28:12","guid":{"rendered":"http://ai.foobrdigital.com/?p=3393"},"modified":"2020-12-16T17:04:14","modified_gmt":"2020-12-16T17:04:14","slug":"keras-model-evaluation-and-model-prediction","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-model-evaluation-and-model-prediction/","title":{"rendered":"Model Evaluation and Model Prediction"},"content":{"rendered":"\n<p>This chapter deals with the model evaluation and model prediction in Keras.</p>\n\n\n\n<p>Let us begin by understanding the model evaluation.</p>\n\n\n\n<h2>Model Evaluation</h2>\n\n\n\n<p>Evaluation is a process during development of the model to check whether the model is best fit for the given problem and corresponding data. Keras model provides a function, evaluate which does the evaluation of the model. It has three main arguments,</p>\n\n\n\n<ul><li>Test data</li><li>Test data label</li><li>verbose &#8211; true or false</li></ul>\n\n\n\n<p>Let us evaluate the model, which we created in the previous chapter using test data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>score = model.evaluate(x_test, y_test, verbose = 0) \n\nprint('Test loss:', score&#91;0]) \nprint('Test accuracy:', score&#91;1])</code></pre>\n\n\n\n<p>Executing the above code will output the below information.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>0 </code></pre>\n\n\n\n<p>The test accuracy is 98.28%. We have created a best model to identify the handwriting digits. On the positive side, we can still scope to improve our model.</p>\n\n\n\n<h2>Model Prediction</h2>\n\n\n\n<p><strong><em>Prediction</em></strong>&nbsp;is the final step and our expected outcome of the model generation. Keras provides a method,&nbsp;<em>predict</em>&nbsp;to get the prediction of the trained model. The signature of the&nbsp;<em>predict</em>&nbsp;method is as follows,</p>\n\n\n\n<pre class=\"wp-block-code\"><code>predict(\n   x, \n   batch_size = None, \n   verbose = 0, \n   steps = None, \n   callbacks = None, \n   max_queue_size = 10, \n   workers = 1, \n   use_multiprocessing = False\n)</code></pre>\n\n\n\n<p>Here, all arguments are optional except the first argument, which refers the unknown input data. The shape should be maintained to get the proper prediction.</p>\n\n\n\n<p>Let us do prediction for our MPL model created in previous chapter using below code −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pred = model.predict(x_test) \npred = np.argmax(pred, axis = 1)&#91;:5] \nlabel = np.argmax(y_test,axis = 1)&#91;:5] \n\nprint(pred) \nprint(label)</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>Line 1</strong>&nbsp;call the predict function using test data.</li><li><strong>Line 2</strong>&nbsp;gets the first five prediction</li><li><strong>Line 3</strong>&nbsp;gets the first five labels of the test data.</li><li><strong>Line 5 &#8211; 6</strong>&nbsp;prints the prediction and actual label.</li></ul>\n\n\n\n<p>The output of the above application is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91;7 2 1 0 4] \n&#91;7 2 1 0 4]\n</code></pre>\n\n\n\n<p>The output of both array is identical and it indicate that our model predicts correctly the first five images.</p>\n","protected":false},"excerpt":{"rendered":"<p>This chapter deals with the model evaluation and model prediction in Keras. Let us begin by understanding the model evaluation. Model Evaluation Evaluation is a process during development of the model to check whether the model is best fit for the given problem and corresponding data. Keras model provides a function, evaluate which does the [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3393"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3393"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3393/revisions"}],"predecessor-version":[{"id":4236,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3393/revisions/4236"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3393"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3393"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3393"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3395,"date":"2020-10-01T11:29:49","date_gmt":"2020-10-01T11:29:49","guid":{"rendered":"http://ai.foobrdigital.com/?p=3395"},"modified":"2020-12-16T17:04:14","modified_gmt":"2020-12-16T17:04:14","slug":"keras-convolution-neural-network","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-convolution-neural-network/","title":{"rendered":"Convolution Neural Network"},"content":{"rendered":"\n<p>Let us modify the model from MPL to&nbsp;<strong>Convolution Neural Network (CNN)</strong>&nbsp;for our earlier digit identification problem.</p>\n\n\n\n<p>CNN can be represented as below −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/convolution_neural_network.jpg\" alt=\"Convolution Neural Network\"/></figure>\n\n\n\n<p>The core features of the model are as follows −</p>\n\n\n\n<ul><li>Input layer consists of (1, 8, 28) values.</li><li>First layer,&nbsp;<strong><em>Conv2D</em></strong>&nbsp;consists of 32 filters and ‘relu’ activation function with kernel size, (3,3).</li><li>Second layer,&nbsp;<strong><em>Conv2D</em></strong>&nbsp;consists of 64 filters and ‘relu’ activation function with kernel size, (3,3).</li><li>Thrid layer,&nbsp;<strong><em>MaxPooling</em></strong>&nbsp;has pool size of (2, 2).</li><li>Fifth layer,&nbsp;<strong><em>Flatten</em></strong>&nbsp;is used to flatten all its input into single dimension.</li><li>Sixth layer,&nbsp;<strong><em>Dense</em></strong>&nbsp;consists of 128 neurons and ‘relu’ activation function.</li><li>Seventh layer,&nbsp;<strong><em>Dropout</em></strong>&nbsp;has 0.5 as its value.</li><li>Eighth and final layer consists of 10 neurons and ‘softmax’ activation function.</li><li>Use&nbsp;<strong>categorical_crossentropy</strong>&nbsp;as loss function.</li><li>Use&nbsp;<strong>Adadelta()</strong>&nbsp;as Optimizer.</li><li>Use&nbsp;<strong>accuracy</strong>&nbsp;as metrics.</li><li>Use 128 as batch size.</li><li>Use 20 as epochs.</li></ul>\n\n\n\n<p><strong>Step 1 − Import the modules</strong></p>\n\n\n\n<p>Let us import the necessary modules.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>import keras \nfrom keras.datasets import mnist \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout, Flatten \nfrom keras.layers import Conv2D, MaxPooling2D \nfrom keras import backend as K \nimport numpy as np</code></pre>\n\n\n\n<p><strong>Step 2 − Load data</strong></p>\n\n\n\n<p>Let us import the mnist dataset.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>(x_train, y_train), (x_test, y_test) = mnist.load_data()\n</code></pre>\n\n\n\n<p><strong>Step 3 − Process the data</strong></p>\n\n\n\n<p>Let us change the dataset according to our model, so that it can be feed into our model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>img_rows, img_cols = 28, 28 \n\nif K.image_data_format() == 'channels_first': \n   x_train = x_train.reshape(x_train.shape&#91;0], 1, img_rows, img_cols) \n   x_test = x_test.reshape(x_test.shape&#91;0], 1, img_rows, img_cols) \n   input_shape = (1, img_rows, img_cols) \nelse: \n   x_train = x_train.reshape(x_train.shape&#91;0], img_rows, img_cols, 1) \n   x_test = x_test.reshape(x_test.shape&#91;0], img_rows, img_cols, 1) \n   input_shape = (img_rows, img_cols, 1) \n   \nx_train = x_train.astype('float32') \nx_test = x_test.astype('float32') \nx_train /= 255 \nx_test /= 255 \n\ny_train = keras.utils.to_categorical(y_train, 10) \ny_test = keras.utils.to_categorical(y_test, 10)</code></pre>\n\n\n\n<p>The data processing is similar to MPL model except the shape of the input data and image format configuration.</p>\n\n\n\n<p><strong>Step 4 − Create the model</strong></p>\n\n\n\n<p>Let us create tha actual model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model = Sequential() \nmodel.add(Conv2D(32, kernel_size = (3, 3),  \n   activation = 'relu', input_shape = input_shape)) \nmodel.add(Conv2D(64, (3, 3), activation = 'relu')) \nmodel.add(MaxPooling2D(pool_size = (2, 2))) \nmodel.add(Dropout(0.25)) model.add(Flatten()) \nmodel.add(Dense(128, activation = 'relu')) \nmodel.add(Dropout(0.5)) \nmodel.add(Dense(10, activation = 'softmax'))</code></pre>\n\n\n\n<p><strong>Step 5 − Compile the model</strong></p>\n\n\n\n<p>Let us compile the model using selected loss function, optimizer and metrics.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.compile(loss = keras.losses.categorical_crossentropy, \n   optimizer = keras.optimizers.Adadelta(), metrics = &#91;'accuracy'])</code></pre>\n\n\n\n<p><strong>Step 6 − Train the model</strong></p>\n\n\n\n<p>Let us train the model using&nbsp;<strong>fit()</strong>&nbsp;method.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.fit(\n   x_train, y_train, \n   batch_size = 128, \n   epochs = 12, \n   verbose = 1, \n   validation_data = (x_test, y_test)\n)</code></pre>\n\n\n\n<p>Executing the application will output the below information −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Train on 60000 samples, validate on 10000 samples Epoch 1/12 \n60000/60000 &#91;==============================] - 84s 1ms/step - loss: 0.2687 \n- acc: 0.9173 - val_loss: 0.0549 - val_acc: 0.9827 Epoch 2/12 \n60000/60000 &#91;==============================] - 86s 1ms/step - loss: 0.0899 \n- acc: 0.9737 - val_loss: 0.0452 - val_acc: 0.9845 Epoch 3/12 \n60000/60000 &#91;==============================] - 83s 1ms/step - loss: 0.0666 \n- acc: 0.9804 - val_loss: 0.0362 - val_acc: 0.9879 Epoch 4/12 \n60000/60000 &#91;==============================] - 81s 1ms/step - loss: 0.0564 \n- acc: 0.9830 - val_loss: 0.0336 - val_acc: 0.9890 Epoch 5/12 \n60000/60000 &#91;==============================] - 86s 1ms/step - loss: 0.0472 \n- acc: 0.9861 - val_loss: 0.0312 - val_acc: 0.9901 Epoch 6/12 \n60000/60000 &#91;==============================] - 83s 1ms/step - loss: 0.0414 \n- acc: 0.9877 - val_loss: 0.0306 - val_acc: 0.9902 Epoch 7/12 \n60000/60000 &#91;==============================] - 89s 1ms/step - loss: 0.0375 \n-acc: 0.9883 - val_loss: 0.0281 - val_acc: 0.9906 Epoch 8/12 \n60000/60000 &#91;==============================] - 91s 2ms/step - loss: 0.0339 \n- acc: 0.9893 - val_loss: 0.0280 - val_acc: 0.9912 Epoch 9/12 \n60000/60000 &#91;==============================] - 89s 1ms/step - loss: 0.0325 \n- acc: 0.9901 - val_loss: 0.0260 - val_acc: 0.9909 Epoch 10/12 \n60000/60000 &#91;==============================] - 89s 1ms/step - loss: 0.0284 \n- acc: 0.9910 - val_loss: 0.0250 - val_acc: 0.9919 Epoch 11/12 \n60000/60000 &#91;==============================] - 86s 1ms/step - loss: 0.0287 \n- acc: 0.9907 - val_loss: 0.0264 - val_acc: 0.9916 Epoch 12/12 \n60000/60000 &#91;==============================] - 86s 1ms/step - loss: 0.0265 \n- acc: 0.9920 - val_loss: 0.0249 - val_acc: 0.9922\n</code></pre>\n\n\n\n<p><strong>Step 7 − Evaluate the model</strong></p>\n\n\n\n<p>Let us evaluate the model using test data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>score = model.evaluate(x_test, y_test, verbose = 0) \n\nprint('Test loss:', score&#91;0]) \nprint('Test accuracy:', score&#91;1])</code></pre>\n\n\n\n<p>Executing the above code will output the below information −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Test loss: 0.024936060590433316 \nTest accuracy: 0.9922\n</code></pre>\n\n\n\n<p>The test accuracy is 99.22%. We have created a best model to identify the handwriting digits.</p>\n\n\n\n<p><strong>Step 8 − Predict</strong></p>\n\n\n\n<p>Finally, predict the digit from images as below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pred = model.predict(x_test) \npred = np.argmax(pred, axis = 1)&#91;:5] \nlabel = np.argmax(y_test,axis = 1)&#91;:5] \n\nprint(pred) \nprint(label)</code></pre>\n\n\n\n<p>The output of the above application is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91;7 2 1 0 4] \n&#91;7 2 1 0 4]\n</code></pre>\n\n\n\n<p>The output of both array is identical and it indicate our model correctly predicts the first five images.</p>\n","protected":false},"excerpt":{"rendered":"<p>Let us modify the model from MPL to&nbsp;Convolution Neural Network (CNN)&nbsp;for our earlier digit identification problem. CNN can be represented as below − The core features of the model are as follows − Input layer consists of (1, 8, 28) values. First layer,&nbsp;Conv2D&nbsp;consists of 32 filters and ‘relu’ activation function with kernel size, (3,3). Second [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3395"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3395"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3395/revisions"}],"predecessor-version":[{"id":4235,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3395/revisions/4235"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3395"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3395"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3395"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3397,"date":"2020-10-01T11:31:52","date_gmt":"2020-10-01T11:31:52","guid":{"rendered":"http://ai.foobrdigital.com/?p=3397"},"modified":"2020-12-16T17:04:13","modified_gmt":"2020-12-16T17:04:13","slug":"keras-regression-prediction-using-mpl","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-regression-prediction-using-mpl/","title":{"rendered":"Regression Prediction using MPL"},"content":{"rendered":"\n<p>In this chapter, let us write a simple MPL based ANN to do regression prediction. Till now, we have only done the classification based prediction. Now, we will try to predict the next possible value by analyzing the previous (continuous) values and its influencing factors.</p>\n\n\n\n<p>The Regression MPL can be represented as below −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/mpl.jpg\" alt=\"MPL\"/></figure>\n\n\n\n<p>The core features of the model are as follows −</p>\n\n\n\n<ul><li>Input layer consists of (13,) values.</li><li>First layer,&nbsp;<em>Dense</em>&nbsp;consists of 64 units and ‘relu’ activation function with ‘normal’ kernel initializer.</li><li>Second layer,&nbsp;<em>Dense</em>&nbsp;consists of 64 units and ‘relu’ activation function.</li><li>Output layer,&nbsp;<em>Dense</em>&nbsp;consists of 1 unit.</li><li>Use&nbsp;<strong>mse</strong>&nbsp;as loss function.</li><li>Use&nbsp;<strong>RMSprop</strong>&nbsp;as Optimizer.</li><li>Use&nbsp;<strong>accuracy</strong>&nbsp;as metrics.</li><li>Use 128 as batch size.</li><li>Use 500 as epochs.</li></ul>\n\n\n\n<p><strong>Step 1 − Import the modules</strong></p>\n\n\n\n<p>Let us import the necessary modules.</p>\n\n\n\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<pre class=\"wp-block-code\"><code>import keras \n\nfrom keras.datasets import boston_housing \nfrom keras.models import Sequential \nfrom keras.layers import Dense \nfrom keras.optimizers import RMSprop \nfrom keras.callbacks import EarlyStopping \nfrom sklearn import preprocessing \nfrom sklearn.preprocessing import scale</code></pre>\n</div></div>\n\n\n\n<p><strong>Step 2 − Load data</strong></p>\n\n\n\n<p>Let us import the Boston housing dataset.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<p><strong>boston_housing</strong>&nbsp;is a dataset provided by Keras. It represents a collection of housing information in Boston area, each having 13 features.</p>\n\n\n\n<p><strong>Step 3 − Process the data</strong></p>\n\n\n\n<p>Let us change the dataset according to our model, so that, we can feed into our model. The data can be changed using below code −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x_train_scaled = preprocessing.scale(x_train) \nscaler = preprocessing.StandardScaler().fit(x_train) \nx_test_scaled = scaler.transform(x_test)</code></pre>\n\n\n\n<p>Here, we have normalized the training data using&nbsp;<strong>sklearn.preprocessing.scale</strong>&nbsp;function.&nbsp;<strong>preprocessing.StandardScaler().fit</strong>&nbsp;function returns a scalar with the normalized mean and standard deviation of the training data, which we can apply to the test data using&nbsp;<strong>scalar.transform</strong>&nbsp;function. This will normalize the test data as well with the same setting as that of training data.</p>\n\n\n\n<p><strong>Step 4 − Create the model</strong></p>\n\n\n\n<p>Let us create the actual model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model = Sequential() \nmodel.add(Dense(64, kernel_initializer = 'normal', activation = 'relu',\ninput_shape = (13,))) \nmodel.add(Dense(64, activation = 'relu')) model.add(Dense(1))</code></pre>\n\n\n\n<p><strong>Step 5 − Compile the model</strong></p>\n\n\n\n<p>Let us compile the model using selected loss function, optimizer and metrics.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.compile(\n   loss = 'mse', \n   optimizer = RMSprop(), \n   metrics = &#91;'mean_absolute_error']\n)</code></pre>\n\n\n\n<p><strong>Step 6 − Train the model</strong></p>\n\n\n\n<p>Let us train the model using&nbsp;<strong>fit()</strong>&nbsp;method.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>history = model.fit(\n   x_train_scaled, y_train,    \n   batch_size=128, \n   epochs = 500, \n   verbose = 1, \n   validation_split = 0.2, \n   callbacks = &#91;EarlyStopping(monitor = 'val_loss', patience = 20)]\n)</code></pre>\n\n\n\n<p>Here, we have used callback function,&nbsp;<strong>EarlyStopping</strong>. The purpose of this callback is to monitor the loss value during each epoch and compare it with previous epoch loss value to find the improvement in the training. If there is no improvement for the&nbsp;<strong>patience</strong>&nbsp;times, then the whole process will be stopped.</p>\n\n\n\n<p>Executing the application will give the below information as output −</p>\n\n\n\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<pre class=\"wp-block-code\"><code>Train on 323 samples, validate on 81 samples Epoch 1/500 2019-09-24 01:07:03.889046: I \ntensorflow/core/platform/cpu_feature_guard.cc:142] \nYour CPU supports instructions that this \nTensorFlow binary was not co mpiled to use: AVX2 323/323 \n&#91;==============================] - 0s 515us/step - loss: 562.3129 \n- mean_absolute_error: 21.8575 - val_loss: 621.6523 - val_mean_absolute_erro \nr: 23.1730 Epoch 2/500 \n323/323 &#91;==============================] - 0s 11us/step - loss: 545.1666 \n- mean_absolute_error: 21.4887 - val_loss: 605.1341 - val_mean_absolute_error \n: 22.8293 Epoch 3/500 \n323/323 &#91;==============================] - 0s 12us/step - loss: 528.9944 \n- mean_absolute_error: 21.1328 - val_loss: 588.6594 - val_mean_absolute_error \n: 22.4799 Epoch 4/500 \n323/323 &#91;==============================] - 0s 12us/step - loss: 512.2739 \n- mean_absolute_error: 20.7658 - val_loss: 570.3772 - val_mean_absolute_error \n: 22.0853 Epoch 5/500\n323/323 &#91;==============================] - 0s 9us/step - loss: 493.9775 \n- mean_absolute_error: 20.3506 - val_loss: 550.9548 - val_mean_absolute_error: 21.6547 \n.......... \n.......... \n.......... \nEpoch 143/500 \n323/323 &#91;==============================] - 0s 15us/step - loss: 8.1004 \n- mean_absolute_error: 2.0002 - val_loss: 14.6286 - val_mean_absolute_error: \n2. 5904 Epoch 144/500 \n323/323 &#91;==============================] - 0s 19us/step - loss: 8.0300 \n- mean_absolute_error: 1.9683 - val_loss: 14.5949 - val_mean_absolute_error: \n2. 5843 Epoch 145/500 \n323/323 &#91;==============================] - 0s 12us/step - loss: 7.8704 \n- mean_absolute_error: 1.9313 - val_loss: 14.3770 - val_mean_absolute_error: 2. 4996\n</code></pre>\n</div></div>\n\n\n\n<p><strong>Step 7 − Evaluate the model</strong></p>\n\n\n\n<p>Let us evaluate the model using test data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>score = model.evaluate(x_test_scaled, y_test, verbose = 0) \nprint('Test loss:', score&#91;0]) \nprint('Test accuracy:', score&#91;1])</code></pre>\n\n\n\n<p>Executing the above code will output the below information −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Test loss: 21.928471583946077 Test accuracy: 2.9599233234629914\n</code></pre>\n\n\n\n<p><strong>Step 8 − Predict</strong></p>\n\n\n\n<p>Finally, predict using test data as below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>prediction = model.predict(x_test_scaled) \nprint(prediction.flatten()) \nprint(y_test)</code></pre>\n\n\n\n<p>The output of the above application is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91; 7.5612316 17.583357 21.09344 31.859276 25.055613 18.673872 26.600405 22.403967 19.060272 22.264952 \n17.4191 17.00466 15.58924 41.624374 20.220217 18.985565 26.419338 19.837091 19.946192 36.43445 \n12.278508 16.330965 20.701359 14.345301 21.741161 25.050423 31.046402 27.738455 9.959419 20.93039 \n20.069063 14.518344 33.20235 24.735163 18.7274 9.148898 15.781284 18.556862 18.692865 26.045074 \n27.954073 28.106823 15.272034 40.879818 29.33896 23.714525 26.427515 16.483374 22.518442 22.425386 \n33.94826 18.831465 13.2501955 15.537227 34.639984 27.468002 13.474407 48.134598 34.39617 \n22.8503124.042334 17.747198 14.7837715 18.187277 23.655672 22.364983 13.858193 22.710032 14.371148 \n7.1272087 35.960033 28.247292 25.3014 14.477208 25.306196 17.891165 20.193708 23.585173 34.690193 \n12.200583 20.102983 38.45882 14.741723 14.408362 17.67158 18.418497 21.151712 21.157492 22.693687 \n29.809034 19.366991 20.072294 25.880817 40.814568 34.64087 19.43741 36.2591 50.73806 26.968863 43.91787 \n32.54908 20.248306 ] &#91; 7.2 18.8 19. 27. 22.2 24.5 31.2 22.9 20.5 23.2 18.6 14.5 17.8 50. 20.8 24.3 24.2 \n19.8 19.1 22.7 12. 10.2 20. 18.5 20.9 23. 27.5 30.1 9.5 22. 21.2 14.1 33.1 23.4 20.1 7.4 15.4 23.8 20.1 \n24.5 33. 28.4 14.1 46.7 32.5 29.6 28.4 19.8 20.2 25. 35.4 20.3 9.7 14.5 34.9 26.6 7.2 50. 32.4 21.6 29.8 \n13.1 27.5 21.2 23.1 21.9 13. 23.2 8.1 5.6 21.7 29.6 19.6 7. 26.4 18.9 20.9 28.1 35.4 10.2 24.3 43.1 17.6 \n15.4 16.2 27.1 21.4 21.5 22.4 25. 16.6 18.6 22. 42.8 35.1 21.5 36. 21.9 24.1 50. 26.7 25. ]\n</code></pre>\n\n\n\n<p>The output of both array have around 10-30% difference and it indicate our model predicts with reasonable range.</p>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, let us write a simple MPL based ANN to do regression prediction. Till now, we have only done the classification based prediction. Now, we will try to predict the next possible value by analyzing the previous (continuous) values and its influencing factors. The Regression MPL can be represented as below − The [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3397"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3397"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3397/revisions"}],"predecessor-version":[{"id":4234,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3397/revisions/4234"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3397"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3397"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3397"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3399,"date":"2020-10-01T11:34:00","date_gmt":"2020-10-01T11:34:00","guid":{"rendered":"http://ai.foobrdigital.com/?p=3399"},"modified":"2020-12-16T17:04:13","modified_gmt":"2020-12-16T17:04:13","slug":"keras-time-series-prediction-using-lstm-rnn","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-time-series-prediction-using-lstm-rnn/","title":{"rendered":"Time Series Prediction using LSTM RNN"},"content":{"rendered":"\n<p>In this chapter, let us write a simple Long Short Term Memory (LSTM) based RNN to do sequence analysis. A sequence is a set of values where each value corresponds to a particular instance of time. Let us consider a simple example of reading a sentence. Reading and understanding a sentence involves reading the word in the given order and trying to understand each word and its meaning in the given context and finally understanding the sentence in a positive or negative sentiment.</p>\n\n\n\n<p>Here, the words are considered as values, and first value corresponds to first word, second value corresponds to second word, etc., and the order will be strictly maintained.&nbsp;<strong>Sequence Analysis</strong>&nbsp;is used frequently in natural language processing to find the sentiment analysis of the given text.</p>\n\n\n\n<p>Let us create a LSTM model to analyze the IMDB movie reviews and find its positive/negative sentiment.</p>\n\n\n\n<p>The model for the sequence analysis can be represented as below −</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://www.tutorialspoint.com/keras/images/sequence_analysis.jpg\" alt=\"Sequence Analysis\"/></figure>\n\n\n\n<p>The core features of the model are as follows −</p>\n\n\n\n<ul><li>Input layer using Embedding layer with 128 features.</li><li>First layer, Dense consists of 128 units with normal dropout and recurrent dropout set to 0.2.</li><li>Output layer,&nbsp;<em>Dense</em>&nbsp;consists of 1 unit and ‘sigmoid’ activation function.</li><li>Use&nbsp;<strong>binary_crossentropy</strong>&nbsp;as loss function.</li><li>Use&nbsp;<strong>adam</strong>&nbsp;as Optimizer.</li><li>Use&nbsp;<strong>accuracy</strong>&nbsp;as metrics.</li><li>Use 32 as batch size.</li><li>Use 15 as epochs.</li><li>Use 80 as the maximum length of the word.</li><li>Use 2000 as the maximum number of word in a given sentence.</li></ul>\n\n\n\n<h2>Step 1: Import the modules</h2>\n\n\n\n<p>Let us import the necessary modules.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>from keras.preprocessing import sequence \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Embedding \nfrom keras.layers import LSTM \nfrom keras.datasets import imdb</code></pre>\n\n\n\n<h2>Step 2: Load data</h2>\n\n\n\n<p>Let us import the imdb dataset.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 2000)\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong>imdb</strong>&nbsp;is a dataset provided by Keras. It represents a collection of movies and its reviews.</li><li><strong>num_words</strong>&nbsp;represent the maximum number of words in the review.</li></ul>\n\n\n\n<h2>Step 3: Process the data</h2>\n\n\n\n<p>Let us change the dataset according to our model, so that it can be fed into our model. The data can be changed using the below code −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>x_train = sequence.pad_sequences(x_train, maxlen=80) \nx_test = sequence.pad_sequences(x_test, maxlen=80)</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<p><strong>sequence.pad_sequences</strong>&nbsp;convert the list of input data with shape,&nbsp;<strong>(data)</strong>&nbsp;into 2D NumPy array of shape&nbsp;<strong>(data, timesteps)</strong>. Basically, it adds timesteps concept into the given data. It generates the timesteps of length,&nbsp;<strong>maxlen</strong>.</p>\n\n\n\n<h2>Step 4: Create the model</h2>\n\n\n\n<p>Let us create the actual model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model = Sequential() \nmodel.add(Embedding(2000, 128)) \nmodel.add(LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)) \nmodel.add(Dense(1, activation = 'sigmoid'))</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<p>We have used&nbsp;<strong>Embedding layer</strong>&nbsp;as input layer and then added the LSTM layer. Finally, a&nbsp;<strong>Dense layer</strong>&nbsp;is used as output layer.</p>\n\n\n\n<h2>Step 5: Compile the model</h2>\n\n\n\n<p>Let us compile the model using selected loss function, optimizer and metrics.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.compile(loss = 'binary_crossentropy', \n   optimizer = 'adam', metrics = &#91;'accuracy'])</code></pre>\n\n\n\n<h2>Step 6: Train the model</h2>\n\n\n\n<p>LLet us train the model using&nbsp;<strong>fit()</strong>&nbsp;method.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>model.fit(\n   x_train, y_train, \n   batch_size = 32, \n   epochs = 15, \n   validation_data = (x_test, y_test)\n)</code></pre>\n\n\n\n<p>Executing the application will output the below information −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Epoch 1/15 2019-09-24 01:19:01.151247: I \ntensorflow/core/platform/cpu_feature_guard.cc:142] \nYour CPU supports instructions that this \nTensorFlow binary was not co mpiled to use: AVX2 \n25000/25000 &#91;==============================] - 101s 4ms/step - loss: 0.4707 \n- acc: 0.7716 - val_loss: 0.3769 - val_acc: 0.8349 Epoch 2/15 \n25000/25000 &#91;==============================] - 95s 4ms/step - loss: 0.3058 \n- acc: 0.8756 - val_loss: 0.3763 - val_acc: 0.8350 Epoch 3/15 \n25000/25000 &#91;==============================] - 91s 4ms/step - loss: 0.2100 \n- acc: 0.9178 - val_loss: 0.5065 - val_acc: 0.8110 Epoch 4/15 \n25000/25000 &#91;==============================] - 90s 4ms/step - loss: 0.1394 \n- acc: 0.9495 - val_loss: 0.6046 - val_acc: 0.8146 Epoch 5/15 \n25000/25000 &#91;==============================] - 90s 4ms/step - loss: 0.0973 \n- acc: 0.9652 - val_loss: 0.5969 - val_acc: 0.8147 Epoch 6/15 \n25000/25000 &#91;==============================] - 98s 4ms/step - loss: 0.0759 \n- acc: 0.9730 - val_loss: 0.6368 - val_acc: 0.8208 Epoch 7/15 \n25000/25000 &#91;==============================] - 95s 4ms/step - loss: 0.0578 \n- acc: 0.9811 - val_loss: 0.6657 - val_acc: 0.8184 Epoch 8/15 \n25000/25000 &#91;==============================] - 97s 4ms/step - loss: 0.0448 \n- acc: 0.9850 - val_loss: 0.7452 - val_acc: 0.8136 Epoch 9/15 \n25000/25000 &#91;==============================] - 95s 4ms/step - loss: 0.0324 \n- acc: 0.9894 - val_loss: 0.7616 - val_acc: 0.8162Epoch 10/15 \n25000/25000 &#91;==============================] - 100s 4ms/step - loss: 0.0247 \n- acc: 0.9922 - val_loss: 0.9654 - val_acc: 0.8148 Epoch 11/15 \n25000/25000 &#91;==============================] - 99s 4ms/step - loss: 0.0169 \n- acc: 0.9946 - val_loss: 1.0013 - val_acc: 0.8104 Epoch 12/15 \n25000/25000 &#91;==============================] - 90s 4ms/step - loss: 0.0154 \n- acc: 0.9948 - val_loss: 1.0316 - val_acc: 0.8100 Epoch 13/15 \n25000/25000 &#91;==============================] - 89s 4ms/step - loss: 0.0113 \n- acc: 0.9963 - val_loss: 1.1138 - val_acc: 0.8108 Epoch 14/15 \n25000/25000 &#91;==============================] - 89s 4ms/step - loss: 0.0106 \n- acc: 0.9971 - val_loss: 1.0538 - val_acc: 0.8102 Epoch 15/15 \n25000/25000 &#91;==============================] - 89s 4ms/step - loss: 0.0090 \n- acc: 0.9972 - val_loss: 1.1453 - val_acc: 0.8129 \n25000/25000 &#91;==============================] - 10s 390us/step\n</code></pre>\n\n\n\n<h2>Step 7 − Evaluate the model</h2>\n\n\n\n<p>Let us evaluate the model using test data.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>score, acc = model.evaluate(x_test, y_test, batch_size = 32) \n   \nprint('Test score:', score) \nprint('Test accuracy:', acc)</code></pre>\n\n\n\n<p>Executing the above code will output the below information −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>Test score: 1.145306069601178 \nTest accuracy: 0.81292</code></pre>\n\n\n\n<p></p>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, let us write a simple Long Short Term Memory (LSTM) based RNN to do sequence analysis. A sequence is a set of values where each value corresponds to a particular instance of time. Let us consider a simple example of reading a sentence. Reading and understanding a sentence involves reading the word [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3399"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3399"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3399/revisions"}],"predecessor-version":[{"id":4233,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3399/revisions/4233"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3399"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3399"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3399"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3401,"date":"2020-10-01T11:34:53","date_gmt":"2020-10-01T11:34:53","guid":{"rendered":"http://ai.foobrdigital.com/?p=3401"},"modified":"2020-12-16T17:04:13","modified_gmt":"2020-12-16T17:04:13","slug":"keras-applications","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-applications/","title":{"rendered":"Applications"},"content":{"rendered":"\n<p>Keras applications module is used to provide pre-trained model for deep neural networks. Keras models are used for prediction, feature extraction and fine tuning. This chapter explains about Keras applications in detail.</p>\n\n\n\n<h3>Pre-trained models</h3>\n\n\n\n<p>Trained model consists of two parts model Architecture and model Weights. Model weights are large file so we have to download and extract the feature from ImageNet database. Some of the popular pre-trained models are listed below,</p>\n\n\n\n<ul><li>ResNet</li><li>VGG16</li><li>MobileNet</li><li>InceptionResNetV2</li><li>InceptionV3</li></ul>\n\n\n\n<h2>Loading a model</h2>\n\n\n\n<p>Keras pre-trained models can be easily loaded as specified below −</p>\n\n\n\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<pre class=\"wp-block-code\"><code>import keras \nimport numpy as np \n\nfrom keras.applications import vgg16, inception_v3, resnet50, mobilenet \n\n#Load the VGG model \nvgg_model = vgg16.VGG16(weights = 'imagenet') \n\n#Load the Inception_V3 model \ninception_model = inception_v3.InceptionV3(weights = 'imagenet') \n\n#Load the ResNet50 model \nresnet_model = resnet50.ResNet50(weights = 'imagenet') \n\n#Load the MobileNet model mobilenet_model = mobilenet.MobileNet(weights = 'imagenet')</code></pre>\n\n\n\n<p></p>\n</div></div>\n\n\n\n<p>Once the model is loaded, we can immediately use it for prediction purpose. Let us check each pre-trained model in the upcoming chapters.</p>\n","protected":false},"excerpt":{"rendered":"<p>Keras applications module is used to provide pre-trained model for deep neural networks. Keras models are used for prediction, feature extraction and fine tuning. This chapter explains about Keras applications in detail. Pre-trained models Trained model consists of two parts model Architecture and model Weights. Model weights are large file so we have to download [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3401"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3401"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3401/revisions"}],"predecessor-version":[{"id":4232,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3401/revisions/4232"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3401"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3401"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3401"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3403,"date":"2020-10-01T11:36:12","date_gmt":"2020-10-01T11:36:12","guid":{"rendered":"http://ai.foobrdigital.com/?p=3403"},"modified":"2020-12-16T17:04:13","modified_gmt":"2020-12-16T17:04:13","slug":"real-time-prediction-using-resnet-model","status":"publish","type":"post","link":"https://python3.foobrdigital.com/real-time-prediction-using-resnet-model/","title":{"rendered":"Real Time Prediction using ResNet Model"},"content":{"rendered":"\n<p><em>ResNet</em>&nbsp;is a pre-trained model. It is trained using&nbsp;<em>ImageNet</em>. ResNet model weights pre-trained on&nbsp;<em>ImageNet</em>. It has the following syntax −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.applications.resnet.ResNet50 (\n   include_top = True, \n   weights = 'imagenet', \n   input_tensor = None, \n   input_shape = None, \n   pooling = None, \n   classes = 1000\n)</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<ul><li><strong><em>include_top</em></strong>&nbsp;refers the fully-connected layer at the top of the network.</li><li><strong><em>weights</em></strong>&nbsp;refer pre-training on ImageNet.</li><li><strong><em>input_tensor</em></strong>&nbsp;refers optional Keras tensor to use as image input for the model.</li><li><strong><em>input_shape</em></strong>&nbsp;refers optional shape tuple. The default input size for this model is 224&#215;224.</li><li><strong><em>classes</em></strong>&nbsp;refer optional number of classes to classify images.</li></ul>\n\n\n\n<p>Let us understand the model by writing a simple example −</p>\n\n\n\n<h2>Step 1: import the modules</h2>\n\n\n\n<p>Let us load the necessary modules as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> import PIL \n>>> from keras.preprocessing.image import load_img \n>>> from keras.preprocessing.image import img_to_array \n>>> from keras.applications.imagenet_utils import decode_predictions \n>>> import matplotlib.pyplot as plt \n>>> import numpy as np \n>>> from keras.applications.resnet50 import ResNet50 \n>>> from keras.applications import resnet50</code></pre>\n\n\n\n<h2>Step 2: Select an input</h2>\n\n\n\n<p>Let us choose an input image,&nbsp;<strong><em>Lotus</em></strong>&nbsp;as specified below −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>>>> filename = 'banana.jpg' \n>>> ## load an image in PIL format \n>>> original = load_img(filename, target_size = (224, 224)) \n>>> print('PIL image size',original.size)\nPIL image size (224, 224) \n>>> plt.imshow(original) \n&lt;matplotlib.image.AxesImage object at 0x1304756d8> \n>>> plt.show()</code></pre>\n\n\n\n<p>Here, we have loaded an image&nbsp;<strong>(banana.jpg)</strong>&nbsp;and displayed it.</p>\n\n\n\n<h2>Step 3: Convert images into NumPy array</h2>\n\n\n\n<p>Let us convert our input,&nbsp;<strong>Banana</strong>&nbsp;into NumPy array, so that it can be passed into the model for the purpose of prediction.</p>\n\n\n\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<pre class=\"wp-block-code\"><code>&amp;gt;&amp;gt;&amp;gt; #convert the PIL image to a numpy array \n&amp;gt;&amp;gt;&amp;gt; numpy_image = img_to_array(original) \n\n&amp;gt;&amp;gt;&amp;gt; plt.imshow(np.uint8(numpy_image)) \n&amp;lt;matplotlib.image.AxesImage object at 0x130475ac8&amp;gt; \n\n&amp;gt;&amp;gt;&amp;gt; print('numpy array size',numpy_image.shape) \nnumpy array size (224, 224, 3) \n\n&amp;gt;&amp;gt;&amp;gt; # Convert the image / images into batch format \n&amp;gt;&amp;gt;&amp;gt; image_batch = np.expand_dims(numpy_image, axis = 0) \n\n&amp;gt;&amp;gt;&amp;gt; print('image batch size', image_batch.shape) \nimage batch size (1, 224, 224, 3)\n&amp;gt;&amp;gt;&amp;gt; </code></pre>\n</div></div>\n\n\n\n<h2>Step 4: Model prediction</h2>\n\n\n\n<p>Let us feed our input into the model to get the predictions</p>\n\n\n\n<pre class=\"wp-block-code\"><code>&amp;gt;&amp;gt;&amp;gt; prepare the image for the resnet50 model &amp;gt;&amp;gt;&amp;gt; \n&amp;gt;&amp;gt;&amp;gt; processed_image = resnet50.preprocess_input(image_batch.copy()) \n\n&amp;gt;&amp;gt;&amp;gt; # create resnet model \n&amp;gt;&amp;gt;&amp;gt;resnet_model = resnet50.ResNet50(weights = 'imagenet') \n&amp;gt;&amp;gt;&amp;gt; Downloavding data from https://github.com/fchollet/deep-learning-models/releas\nes/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5 \n102858752/102853048 &#91;==============================] - 33s 0us/step \n\n&amp;gt;&amp;gt;&amp;gt; # get the predicted probabilities for each class \n&amp;gt;&amp;gt;&amp;gt; predictions = resnet_model.predict(processed_image) \n\n&amp;gt;&amp;gt;&amp;gt; # convert the probabilities to class labels \n&amp;gt;&amp;gt;&amp;gt; label = decode_predictions(predictions) \nDownloading data from https://storage.googleapis.com/download.tensorflow.org/\ndata/imagenet_class_index.json \n40960/35363 &#91;==================================] - 0s 0us/step \n\n&amp;gt;&amp;gt;&amp;gt; print(label)</code></pre>\n\n\n\n<h2>Output</h2>\n\n\n\n<pre class=\"wp-block-code\"><code>&#91;\n   &#91;\n      ('n07753592', 'banana', 0.99229723), \n      ('n03532672', 'hook', 0.0014551596), \n      ('n03970156', 'plunger', 0.0010738898), \n      ('n07753113', 'fig', 0.0009359837) , \n      ('n03109150', 'corkscrew', 0.00028538404)\n   ]\n]\n</code></pre>\n\n\n\n<p>Here, the model predicted the images as banana correctly.</p>\n","protected":false},"excerpt":{"rendered":"<p>ResNet&nbsp;is a pre-trained model. It is trained using&nbsp;ImageNet. ResNet model weights pre-trained on&nbsp;ImageNet. It has the following syntax − Here, include_top&nbsp;refers the fully-connected layer at the top of the network. weights&nbsp;refer pre-training on ImageNet. input_tensor&nbsp;refers optional Keras tensor to use as image input for the model. input_shape&nbsp;refers optional shape tuple. The default input size for [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3403"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3403"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3403/revisions"}],"predecessor-version":[{"id":4231,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3403/revisions/4231"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3403"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3403"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3403"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}},{"id":3405,"date":"2020-10-01T11:37:06","date_gmt":"2020-10-01T11:37:06","guid":{"rendered":"http://ai.foobrdigital.com/?p=3405"},"modified":"2020-12-16T17:04:12","modified_gmt":"2020-12-16T17:04:12","slug":"keras-pre-trained-models","status":"publish","type":"post","link":"https://python3.foobrdigital.com/keras-pre-trained-models/","title":{"rendered":"Pre-Trained Models"},"content":{"rendered":"\n<p>In this chapter, we will learn about the pre-trained models in Keras. Let us begin with VGG16.</p>\n\n\n\n<h2>VGG16</h2>\n\n\n\n<p><strong>VGG16</strong>&nbsp;is another pre-trained model. It is also trained using ImageNet. The syntax to load the model is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.applications.vgg16.VGG16(\n   include_top = True, \n   weights = 'imagenet', \n   input_tensor = None, \n   input_shape = None, \n   pooling = None, \n   classes = 1000\n)</code></pre>\n\n\n\n<p>The default input size for this model is 224&#215;224.</p>\n\n\n\n<h2>MobileNetV2</h2>\n\n\n\n<p><strong>MobileNetV2</strong>&nbsp;is another pre-trained model. It is also trained uing&nbsp;<strong>ImageNet</strong>.</p>\n\n\n\n<p>The syntax to load the model is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.applications.mobilenet_v2.MobileNetV2 (\n   input_shape = None, \n   alpha = 1.0, \n   include_top = True, \n   weights = 'imagenet', \n   input_tensor = None, \n   pooling = None, \n   classes = 1000\n)</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<p><strong>alpha</strong>&nbsp;controls the width of the network. If the value is below 1, decreases the number of filters in each layer. If the value is above 1, increases the number of filters in each layer. If alpha = 1, default number of filters from the paper are used at each layer.</p>\n\n\n\n<p>The default input size for this model is&nbsp;<strong>224&#215;224</strong>.</p>\n\n\n\n<h2>InceptionResNetV2</h2>\n\n\n\n<p><strong>InceptionResNetV2</strong>&nbsp;is another pre-trained model. It is also trained using&nbsp;<strong>ImageNet</strong>. The syntax to load the model is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.applications.inception_resnet_v2.InceptionResNetV2 (\n   include_top = True, \n   weights = 'imagenet',\n   input_tensor = None, \n   input_shape = None, \n   pooling = None, \n   classes = 1000)</code></pre>\n\n\n\n<p>This model and can be built both with ‘channels_first’ data format (channels, height, width) or ‘channels_last’ data format (height, width, channels).</p>\n\n\n\n<p>The default input size for this model is&nbsp;<strong>299&#215;299</strong>.</p>\n\n\n\n<h2>InceptionV3</h2>\n\n\n\n<p><strong>InceptionV3</strong>&nbsp;is another pre-trained model. It is also trained uing&nbsp;<strong>ImageNet</strong>. The syntax to load the model is as follows −</p>\n\n\n\n<pre class=\"wp-block-code\"><code>keras.applications.inception_v3.InceptionV3 (\n   include_top = True, \n   weights = 'imagenet', \n   input_tensor = None, \n   input_shape = None, \n   pooling = None, \n   classes = 1000\n)\n</code></pre>\n\n\n\n<p>Here,</p>\n\n\n\n<p>The default input size for this model is&nbsp;<strong>299&#215;299</strong>.</p>\n\n\n\n<h2>Conclusion</h2>\n\n\n\n<p>Keras is very simple, extensible and easy to implement neural network API, which can be used to build deep learning applications with high level abstraction. Keras is an optimal choice for deep leaning models.</p>\n","protected":false},"excerpt":{"rendered":"<p>In this chapter, we will learn about the pre-trained models in Keras. Let us begin with VGG16. VGG16 VGG16&nbsp;is another pre-trained model. It is also trained using ImageNet. The syntax to load the model is as follows − The default input size for this model is 224&#215;224. MobileNetV2 MobileNetV2&nbsp;is another pre-trained model. It is also [&hellip;]</p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[92,153],"tags":[],"_links":{"self":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3405"}],"collection":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts"}],"about":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/types/post"}],"author":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/users/1"}],"replies":[{"embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/comments?post=3405"}],"version-history":[{"count":1,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3405/revisions"}],"predecessor-version":[{"id":4230,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/posts/3405/revisions/4230"}],"wp:attachment":[{"href":"https://python3.foobrdigital.com/wp-json/wp/v2/media?parent=3405"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/categories?post=3405"},{"taxonomy":"post_tag","embeddable":true,"href":"https://python3.foobrdigital.com/wp-json/wp/v2/tags?post=3405"}],"curies":[{"name":"wp","href":"https://api.w.org/{rel}","templated":true}]}}]